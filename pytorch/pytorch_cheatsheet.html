
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Pytorch Cheatsheet &#8212; My sample book</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Introduction to Tensors" href="../old/1.tensor.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="../intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Cheat Sheet
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   1. Pytorch Cheatsheet
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tensorflow basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../old/1.tensor.html">
   2. Introduction to Tensors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../old/2.variable.html">
   3. Introduction to Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../old/3.autodiff.html">
   4. Introduction to gradients and automatic differentiation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../old/5.intro_to_modules.html">
   5. Introduction to modules, layers, and models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../old/6.basic_training_loops.html">
   7. Basic training loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../old/7.keras_sequential_model.html">
   8. The Sequential model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tf_create_model.html">
   9. 三種搭建神經網路的方式
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../hands_on_ml3/tf_customization.html">
   10. Customization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pytorch resource summarise
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="d2l/d2l_linear_regression.html">
   11. Linear regression (d2l)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="d2l/d2l_softmax_regression.html">
   12. Softmax regression (d2l)
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/pytorch/pytorch_cheatsheet.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpytorch/pytorch_cheatsheet.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/pytorch/pytorch_cheatsheet.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensors">
   1.1. Tensors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor">
     1.1.1. 建立 tensor 的方式
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-empty-torch-zeros-torch-ones-torch-rand">
       1.1.1.1. torch.empty(), torch.zeros(), torch.ones(), torch.rand()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-manual-seed">
       1.1.1.2. torch.manual_seed()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-empty-like-torch-zeros-like-torch-ones-like-torch-rand-like">
       1.1.1.3. torch.empty_like(), torch.zeros_like(), torch.ones_like(), torch.rand_like()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dtype-torch-int16-and-tensor-obj-to-torch-int32">
       1.1.1.4.
       <code class="docutils literal notranslate">
        <span class="pre">
         dtype
        </span>
        <span class="pre">
         =
        </span>
        <span class="pre">
         torch.int16
        </span>
       </code>
       and
       <code class="docutils literal notranslate">
        <span class="pre">
         tensor_obj.to(torch.int32)
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-clone">
     1.1.2. tensor_obj.clone()
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-detach">
     1.1.3. tensor_obj.detach()
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-unsqueeze-dim-xx-tensor-obj-squeeze-dim-xx">
     1.1.4.
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.unsqueeze(dim=xx)
      </span>
     </code>
     增軸;
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.squeeze(dim=xx)
      </span>
     </code>
     減軸
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#moving-to-gpu">
     1.1.5. Moving to GPU
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#torch-from-numpy-np-array-and-tensor-obj-clone-numpy">
     1.1.6.
     <code class="docutils literal notranslate">
      <span class="pre">
       torch.from_numpy(np_array)
      </span>
     </code>
     and
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.clone().numpy()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     1.1.7. 常用數學計算
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.2. 自動微分
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   1.3. Data preparation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-class">
     1.3.1. Dataset - 自訂 class
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-tensordataset">
     1.3.2. Dataset - 直接用
     <code class="docutils literal notranslate">
      <span class="pre">
       TensorDataset
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataloader">
     1.3.3. DataLoader
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     1.3.4. 內建 dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       1.3.4.1. 圖片類
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#transform">
         1.3.4.1.1. 無 transform
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id4">
         1.3.4.1.2. 有 transform
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transforms">
   1.4. Transforms
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nn-structures">
   1.5. NN structures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import">
     1.5.1. import
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-functions">
   1.6. activation functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.6.1. 內建
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relu">
       1.6.1.1. ReLU
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sigmoid">
       1.6.1.2. Sigmoid
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     1.6.2. 自訂
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-layers-block">
   1.7. custom layers &amp; block
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#custom-layer">
     1.7.1. custom layer (不帶參數)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     1.7.2. custom layer (帶參數)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-block-nn-sequential-layer1-block2">
     1.7.3. sequential block (
     <code class="docutils literal notranslate">
      <span class="pre">
       nn.Sequential(layer1,
      </span>
      <span class="pre">
       block2,
      </span>
      <span class="pre">
       ...)
      </span>
     </code>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-for-tips">
     1.7.4. sequential
     <code class="docutils literal notranslate">
      <span class="pre">
       for
      </span>
     </code>
     tips
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#custom-block">
     1.7.5. custom block
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   1.8. 參數管理
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-structure">
     1.8.1. 看 model structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-bias-gradient">
     1.8.2. 看單一層的 weight, bias, gradient
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#state-dict">
       1.8.2.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         .state_dict()
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#weight-weight-data-weight-grad">
       1.8.2.2.
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight.data
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight.grad
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bias-bias-data-bias-grad">
       1.8.2.3.
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias.data
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias.grad
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parameters">
       1.8.2.4.
       <code class="docutils literal notranslate">
        <span class="pre">
         .parameters()
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#named-parameters">
       1.8.2.5.
       <code class="docutils literal notranslate">
        <span class="pre">
         .named_parameters
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters-weight-bias-gradient">
     1.8.3. 看所有的 parameters, weight, bias, gradient
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#block-factory">
     1.8.4. block factory
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   1.9. 參數初始化
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classical-layers">
   1.10. Classical Layers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nn">
     1.10.1. NN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nn-linear-in-dim-out-dim">
       1.10.1.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         nn.Linear(in_dim,
        </span>
        <span class="pre">
         out_dim)
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cnn">
     1.10.2. CNN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolution">
       1.10.2.1. convolution
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pooling">
       1.10.2.2. pooling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#vgg">
       1.10.2.3. VGG
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#resnet">
       1.10.2.4. ResNet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rnn">
     1.10.3. RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss">
   1.11. Loss
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     1.11.1. overview
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mse">
     1.11.2. mse
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class">
       1.11.2.1. class 版本
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#function">
       1.11.2.2. function 版本
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mae">
     1.11.3. mae
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy">
     1.11.4. binary cross entropy
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       1.11.4.1. class 版本
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       1.11.4.2. function 版
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy-with-logits">
     1.11.5. binary cross entropy with logits
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-entropy">
     1.11.6. cross-entropy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.11.7. 自訂 loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     1.11.8. 對比學習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autoencoder">
     1.11.9. autoencoder
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizer">
   1.12. Optimizer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.12.1. 建立 optimizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate">
     1.12.2. 不同 learning rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate-scheduler">
     1.12.3. learning rate scheduler
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-loops">
   1.13. Training loops
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     1.13.1. 完整版 (了解概念用)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deploy">
     1.13.2. 模組版 (實際做實驗, deploy 時用)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     1.13.3. CNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   1.14. Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   1.15. Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-load-model">
   1.16. Save/ load model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight">
     1.16.1. 只存 weight
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-model-structure">
     1.16.2. 存 weight 和 model structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checkpoints">
     1.16.3. checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#callbacks">
   1.17. callbacks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     1.17.1. Early stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   1.18. Visualization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explaianation">
   1.19. Explaianation
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Pytorch Cheatsheet</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensors">
   1.1. Tensors
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor">
     1.1.1. 建立 tensor 的方式
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-empty-torch-zeros-torch-ones-torch-rand">
       1.1.1.1. torch.empty(), torch.zeros(), torch.ones(), torch.rand()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-manual-seed">
       1.1.1.2. torch.manual_seed()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#torch-empty-like-torch-zeros-like-torch-ones-like-torch-rand-like">
       1.1.1.3. torch.empty_like(), torch.zeros_like(), torch.ones_like(), torch.rand_like()
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dtype-torch-int16-and-tensor-obj-to-torch-int32">
       1.1.1.4.
       <code class="docutils literal notranslate">
        <span class="pre">
         dtype
        </span>
        <span class="pre">
         =
        </span>
        <span class="pre">
         torch.int16
        </span>
       </code>
       and
       <code class="docutils literal notranslate">
        <span class="pre">
         tensor_obj.to(torch.int32)
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-clone">
     1.1.2. tensor_obj.clone()
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-detach">
     1.1.3. tensor_obj.detach()
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensor-obj-unsqueeze-dim-xx-tensor-obj-squeeze-dim-xx">
     1.1.4.
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.unsqueeze(dim=xx)
      </span>
     </code>
     增軸;
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.squeeze(dim=xx)
      </span>
     </code>
     減軸
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#moving-to-gpu">
     1.1.5. Moving to GPU
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#torch-from-numpy-np-array-and-tensor-obj-clone-numpy">
     1.1.6.
     <code class="docutils literal notranslate">
      <span class="pre">
       torch.from_numpy(np_array)
      </span>
     </code>
     and
     <code class="docutils literal notranslate">
      <span class="pre">
       tensor_obj.clone().numpy()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     1.1.7. 常用數學計算
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.2. 自動微分
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preparation">
   1.3. Data preparation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-class">
     1.3.1. Dataset - 自訂 class
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-tensordataset">
     1.3.2. Dataset - 直接用
     <code class="docutils literal notranslate">
      <span class="pre">
       TensorDataset
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataloader">
     1.3.3. DataLoader
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset">
     1.3.4. 內建 dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       1.3.4.1. 圖片類
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#transform">
         1.3.4.1.1. 無 transform
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id4">
         1.3.4.1.2. 有 transform
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transforms">
   1.4. Transforms
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nn-structures">
   1.5. NN structures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import">
     1.5.1. import
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#activation-functions">
   1.6. activation functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.6.1. 內建
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relu">
       1.6.1.1. ReLU
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sigmoid">
       1.6.1.2. Sigmoid
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     1.6.2. 自訂
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-layers-block">
   1.7. custom layers &amp; block
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#custom-layer">
     1.7.1. custom layer (不帶參數)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     1.7.2. custom layer (帶參數)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-block-nn-sequential-layer1-block2">
     1.7.3. sequential block (
     <code class="docutils literal notranslate">
      <span class="pre">
       nn.Sequential(layer1,
      </span>
      <span class="pre">
       block2,
      </span>
      <span class="pre">
       ...)
      </span>
     </code>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sequential-for-tips">
     1.7.4. sequential
     <code class="docutils literal notranslate">
      <span class="pre">
       for
      </span>
     </code>
     tips
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#custom-block">
     1.7.5. custom block
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   1.8. 參數管理
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-structure">
     1.8.1. 看 model structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-bias-gradient">
     1.8.2. 看單一層的 weight, bias, gradient
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#state-dict">
       1.8.2.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         .state_dict()
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#weight-weight-data-weight-grad">
       1.8.2.2.
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight.data
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .weight.grad
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bias-bias-data-bias-grad">
       1.8.2.3.
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias.data
        </span>
       </code>
       ,
       <code class="docutils literal notranslate">
        <span class="pre">
         .bias.grad
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parameters">
       1.8.2.4.
       <code class="docutils literal notranslate">
        <span class="pre">
         .parameters()
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#named-parameters">
       1.8.2.5.
       <code class="docutils literal notranslate">
        <span class="pre">
         .named_parameters
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters-weight-bias-gradient">
     1.8.3. 看所有的 parameters, weight, bias, gradient
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#block-factory">
     1.8.4. block factory
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   1.9. 參數初始化
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classical-layers">
   1.10. Classical Layers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nn">
     1.10.1. NN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nn-linear-in-dim-out-dim">
       1.10.1.1.
       <code class="docutils literal notranslate">
        <span class="pre">
         nn.Linear(in_dim,
        </span>
        <span class="pre">
         out_dim)
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cnn">
     1.10.2. CNN
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolution">
       1.10.2.1. convolution
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pooling">
       1.10.2.2. pooling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#vgg">
       1.10.2.3. VGG
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#resnet">
       1.10.2.4. ResNet
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rnn">
     1.10.3. RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss">
   1.11. Loss
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview">
     1.11.1. overview
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mse">
     1.11.2. mse
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#class">
       1.11.2.1. class 版本
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#function">
       1.11.2.2. function 版本
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mae">
     1.11.3. mae
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy">
     1.11.4. binary cross entropy
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       1.11.4.1. class 版本
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id11">
       1.11.4.2. function 版
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#binary-cross-entropy-with-logits">
     1.11.5. binary cross entropy with logits
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-entropy">
     1.11.6. cross-entropy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     1.11.7. 自訂 loss
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     1.11.8. 對比學習
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autoencoder">
     1.11.9. autoencoder
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizer">
   1.12. Optimizer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     1.12.1. 建立 optimizer
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate">
     1.12.2. 不同 learning rate
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#learning-rate-scheduler">
     1.12.3. learning rate scheduler
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-loops">
   1.13. Training loops
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     1.13.1. 完整版 (了解概念用)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deploy">
     1.13.2. 模組版 (實際做實驗, deploy 時用)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     1.13.3. CNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#prediction">
   1.14. Prediction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation">
   1.15. Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#save-load-model">
   1.16. Save/ load model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight">
     1.16.1. 只存 weight
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#weight-model-structure">
     1.16.2. 存 weight 和 model structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#checkpoints">
     1.16.3. checkpoints
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#callbacks">
   1.17. callbacks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     1.17.1. Early stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   1.18. Visualization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explaianation">
   1.19. Explaianation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="pytorch-cheatsheet">
<h1><span class="section-number">1. </span>Pytorch Cheatsheet<a class="headerlink" href="#pytorch-cheatsheet" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>settings</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mounted at /content/drive
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/0. codepool_python/python_dl/mybook/pytorch&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">math</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="tensors">
<h2><span class="section-number">1.1. </span>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<div class="section" id="tensor">
<h3><span class="section-number">1.1.1. </span>建立 tensor 的方式<a class="headerlink" href="#tensor" title="Permalink to this headline">¶</a></h3>
<div class="section" id="torch-empty-torch-zeros-torch-ones-torch-rand">
<h4><span class="section-number">1.1.1.1. </span>torch.empty(), torch.zeros(), torch.ones(), torch.rand()<a class="headerlink" href="#torch-empty-torch-zeros-torch-ones-torch-rand" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 建立出指定 shape 的 placeholder</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.0000e+00, -0.0000e+00, 0.0000e+00, -0.0000e+00],
        [1.1210e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>這些數字都是假的，實際上只是在 memory 上幫你開好 (3, 4) 這種 shape 的 placeholder</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0., 0., 0.],
        [0., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1., 1., 1.],
        [1., 1., 1.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># 生出 0~1 的隨機數</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.6128, 0.1519, 0.0453],
        [0.5035, 0.9978, 0.3884]])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="torch-manual-seed">
<h4><span class="section-number">1.1.1.2. </span>torch.manual_seed()<a class="headerlink" href="#torch-manual-seed" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">random1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random1</span><span class="p">)</span>

<span class="n">random2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random2</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1729</span><span class="p">)</span>
<span class="n">random3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random3</span><span class="p">)</span>

<span class="n">random4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.3126, 0.3791, 0.3087],
        [0.0736, 0.4216, 0.0691]])
tensor([[0.2332, 0.4047, 0.2162],
        [0.9927, 0.4128, 0.5938]])
tensor([[0.3126, 0.3791, 0.3087],
        [0.0736, 0.4216, 0.0691]])
tensor([[0.2332, 0.4047, 0.2162],
        [0.9927, 0.4128, 0.5938]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>設 seed 後，接續的第一、第二…、第 n 次生成，結果會不同，但只要再設一次 seed，那結果就會和之前的第一、第二、…、第 n 次相同</p></li>
</ul>
</div>
<div class="section" id="torch-empty-like-torch-zeros-like-torch-ones-like-torch-rand-like">
<h4><span class="section-number">1.1.1.3. </span>torch.empty_like(), torch.zeros_like(), torch.ones_like(), torch.rand_like()<a class="headerlink" href="#torch-empty-like-torch-zeros-like-torch-ones-like-torch-rand-like" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">empty_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">empty_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">empty_like_x</span><span class="p">)</span>

<span class="n">zeros_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zeros_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zeros_like_x</span><span class="p">)</span>

<span class="n">ones_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones_like_x</span><span class="p">)</span>

<span class="n">rand_like_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rand_like_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">rand_like_x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 2, 3])
tensor([[[0.0000e+00, -0.0000e+00, 0.0000e+00],
         [-0.0000e+00, 5.6107e-18, 4.5901e-41]],

        [[0.0000e+00, 0.0000e+00, 0.0000e+00],
         [0.0000e+00,        nan, 0.0000e+00]]])
torch.Size([2, 2, 3])
tensor([[[ 0.0000e+00, -0.0000e+00,  8.3198e+01],
         [-2.5250e-29,  2.1071e-08,  1.4013e-45]],

        [[ 0.0000e+00,  0.0000e+00,  1.4013e-45],
         [ 0.0000e+00,  2.0860e-13,  4.5901e-41]]])
torch.Size([2, 2, 3])
tensor([[[0., 0., 0.],
         [0., 0., 0.]],

        [[0., 0., 0.],
         [0., 0., 0.]]])
torch.Size([2, 2, 3])
tensor([[[1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.]]])
torch.Size([2, 2, 3])
tensor([[[0.6929, 0.1703, 0.1384],
         [0.4759, 0.7481, 0.0361]],

        [[0.5062, 0.8469, 0.2588],
         [0.2707, 0.4115, 0.6839]]])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dtype-torch-int16-and-tensor-obj-to-torch-int32">
<h4><span class="section-number">1.1.1.4. </span><code class="docutils literal notranslate"><span class="pre">dtype</span> <span class="pre">=</span> <span class="pre">torch.int16</span></code> and <code class="docutils literal notranslate"><span class="pre">tensor_obj.to(torch.int32)</span></code><a class="headerlink" href="#dtype-torch-int16-and-tensor-obj-to-torch-int32" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>常見的 dtype</p>
<ul>
<li><p>torch.bool</p></li>
<li><p>torch.int8</p></li>
<li><p>torch.uint8</p></li>
<li><p>torch.int16</p></li>
<li><p>torch.int32</p></li>
<li><p>torch.int64</p></li>
<li><p>torch.half</p></li>
<li><p>torch.float</p></li>
<li><p>torch.double</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>建立想要的 dtype 的 3 種方式:</p>
<ul>
<li><p>直接給小數點.</p></li>
<li><p>用 dtype = …</p></li>
<li><p>用 tensor_obj.to(…)</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 直接給小數點</span>

<span class="n">some_constants</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.1415926</span><span class="p">,</span> <span class="mf">2.71828</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.61803</span><span class="p">,</span> <span class="mf">0.0072897</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">some_constants</span><span class="p">)</span>

<span class="n">some_integers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">some_integers</span><span class="p">)</span>

<span class="n">more_integers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">more_integers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[3.1416, 2.7183],
        [1.6180, 0.0073]])
tensor([ 2,  3,  5,  7, 11, 13, 17, 19])
tensor([[2, 4, 6],
        [3, 6, 9]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 指定 type</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span> <span class="o">*</span> <span class="mf">20.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1, 1, 1],
        [1, 1, 1]], dtype=torch.int16)
tensor([[11.2406, 11.2083, 11.6692],
        [18.3283,  0.2118, 18.4972]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 轉換 type</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[11, 11, 11],
        [18,  0, 18]], dtype=torch.int32)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="tensor-obj-clone">
<h3><span class="section-number">1.1.2. </span>tensor_obj.clone()<a class="headerlink" href="#tensor-obj-clone" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>tensor 是 mutable 的：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span>

<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">561</span>  <span class="c1"># we change a...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>       <span class="c1"># ...and b is also altered</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[  1., 561.],
        [  1.,   1.]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>所以記得用 tensro_obj.clone() 來做 copy (就是 df.copy() 的類似寫法)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

<span class="k">assert</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">a</span>      <span class="c1"># different objects in memory...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>  <span class="c1"># ...but still with the same contents!</span>

<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">561</span>          <span class="c1"># a changes...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>               <span class="c1"># ...but b is still all ones</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[True, True],
        [True, True]])
tensor([[1., 1.],
        [1., 1.]])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tensor-obj-detach">
<h3><span class="section-number">1.1.3. </span>tensor_obj.detach()<a class="headerlink" href="#tensor-obj-detach" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>.detach() 的意思，主要就是刪掉 gradient 紀錄</p></li>
<li><p>這主要是用在：</p>
<ul>
<li><p>NN 計算到一半時，你想拿某個中間產物，出去算一些暫時的結果，然後再回來.</p></li>
<li><p>這時，你不希望中間跑出去算的哪些過程，也被記錄下來，導致去做 backpropagation 時，還會更新到那些 gradient，進而影想到真正的 variable 的 gradient</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># turn on autograd</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.6865, 0.3614],
        [0.6493, 0.2633]], requires_grad=True)
tensor([[0.6865, 0.3614],
        [0.6493, 0.2633]], grad_fn=&lt;CloneBackward0&gt;)
tensor([[0.6865, 0.3614],
        [0.6493, 0.2633]])
tensor([[0.6865, 0.3614],
        [0.6493, 0.2633]], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>解釋一下這邊發生的事：</p>
<ul>
<li><p>我們用 <code class="docutils literal notranslate"><span class="pre">requires_grad</span> <span class="pre">=</span> <span class="pre">True</span></code> 建立了 a ，所以去 print(a) 時，他告訴我們： requires_grad = True，表示 autograd 和 computation history tracking 都有被 turn on.</p></li>
<li><p>當我們單純把 a clone 到 b 時，他不僅繼承了 a 的 requires_grad，他也記錄了你的這次 computation history: clone，所以寫成 CloneBackward.</p></li>
<li><p>但如果我們先把 a detach，再把 a clone 給 c，就可以發現 c 乾乾淨淨的沒有任何 gradient 的痕跡。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">detach()</span></code> 會 detaches the tensor from its computation history。他等於在說：不管接下來你要做啥計算，都把 autograd 給關起來。</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="tensor-obj-unsqueeze-dim-xx-tensor-obj-squeeze-dim-xx">
<h3><span class="section-number">1.1.4. </span><code class="docutils literal notranslate"><span class="pre">tensor_obj.unsqueeze(dim=xx)</span></code> 增軸; <code class="docutils literal notranslate"><span class="pre">tensor_obj.squeeze(dim=xx)</span></code> 減軸<a class="headerlink" href="#tensor-obj-unsqueeze-dim-xx-tensor-obj-squeeze-dim-xx" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>我們常常想把單一一張 img 的 shape，增軸成 batch = 1 的一張 img (i.e. 把 shape = (3, 266, 266) 增軸成 (1, 3, 266, 266))</p></li>
<li><p>那 unsqueeze 就是增軸，例如這邊，我想增在 第 0 軸</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">226</span><span class="p">,</span> <span class="mi">226</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([3, 226, 226])
torch.Size([1, 3, 226, 226])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>相反的，我們有時候拿到帶有 batch 資訊的資料時，我們想把他 un-batch.</p></li>
<li><p>例如，我拿到 shape = (1, 1) 的 output，但最前面的 1 其實是 batch_size，他就等於 1 而已.</p></li>
<li><p>我想把他拔掉，就用 squeeze</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.6759]])
torch.Size([1, 1])
tensor([0.6759])
torch.Size([1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 20])
tensor([[0.0746, 0.2186, 0.8389, 0.3639, 0.2582, 0.1838, 0.3514, 0.2332, 0.5520,
         0.4285, 0.5416, 0.2346, 0.0468, 0.4869, 0.5096, 0.9663, 0.0631, 0.1065,
         0.7211, 0.5715]])
torch.Size([20])
tensor([0.0746, 0.2186, 0.8389, 0.3639, 0.2582, 0.1838, 0.3514, 0.2332, 0.5520,
        0.4285, 0.5416, 0.2346, 0.0468, 0.4869, 0.5096, 0.9663, 0.0631, 0.1065,
        0.7211, 0.5715])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>pytorch 很聰明的，如果你的原始軸不是 1 ，他不會幫你 squeeze，例如下例就沒改變任何東西：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.1736, 0.8499],
        [0.9200, 0.4837]])
torch.Size([2, 2])
tensor([[0.1736, 0.8499],
        [0.9200, 0.4837]])
torch.Size([2, 2])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="moving-to-gpu">
<h3><span class="section-number">1.1.5. </span>Moving to GPU<a class="headerlink" href="#moving-to-gpu" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cuda&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>建立時直接指定 device</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="n">device</span><span class="p">)</span>
<span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.1151, 0.3213],
        [0.0268, 0.3337]], device=&#39;cuda:0&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>確認 目前變數的 device</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>device(type=&#39;cuda&#39;, index=0)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>轉換 device</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y1</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">y2</span> <span class="o">=</span> <span class="n">y1</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y2</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">y3</span> <span class="o">=</span> <span class="n">y2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y3</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cpu
cuda:0
cpu
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>tensor 做計算時，必須在同一個 device 上才能算 (都在 GPU or 都在 CPU)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;gpu&#39;</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>  <span class="c1"># exception will be thrown</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">7</span><span class="n">d8d3d884488</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;gpu&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>  <span class="c1"># exception will be thrown</span>

<span class="ne">RuntimeError</span>: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, privateuseone device type at start of device string: gpu
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="torch-from-numpy-np-array-and-tensor-obj-clone-numpy">
<h3><span class="section-number">1.1.6. </span><code class="docutils literal notranslate"><span class="pre">torch.from_numpy(np_array)</span></code> and <code class="docutils literal notranslate"><span class="pre">tensor_obj.clone().numpy()</span></code><a class="headerlink" href="#torch-from-numpy-np-array-and-tensor-obj-clone-numpy" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>把 numpy 改成 tensor 的目的：</p>
<ul>
<li><p>可以放到 GPU 上加速</p></li>
<li><p>可以做 autograd.</p></li>
</ul>
</li>
<li><p>把 tensor 改成 numpy 的目的：</p>
<ul>
<li><p>做些中途的計算 &amp; 產出，但不會涉及到 gradient 紀錄.</p></li>
<li><p>特別小心，如果直接用 <code class="docutils literal notranslate"><span class="pre">tensor_obj.numpy()</span></code>，那他們是共享同個記憶體，是 mutable 的，所以改動 numpy 時，會影響到 tensor。所以才要先 clone() 再 numpy() (至於 detach 就不必要了，因為當你轉成 numpy 時，本來就不會有 gradient 紀錄了)</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">numpy_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>

<span class="n">pytorch_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">numpy_array</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pytorch_tensor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[1. 1. 1.]
 [1. 1. 1.]]
tensor([[1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>直接做 <code class="docutils literal notranslate"><span class="pre">tensor_obj.numpy()</span></code>，那會是 mutable，改一個，影響另一個：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pytorch_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pytorch_rand</span><span class="p">)</span>

<span class="n">numpy_rand</span> <span class="o">=</span> <span class="n">pytorch_rand</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.7552, 0.4874, 0.7107],
        [0.6109, 0.6544, 0.7272]])
[[0.7551676 0.4873578 0.7107467]
 [0.6108871 0.6544106 0.7271516]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numpy_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">23</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pytorch_tensor</span><span class="p">)</span>

<span class="n">pytorch_rand</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">17</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 1.,  1.,  1.],
        [ 1., 23.,  1.]], dtype=torch.float64)
[[ 0.7551676  0.4873578  0.7107467]
 [ 0.6108871 17.         0.7271516]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>但如果先 clone 再 .numpy，那就是不同記憶體了，彼此不影響：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pytorch_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pytorch_rand</span><span class="p">)</span>

<span class="n">numpy_rand</span> <span class="o">=</span> <span class="n">pytorch_rand</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.3561, 0.8712, 0.8384],
        [0.5608, 0.1938, 0.8030]])
[[0.3561455  0.87122315 0.83837247]
 [0.560761   0.19379157 0.80295706]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numpy_array</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">23</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pytorch_tensor</span><span class="p">)</span>

<span class="n">pytorch_rand</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">17</span>
<span class="nb">print</span><span class="p">(</span><span class="n">numpy_rand</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 1.,  1.,  1.],
        [ 1., 23.,  1.]], dtype=torch.float64)
[[0.3561455  0.87122315 0.83837247]
 [0.560761   0.19379157 0.80295706]]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3><span class="section-number">1.1.7. </span>常用數學計算<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">twos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">fours</span> <span class="o">=</span> <span class="n">twos</span> <span class="o">**</span> <span class="mi">2</span> <span class="c1"># 次方計算</span>
<span class="n">sqrt2s</span> <span class="o">=</span> <span class="n">twos</span> <span class="o">**</span> <span class="mf">0.5</span> <span class="c1"># 開根號</span>

<span class="nb">print</span><span class="p">(</span><span class="n">ones</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">twos</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">fours</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sqrt2s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1., 1.],
        [1., 1.]])
tensor([[2., 2.],
        [2., 2.]])
tensor([[3., 3.],
        [3., 3.]])
tensor([[4., 4.],
        [4., 4.]])
tensor([[1.4142, 1.4142],
        [1.4142, 1.4142]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># common functions</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Common functions:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Common functions:
tensor([[0.8304, 0.7952, 0.6749, 0.4929],
        [0.4727, 0.2614, 0.9301, 0.8193]])
tensor([[-0., -0., -0., -0.],
        [1., 1., -0., -0.]])
tensor([[-1., -1., -1., -1.],
        [ 0.,  0., -1., -1.]])
tensor([[-0.5000, -0.5000, -0.5000, -0.4929],
        [ 0.4727,  0.2614, -0.5000, -0.5000]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># trigonometric functions and their inverses</span>
<span class="n">angles</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">sines</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
<span class="n">inverses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">(</span><span class="n">sines</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Sine and arcsine:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">angles</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sines</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inverses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sine and arcsine:
tensor([0.0000, 0.7854, 1.5708, 2.3562])
tensor([0.0000, 0.7071, 1.0000, 0.7071])
tensor([0.0000, 0.7854, 1.5708, 0.7854])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># bitwise operations</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Bitwise XOR:&#39;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Bitwise XOR:
tensor([3, 2, 1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># comparisons:</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Broadcasted, element-wise equality comparison:&#39;</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># many comparison ops support broadcasting!</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span> <span class="c1"># returns a tensor of type bool</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Broadcasted, element-wise equality comparison:
tensor([[ True, False],
        [False, False]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># reductions:</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Reduction ops:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>        <span class="c1"># returns a single-element tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1"># extracts the value from the returned tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>       <span class="c1"># average</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>        <span class="c1"># standard deviation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>       <span class="c1"># product of all numbers</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])))</span> <span class="c1"># filter unique elements</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reduction ops:
tensor(4.)
4.0
tensor(2.5000)
tensor(1.2910)
tensor(24.)
tensor([1, 2])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># vector and linear algebra operations</span>
<span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>         <span class="c1"># x unit vector</span>
<span class="n">v2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>         <span class="c1"># y unit vector</span>
<span class="n">m1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>                   <span class="c1"># random matrix</span>
<span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]])</span> <span class="c1"># three times identity matrix</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Vectors &amp; Matrices:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">v2</span><span class="p">,</span> <span class="n">v1</span><span class="p">))</span> <span class="c1"># negative of z unit vector (v1 x v2 == -v2 x v1)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m1</span><span class="p">)</span>
<span class="n">m3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m3</span><span class="p">)</span>                  <span class="c1"># 3 times m1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">m3</span><span class="p">))</span>       <span class="c1"># singular value decomposition</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Vectors &amp; Matrices:
tensor([ 0.,  0., -1.])
tensor([[0.0685, 0.9392],
        [0.2532, 0.6231]])
tensor([[0.2055, 2.8177],
        [0.7597, 1.8692]])
torch.return_types.svd(
U=tensor([[-0.8183, -0.5748],
        [-0.5748,  0.8183]]),
S=tensor([3.4338, 0.5115]),
V=tensor([[-0.1762,  0.9844],
        [-0.9844, -0.1762]]))
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h2><span class="section-number">1.2. </span>自動微分<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="data-preparation">
<h2><span class="section-number">1.3. </span>Data preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dataset-class">
<h3><span class="section-number">1.3.1. </span>Dataset - 自訂 class<a class="headerlink" href="#dataset-class" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_matrix</span><span class="p">,</span> <span class="n">label_vector</span><span class="p">):</span>             <span class="c1"># 把資料存進 class object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_matrix</span> <span class="o">=</span> <span class="n">feature_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_vector</span> <span class="o">=</span> <span class="n">label_vector</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_matrix</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_vector</span><span class="p">)</span> <span class="c1"># 確定資料有互相對應</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_matrix</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>                     <span class="c1"># 定義我們需要取得某筆資料的方式</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_matrix</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_vector</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 測試看看</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 1000 張 100 x 100 單色圖片</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 1000 個 labels</span>

<span class="n">my_dataset</span> <span class="o">=</span> <span class="n">MyDataset</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">taken_x</span><span class="p">,</span> <span class="n">taken_y</span> <span class="o">=</span> <span class="n">my_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 取得第一筆資料</span>
<span class="n">taken_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">taken_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((100, 100, 1), (10,))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataset-tensordataset">
<h3><span class="section-number">1.3.2. </span>Dataset - 直接用 <code class="docutils literal notranslate"><span class="pre">TensorDataset</span></code><a class="headerlink" href="#dataset-tensordataset" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># 手上有的資料，先轉成 Tensor</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 1000 張 100 x 100 單色圖片</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 1000 個 labels</span>
<span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># 餵到 TensorDataset 裡面</span>
<span class="n">tsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 幾個重要的用法</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tsrdataset</span><span class="o">.</span><span class="fm">__len__</span><span class="p">())</span> <span class="c1"># 幾張圖</span>
<span class="n">taken_x</span><span class="p">,</span> <span class="n">taken_y</span> <span class="o">=</span> <span class="n">tsrdataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 取得第一筆資料</span>
<span class="nb">print</span><span class="p">(</span><span class="n">taken_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">taken_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1000
torch.Size([100, 100, 1]) torch.Size([10])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataloader">
<h3><span class="section-number">1.3.3. </span>DataLoader<a class="headerlink" href="#dataloader" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="c1"># 將 dataset 包裝成 dataloader</span>
<span class="n">my_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">my_dataset</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span> <span class="c1">#, </span>
    <span class="c1"># num_workers=4</span>
<span class="p">)</span>

<span class="c1"># 跑一個 loop 確認拿到的 batch 是否正確</span>
<span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">my_dataloader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">((</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataset">
<h3><span class="section-number">1.3.4. </span>內建 dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id3">
<h4><span class="section-number">1.3.4.1. </span>圖片類<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h4>
<div class="section" id="transform">
<h5><span class="section-number">1.3.4.1.1. </span>無 transform<a class="headerlink" href="#transform" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>

<span class="c1"># dataset</span>
<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>此時為 dataset 格式</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dataset FashionMNIST
    Number of datapoints: 60000
    Root location: data
    Split: Train
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>用 index 可以取資料</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 第 0 筆</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>x 會是 PIL 物件, y 是 lab</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PIL.Image.Image
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_89_0.png" src="../_images/pytorch_cheatsheet_89_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_90_0.png" src="../_images/pytorch_cheatsheet_90_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以把 x 轉成 numpy 看看：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_array</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_array</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_array</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(28, 28)
uint8
0
255
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以看到是 28x28 的圖，且是 uint8 type，介於 0~255 整數值</p></li>
</ul>
</div>
<div class="section" id="id4">
<h5><span class="section-number">1.3.4.1.2. </span>有 transform<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><p>圖片類資料庫，通常都會做以下 transform:</p>
<ul>
<li><p>把圖片改成 float32 浮點數 type.</p></li>
<li><p>把圖片正規化到 0~1 之間</p></li>
<li><p>轉成 tensor (灰階圖，會變成 (1,28,28), RGB圖仍是 (3, 28, 28))</p></li>
</ul>
</li>
<li><p>這其實就是 <code class="docutils literal notranslate"><span class="pre">torchvision.transforms.ToTensor()</span></code> 在做的事</p></li>
<li><p>看一下剛剛的例子</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="n">trans</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">x_trans</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x_trans</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_trans</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_trans</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_trans</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;PIL.Image.Image&#39;&gt;
uint8
&lt;class &#39;torch.Tensor&#39;&gt;
torch.float32
tensor(0.)
tensor(1.)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>讀檔時，就可以把這個放進去：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="n">trans</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>

<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">trans</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_train</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dataset FashionMNIST
    Number of datapoints: 60000
    Root location: data
    Split: Train
    StandardTransform
Transform: ToTensor()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([1, 28, 28])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 28, 28)
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="transforms">
<h2><span class="section-number">1.4. </span>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="nn-structures">
<h2><span class="section-number">1.5. </span>NN structures<a class="headerlink" href="#nn-structures" title="Permalink to this headline">¶</a></h2>
<div class="section" id="import">
<h3><span class="section-number">1.5.1. </span>import<a class="headerlink" href="#import" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>萬用起手式</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="activation-functions">
<h2><span class="section-number">1.6. </span>activation functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id5">
<h3><span class="section-number">1.6.1. </span>內建<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>activation function</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span> <span class="pre">as</span> <span class="pre">nn</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span> <span class="pre">as</span> <span class="pre">F</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>Sigmoid</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sigmoid()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.sigmoid</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Softmax</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Softmax(dim=None)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.softmax</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>ReLU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.relu</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>LeakyReLU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.LeakyReLU(negative_slope=0.01)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.leaky_relu</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Tanh</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Tanh()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.tanh</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>GELU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.GELU()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.gelu</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>ReLU6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU6()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.relu6</span></code></p></td>
</tr>
</tbody>
</table>
<div class="section" id="relu">
<h4><span class="section-number">1.6.1.1. </span>ReLU<a class="headerlink" href="#relu" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>主要重點：</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(ReLU(x) = max(x, 0)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{x}{dx} ReLU(x) = 1\)</span> if x &gt; 0; <span class="math notranslate nohighlight">\(\frac{x}{dx} ReLU(x) = 0\)</span> if x &lt;= 0</p></li>
<li><p>relu 的導數，在 x = 0 時，數學上是不存在，但在工程上 “定義” 導數為 0，這樣就能繼續做了</p></li>
<li><p>relu 的優點是求導的結果簡單，不是 0 就是 1，在 backward 更新參數時， <code class="docutils literal notranslate"><span class="pre">weight_new</span> <span class="pre">=</span> <span class="pre">weight_old</span> <span class="pre">-</span> <span class="pre">learning_rate</span> <span class="pre">*</span> <span class="pre">grad</span></code>，那 grad 不是 0 就是 1，減輕了以往NN的梯度消失問題。</p></li>
</ul>
</li>
<li><p>簡單範例：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,
        1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000, 1.8000,
        1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000,
        2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000,
        3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000, 4.5000,
        4.6000, 4.7000, 4.8000, 4.9000, 5.0000, 5.1000, 5.2000, 5.3000, 5.4000,
        5.5000, 5.6000, 5.7000, 5.8000, 5.9000, 6.0000, 6.1000, 6.2000, 6.3000,
        6.4000, 6.5000, 6.6000, 6.7000, 6.8000, 6.9000, 7.0000, 7.1000, 7.2000,
        7.3000, 7.4000, 7.5000, 7.6000, 7.7000, 7.8000, 7.9000],
       grad_fn=&lt;ReluBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">());</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_114_0.png" src="../_images/pytorch_cheatsheet_114_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">);</span> <span class="c1"># gradient</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_115_0.png" src="../_images/pytorch_cheatsheet_115_0.png" />
</div>
</div>
</div>
<div class="section" id="sigmoid">
<h4><span class="section-number">1.6.1.2. </span>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>主要重點：</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(sigmoid(x) = \frac{1}{1 + exp(-x)}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\frac{x}{dx} sigmoid(x) = sigmoid(x)(1-sigmoid(x))\)</span></p></li>
<li><p>從導數的性質，可以發現，gradient 在 x 靠近 0 時，值較大 (參數更新較快）， x 遠離 0 時， gradient 趨近於 0 (參數停止更新)</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">());</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_118_0.png" src="../_images/pytorch_cheatsheet_118_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># gradients</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/pytorch_cheatsheet_119_0.png" src="../_images/pytorch_cheatsheet_119_0.png" />
</div>
</div>
</div>
</div>
<div class="section" id="id6">
<h3><span class="section-number">1.6.2. </span>自訂<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>直接定義一個 function</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># shape 會與 x 一樣</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="custom-layers-block">
<h2><span class="section-number">1.7. </span>custom layers &amp; block<a class="headerlink" href="#custom-layers-block" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>幾個名詞定義一下：</p>
<ul>
<li><p>layer: 只要是 input n 個 neruon, output m 個 neuron 的 function，就被稱為一個 layer。例如 <code class="docutils literal notranslate"><span class="pre">nn.Linear(in_dim,</span> <span class="pre">out_dim)</span></code> 就是個 linear layer.</p></li>
<li><p>block:</p>
<ul>
<li><p>多個 layer 組合在一起，稱為一個 block。例如一個 VGG block，就是由數個 conv, pooling layer 所組成.</p></li>
<li><p>通常用 sequential 來把 layer 組成 block; 或用 sub-class 來把 layer 組成 block</p></li>
</ul>
</li>
<li><p>model:</p>
<ul>
<li><p>由 layers or/and blocks 組起來，只要 input 是 feature/images/sentences..，output 是 回歸/分類…結果，就都可稱為 model。</p></li>
<li><p>例如一個 linear layer 可以是 model (e.g. linear regression)，一個 block 可以是 model (e.g. 多層感知機)，多個 block 組在一起 (e.g. resnet) 也可以是 model</p></li>
<li><p>所以，可以用 <code class="docutils literal notranslate"><span class="pre">layer</span></code> 來做出 model，也可以用 <code class="docutils literal notranslate"><span class="pre">sequential</span></code> 組成 model，也可以用 <code class="docutils literal notranslate"><span class="pre">sub-class</span></code> 組成 model</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="section" id="custom-layer">
<h3><span class="section-number">1.7.1. </span>custom layer (不帶參數)<a class="headerlink" href="#custom-layer" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CenteredLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;用來做中心化(去平均)的layer</span>
<span class="sd">    args:</span>
<span class="sd">      X: 任何 shape，但通常是 (n, p)，然後我們想把 feature 都 de-mean</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 做 5 個 sample，每個 sample 都有 2 個 feature 的 X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.9273,  0.1359],
        [-1.1151, -1.3790],
        [-0.5349, -4.1247],
        [-1.9496,  0.5590],
        [-1.4850,  1.3104]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">CenteredLayer</span><span class="p">()</span>
<span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.5316,  0.5316],
        [ 0.1319, -0.1319],
        [ 1.7949, -1.7949],
        [-1.2543,  1.2543],
        [-1.3977,  1.3977]])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以清楚看到，de-mean 後，每個 row 現在相加都是 0</p></li>
</ul>
<ul class="simple">
<li><p>之後，這種 layer 就可以當作前處理，然後這樣用：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">CenteredLayer</span><span class="p">(),</span> <span class="c1"># 前處理用，de-mean</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># linear regression</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.8472],
        [ 0.4268],
        [-0.6269],
        [ 1.3052],
        [ 1.3961]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h3><span class="section-number">1.7.2. </span>custom layer (帶參數)<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>重點在，weight, bias 要用 <code class="docutils literal notranslate"><span class="pre">nn.Parameter()</span></code> 來造，這樣就可以保有計算 gradient 等功能(預設 requires_grad = True)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">?</span> nn.Parameter
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Red">Init signature:</span>  nn<span class=" -Color -Color-Blue">.</span>Parameter<span class=" -Color -Color-Blue">(</span>data<span class=" -Color -Color-Blue">=</span><span class=" -Color -Color-Green">None</span><span class=" -Color -Color-Blue">,</span> requires_grad<span class=" -Color -Color-Blue">=</span><span class=" -Color -Color-Green">True</span><span class=" -Color -Color-Blue">)</span>
<span class=" -Color -Color-Red">Docstring:</span>     
A kind of Tensor that is to be considered a module parameter.

Parameters are :class:`~torch.Tensor` subclasses, that have a
very special property when used with :class:`Module` s - when they&#39;re
assigned as Module attributes they are automatically added to the list of
its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.
Assigning a Tensor doesn&#39;t have such effect. This is because one might
want to cache some temporary state, like last hidden state of the RNN, in
the model. If there was no such class as :class:`Parameter`, these
temporaries would get registered too.

Args:
    data (Tensor): parameter tensor.
    requires_grad (bool, optional): if the parameter requires gradient. See
        :ref:`locally-disable-grad-doc` for more details. Default: `True`
<span class=" -Color -Color-Red">File:</span>           ~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/parameter.py
<span class=" -Color -Color-Red">Type:</span>           _ParameterMeta
<span class=" -Color -Color-Red">Subclasses:</span>     UninitializedParameter
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; 自己寫一個 dense 層 &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,))</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
        <span class="k">return</span> <span class="n">linear</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>看一下實例化後，起始參數：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear</span> <span class="o">=</span> <span class="n">MyLinear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([[-0.3640,  1.5913,  0.4055],
        [-1.0218,  0.4775, -1.1235],
        [-1.7111,  0.8637, -0.4625],
        [-0.5543, -0.6704, -0.0141],
        [-1.1417,  0.6179,  0.6895]], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>用用看：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">linear</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-3.2610, -0.1284, -1.8087],
        [ 0.6928,  1.0955, -1.3039],
        [-3.6307,  2.3802, -0.8923],
        [-1.7597,  1.9472, -0.6151],
        [-2.2773,  0.8810, -1.5115],
        [-0.4681,  1.1092,  1.5497],
        [-1.9127,  1.2226, -0.9216],
        [-2.4812,  1.8624,  0.1789],
        [-0.7259,  1.6919,  1.7905],
        [-0.0247, -1.7735, -0.9420]])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sequential-block-nn-sequential-layer1-block2">
<h3><span class="section-number">1.7.3. </span>sequential block (<code class="docutils literal notranslate"><span class="pre">nn.Sequential(layer1,</span> <span class="pre">block2,</span> <span class="pre">...)</span></code>)<a class="headerlink" href="#sequential-block-nn-sequential-layer1-block2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-1.0751e-01, -1.2425e-01,  1.4933e-01,  7.5487e-02,  2.6889e-01,
         -2.4903e-01,  3.5666e-05, -7.2805e-02,  2.4102e-02, -7.0524e-02],
        [-1.1472e-01, -4.5277e-02,  1.8385e-01, -1.1014e-01,  3.0093e-01,
         -2.1793e-01, -7.2202e-02, -1.2279e-01,  1.7267e-01, -3.3422e-02]],
       grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="sequential-for-tips">
<h3><span class="section-number">1.7.4. </span>sequential <code class="docutils literal notranslate"><span class="pre">for</span></code> tips<a class="headerlink" href="#sequential-for-tips" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>我們可以建立一個自己的 sequential，就可以看到實際運作狀況：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
            <span class="c1"># args 就是 user 隨意要丟幾個 layer, block 進來，所組成的 list</span>
            <span class="c1"># 变量_modules中。_module的类型是OrderedDict</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">module</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># OrderedDict保证了按照成员添加的顺序遍历它们</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>來試試看：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">MySequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.3512,  0.0382, -0.0272, -0.0299,  0.1932, -0.0300,  0.0591,  0.0224,
          0.0579,  0.1903],
        [ 0.3129,  0.1721,  0.1292,  0.0103,  0.2904,  0.1143, -0.0841, -0.1001,
          0.2664,  0.1742]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="custom-block">
<h3><span class="section-number">1.7.5. </span>custom block<a class="headerlink" href="#custom-block" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>雖然 sequential block 很方便，但有時我們會需要在 forward 的時候，做一些靈活的控制，例如以下這個刻意做出來的例子：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># 這邊開始是 flexible 的設計, 這就是 sequential 辦不到的</span>
        <span class="c1"># 我希望控制輸出，當輸出的 tensor 的 L1 norm &gt; 1 時，我就把他除以2，直到輸出的 L1 norm 壓在 1 以內</span>
        <span class="k">while</span> <span class="n">X</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">/=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>來試一下：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.0155, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id8">
<h2><span class="section-number">1.8. </span>參數管理<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>假設 model 長這樣：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># fake data: batch_size = 2</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>

<span class="c1"># one-epoch training</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>        <span class="c1"># 把 x tensor 移到 GPU 計算</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> <span class="c1"># 把 y tensor 移到 GPU 計算，</span>
                                      <span class="c1">##  y_hat 因為是從 GPU model input GPU Tensor 出來的</span>
                                      <span class="c1">##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||</span>
<span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># 把 trainable variable/weights/parameters 的 gradient 給 歸 0</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># 利用 loss，計算出每個 trainable variable/weights/parameters 所對應的 gradient</span>
<span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 更新 trainable variable/weights/parameters 的值： parameters_new = parameters_old - learning_rate * gradient</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.0542],
        [-0.1957]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-structure">
<h3><span class="section-number">1.8.1. </span>看 model structure<a class="headerlink" href="#model-structure" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Linear(in_features=4, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以看到，他用 index 來表明每一層的 layer</p></li>
</ul>
</div>
<div class="section" id="weight-bias-gradient">
<h3><span class="section-number">1.8.2. </span>看單一層的 weight, bias, gradient<a class="headerlink" href="#weight-bias-gradient" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>例如，看第 0 個 index 的 參數：</p></li>
</ul>
<div class="section" id="state-dict">
<h4><span class="section-number">1.8.2.1. </span><code class="docutils literal notranslate"><span class="pre">.state_dict()</span></code><a class="headerlink" href="#state-dict" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;weight&#39;,
              tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
                      [ 0.3939, -0.3583, -0.3972,  0.4755],
                      [-0.1534, -0.2841,  0.3249, -0.2912],
                      [ 0.1784,  0.4749, -0.1225,  0.1678],
                      [ 0.2339,  0.4488, -0.2803,  0.1215],
                      [ 0.3486,  0.4914,  0.0383, -0.4629],
                      [-0.1031, -0.1659, -0.3799,  0.4556],
                      [ 0.1895,  0.3306,  0.0714,  0.4956]])),
             (&#39;bias&#39;,
              tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021]))])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>所以，要取得 weight 或 bias 的資料可以這樣拿：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s1">&#39;weight&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
        [ 0.3939, -0.3583, -0.3972,  0.4755],
        [-0.1534, -0.2841,  0.3249, -0.2912],
        [ 0.1784,  0.4749, -0.1225,  0.1678],
        [ 0.2339,  0.4488, -0.2803,  0.1215],
        [ 0.3486,  0.4914,  0.0383, -0.4629],
        [-0.1031, -0.1659, -0.3799,  0.4556],
        [ 0.1895,  0.3306,  0.0714,  0.4956]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="s1">&#39;bias&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="weight-weight-data-weight-grad">
<h4><span class="section-number">1.8.2.2. </span><code class="docutils literal notranslate"><span class="pre">.weight</span></code>, <code class="docutils literal notranslate"><span class="pre">.weight.data</span></code>, <code class="docutils literal notranslate"><span class="pre">.weight.grad</span></code><a class="headerlink" href="#weight-weight-data-weight-grad" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>除了這種做法外，也可以用 <code class="docutils literal notranslate"><span class="pre">.weight</span></code> 取得 weight 物件，再往下去取得 data 和 gradient 資訊：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span> <span class="c1"># 這是物件</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
        [ 0.3939, -0.3583, -0.3972,  0.4755],
        [-0.1534, -0.2841,  0.3249, -0.2912],
        [ 0.1784,  0.4749, -0.1225,  0.1678],
        [ 0.2339,  0.4488, -0.2803,  0.1215],
        [ 0.3486,  0.4914,  0.0383, -0.4629],
        [-0.1031, -0.1659, -0.3799,  0.4556],
        [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)
&lt;class &#39;torch.nn.parameter.Parameter&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 取這個物件，底下的 data (i.e. value)</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
        [ 0.3939, -0.3583, -0.3972,  0.4755],
        [-0.1534, -0.2841,  0.3249, -0.2912],
        [ 0.1784,  0.4749, -0.1225,  0.1678],
        [ 0.2339,  0.4488, -0.2803,  0.1215],
        [ 0.3486,  0.4914,  0.0383, -0.4629],
        [-0.1031, -0.1659, -0.3799,  0.4556],
        [ 0.1895,  0.3306,  0.0714,  0.4956]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># gradient</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.1611,  0.1510,  0.1755,  0.1280],
        [-0.2097, -0.1966, -0.2285, -0.1666],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0678,  0.0636,  0.0739,  0.0539],
        [ 0.0354,  0.0331,  0.0385,  0.0281],
        [ 0.0608,  0.0955,  0.0774,  0.0291],
        [ 0.1630,  0.1528,  0.1776,  0.1295],
        [ 0.1269,  0.1189,  0.1383,  0.1008]])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bias-bias-data-bias-grad">
<h4><span class="section-number">1.8.2.3. </span><code class="docutils literal notranslate"><span class="pre">.bias</span></code>, <code class="docutils literal notranslate"><span class="pre">.bias.data</span></code>, <code class="docutils literal notranslate"><span class="pre">.bias.grad</span></code><a class="headerlink" href="#bias-bias-data-bias-grad" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],
       requires_grad=True)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([ 0.2477, -0.3225,  0.0000,  0.1043,  0.0544,  0.0989,  0.2507,  0.1951])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="parameters">
<h4><span class="section-number">1.8.2.4. </span><code class="docutils literal notranslate"><span class="pre">.parameters()</span></code><a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>也可以用 <code class="docutils literal notranslate"><span class="pre">.parameters</span></code>，出來的會是物件：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;generator object Module.parameters at 0x13e20ee40&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parameter containing:
 tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
         [ 0.3939, -0.3583, -0.3972,  0.4755],
         [-0.1534, -0.2841,  0.3249, -0.2912],
         [ 0.1784,  0.4749, -0.1225,  0.1678],
         [ 0.2339,  0.4488, -0.2803,  0.1215],
         [ 0.3486,  0.4914,  0.0383, -0.4629],
         [-0.1031, -0.1659, -0.3799,  0.4556],
         [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True),
 Parameter containing:
 tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],
        requires_grad=True)]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以看到，list 裡面的第一個 element，很明顯是 weight, 第二個 element，很明顯是 bias，兩個都是物件，所以真的要取資料時，可以這樣取：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
        [ 0.3939, -0.3583, -0.3972,  0.4755],
        [-0.1534, -0.2841,  0.3249, -0.2912],
        [ 0.1784,  0.4749, -0.1225,  0.1678],
        [ 0.2339,  0.4488, -0.2803,  0.1215],
        [ 0.3486,  0.4914,  0.0383, -0.4629],
        [-0.1031, -0.1659, -0.3799,  0.4556],
        [ 0.1895,  0.3306,  0.0714,  0.4956]])
tensor([[ 0.1611,  0.1510,  0.1755,  0.1280],
        [-0.2097, -0.1966, -0.2285, -0.1666],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0678,  0.0636,  0.0739,  0.0539],
        [ 0.0354,  0.0331,  0.0385,  0.0281],
        [ 0.0608,  0.0955,  0.0774,  0.0291],
        [ 0.1630,  0.1528,  0.1776,  0.1295],
        [ 0.1269,  0.1189,  0.1383,  0.1008]])
1
tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])
tensor([ 0.2477, -0.3225,  0.0000,  0.1043,  0.0544,  0.0989,  0.2507,  0.1951])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="named-parameters">
<h4><span class="section-number">1.8.2.5. </span><code class="docutils literal notranslate"><span class="pre">.named_parameters</span></code><a class="headerlink" href="#named-parameters" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;weight&#39;,
  Parameter containing:
  tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
          [ 0.3939, -0.3583, -0.3972,  0.4755],
          [-0.1534, -0.2841,  0.3249, -0.2912],
          [ 0.1784,  0.4749, -0.1225,  0.1678],
          [ 0.2339,  0.4488, -0.2803,  0.1215],
          [ 0.3486,  0.4914,  0.0383, -0.4629],
          [-0.1031, -0.1659, -0.3799,  0.4556],
          [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)),
 (&#39;bias&#39;,
  Parameter containing:
  tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],
         requires_grad=True))]
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="parameters-weight-bias-gradient">
<h3><span class="section-number">1.8.3. </span>看所有的 parameters, weight, bias, gradient<a class="headerlink" href="#parameters-weight-bias-gradient" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>有了前面的練習，應該就不難理解一次看全部的結果：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Linear(in_features=4, out_features=8, bias=True)
  (1): ReLU()
  (2): Linear(in_features=8, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OrderedDict([(&#39;0.weight&#39;,
              tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
                      [ 0.3939, -0.3583, -0.3972,  0.4755],
                      [-0.1534, -0.2841,  0.3249, -0.2912],
                      [ 0.1784,  0.4749, -0.1225,  0.1678],
                      [ 0.2339,  0.4488, -0.2803,  0.1215],
                      [ 0.3486,  0.4914,  0.0383, -0.4629],
                      [-0.1031, -0.1659, -0.3799,  0.4556],
                      [ 0.1895,  0.3306,  0.0714,  0.4956]])),
             (&#39;0.bias&#39;,
              tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])),
             (&#39;2.weight&#39;,
              tensor([[-0.2377,  0.3098, -0.2583, -0.1001, -0.0521, -0.1530, -0.2406, -0.1873]])),
             (&#39;2.bias&#39;, tensor([0.1550]))])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以看到 weight 和 bias 前面，有加上 index (i.e. 0 和 2)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;generator object Module.named_parameters at 0x13c52fe40&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(&#39;0.weight&#39;,
  Parameter containing:
  tensor([[-0.3048,  0.2219,  0.2388,  0.3435],
          [ 0.3939, -0.3583, -0.3972,  0.4755],
          [-0.1534, -0.2841,  0.3249, -0.2912],
          [ 0.1784,  0.4749, -0.1225,  0.1678],
          [ 0.2339,  0.4488, -0.2803,  0.1215],
          [ 0.3486,  0.4914,  0.0383, -0.4629],
          [-0.1031, -0.1659, -0.3799,  0.4556],
          [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)),
 (&#39;0.bias&#39;,
  Parameter containing:
  tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],
         requires_grad=True)),
 (&#39;2.weight&#39;,
  Parameter containing:
  tensor([[-0.2377,  0.3098, -0.2583, -0.1001, -0.0521, -0.1530, -0.2406, -0.1873]],
         requires_grad=True)),
 (&#39;2.bias&#39;,
  Parameter containing:
  tensor([0.1550], requires_grad=True))]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="block-factory">
<h3><span class="section-number">1.8.4. </span>block factory<a class="headerlink" href="#block-factory" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>如果我們把 block 給 nested 在一起，那要如何做參數管理？</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">block1</span><span class="p">():</span>
    
    <span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> 
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">out</span> 

<span class="k">def</span> <span class="nf">block2</span><span class="p">():</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="c1"># 在這裡 nested</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;block </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">block1</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">net</span>

<span class="n">rgnet</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">block2</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">rgnet</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.4301],
        [-0.4301]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">rgnet</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sequential(
  (0): Sequential(
    (block 0): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 1): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 2): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
    (block 3): Sequential(
      (0): Linear(in_features=4, out_features=8, bias=True)
      (1): ReLU()
      (2): Linear(in_features=8, out_features=4, bias=True)
      (3): ReLU()
    )
  )
  (1): Linear(in_features=4, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>那要取資訊時，就是一層一層往下取就好：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rgnet</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([ 0.3477,  0.0886,  0.2932,  0.3275, -0.1417,  0.2814,  0.1715, -0.3397])
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id9">
<h2><span class="section-number">1.9. </span>參數初始化<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>知道如何訪問參數後，現在來講如何初始化參數.</p></li>
<li><p>這要用到 pytorch 的 <code class="docutils literal notranslate"><span class="pre">nn.init</span></code> module 提供的多種方法</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># weight 和 bias 的初始值都設為 N(0, 0.01) 的 init</span>
<span class="k">def</span> <span class="nf">init_normal</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

        
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_normal</span><span class="p">)</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[ 0.0105,  0.0073, -0.0162,  0.0021],
         [-0.0090, -0.0050, -0.0081,  0.0137],
         [-0.0094,  0.0131, -0.0050, -0.0125],
         [-0.0123, -0.0004, -0.0149,  0.0064],
         [ 0.0014,  0.0075, -0.0244,  0.0135],
         [ 0.0065, -0.0017, -0.0205,  0.0050],
         [ 0.0271,  0.0054,  0.0010,  0.0047],
         [ 0.0182,  0.0035,  0.0027, -0.0007]]),
 tensor([ 0.0125, -0.3895, -0.2890, -0.0959, -0.4549, -0.3239,  0.0046,  0.3682]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># weight 的 初始值都設為 1, bias 都設為 0</span>
<span class="k">def</span> <span class="nf">init_constant</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_constant</span><span class="p">)</span>

<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.],
         [1., 1., 1., 1.]]),
 tensor([0., 0., 0., 0., 0., 0., 0., 0.]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># xavier</span>
<span class="k">def</span> <span class="nf">init_xavier</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_xavier</span><span class="p">)</span>

<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(tensor([[ 0.6934,  0.4680, -0.3913,  0.0849],
         [ 0.1309,  0.5539, -0.4249, -0.5450],
         [-0.1842, -0.2299, -0.4047,  0.2514],
         [-0.6546,  0.4458, -0.6788, -0.1312],
         [-0.1920,  0.0308,  0.1797, -0.3841],
         [ 0.6221, -0.3523,  0.5078, -0.3886],
         [-0.3136,  0.3043, -0.3935,  0.2180],
         [ 0.5874, -0.5117, -0.5833,  0.0361]]),
 tensor([0., 0., 0., 0., 0., 0., 0., 0.]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 自訂義初始化</span>
<span class="c1"># weight 有 1/4 的可能性，來自 U(5, 10), 1/4 可能性來自 U(-10, -5), 1/2 可能性是 0</span>

<span class="k">def</span> <span class="nf">my_init</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Init&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">*=</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">5</span>

<span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">my_init</span><span class="p">)</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Init weight torch.Size([8, 4])
Init weight torch.Size([1, 8])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Parameter containing:
tensor([[ 7.3381, -6.7319, -5.7735,  8.2337],
        [ 9.4036, -8.0004, -5.2134,  0.0000],
        [ 0.0000, -8.1653, -5.6182, -0.0000],
        [-0.0000,  0.0000,  5.3923, -0.0000],
        [ 0.0000, -0.0000,  9.4830, -0.0000],
        [ 0.0000,  0.0000,  5.3328,  9.0293],
        [-0.0000, -5.9543,  5.0917, -0.0000],
        [ 0.0000, -9.4781,  0.0000, -0.0000]], requires_grad=True)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>我們也可以自己設定參數</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([42.0000, -5.7319, -4.7735,  9.2337])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="classical-layers">
<h2><span class="section-number">1.10. </span>Classical Layers<a class="headerlink" href="#classical-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nn">
<h3><span class="section-number">1.10.1. </span>NN<a class="headerlink" href="#nn" title="Permalink to this headline">¶</a></h3>
<div class="section" id="nn-linear-in-dim-out-dim">
<h4><span class="section-number">1.10.1.1. </span><code class="docutils literal notranslate"><span class="pre">nn.Linear(in_dim,</span> <span class="pre">out_dim)</span></code><a class="headerlink" href="#nn-linear-in-dim-out-dim" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="cnn">
<h3><span class="section-number">1.10.2. </span>CNN<a class="headerlink" href="#cnn" title="Permalink to this headline">¶</a></h3>
<div class="section" id="convolution">
<h4><span class="section-number">1.10.2.1. </span>convolution<a class="headerlink" href="#convolution" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>2d convolution: <code class="docutils literal notranslate"><span class="pre">nn.Conv2d(in_channels,</span> <span class="pre">out_channels,</span> <span class="pre">kernel_size,</span> <span class="pre">stride=1,</span> <span class="pre">padding=0)</span></code></p></li>
<li><p>1d convolution</p></li>
</ul>
</div>
<div class="section" id="pooling">
<h4><span class="section-number">1.10.2.2. </span>pooling<a class="headerlink" href="#pooling" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>maximum pooling:  <code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d(kernel_size,</span> <span class="pre">stride=None,</span> <span class="pre">padding=0,</span> <span class="pre">dilation=1)</span></code></p></li>
<li><p>average pooling:</p></li>
<li><p>global maximum pooling:</p></li>
<li><p>global average pooling:</p></li>
</ul>
</div>
<div class="section" id="vgg">
<h4><span class="section-number">1.10.2.3. </span>VGG<a class="headerlink" href="#vgg" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="resnet">
<h4><span class="section-number">1.10.2.4. </span>ResNet<a class="headerlink" href="#resnet" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="rnn">
<h3><span class="section-number">1.10.3. </span>RNN<a class="headerlink" href="#rnn" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="loss">
<h2><span class="section-number">1.11. </span>Loss<a class="headerlink" href="#loss" title="Permalink to this headline">¶</a></h2>
<div class="section" id="overview">
<h3><span class="section-number">1.11.1. </span>overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>官網連結: <a class="reference external" href="https://pytorch.org/docs/stable/nn.html#loss-functions">https://pytorch.org/docs/stable/nn.html#loss-functions</a></p></li>
<li><p>常用的整理：</p></li>
</ul>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>loss function</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span> <span class="pre">as</span> <span class="pre">nn</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span> <span class="pre">as</span> <span class="pre">F</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>Binary cross entropy</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.BCELoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.binary_cross_entropy</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Binary cross entropy with logits</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.BCEWithLogitsLoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.binary_cross_entropy_with_logits</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>categorical cross entropy</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.CrossEntropyLoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.relu</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>mse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.MSELoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.leaky_relu</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>mae</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.L1Loss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.tanh</span></code></p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p>概念講一下：</p>
<ul>
<li><p>loss 在統計的定義，是對 “單一” sample 算 loss，例如 square error loss = <span class="math notranslate nohighlight">\((y_i - \hat{y_i})^2\)</span></p></li>
<li><p>然後 mse 是 cost，不是 loss，所以 mse cost = <span class="math notranslate nohighlight">\(\frac{1}{n}\sum_{i=1}^n (y_i - \hat{y_i})^2\)</span></p></li>
<li><p>但在 pytorch/tensorflow 中，這兩個已經被混用了，都叫做 loss.</p></li>
<li><p>至於，如何區別這兩者呢？靠 class/function 中的參數定義來決定。</p></li>
<li><p>例如： <code class="docutils literal notranslate"><span class="pre">my_mse</span> <span class="pre">=</span> <span class="pre">nn.MSELoss()</span></code>, 然後 <code class="docutils literal notranslate"><span class="pre">my_mse(y_hat_vector,</span> <span class="pre">y_true_vector)</span></code>，算出來的就是 mse cost.</p></li>
<li><p>但如果 <code class="docutils literal notranslate"><span class="pre">my_mse</span> <span class="pre">=</span> <span class="pre">nn.MSELoss(reduction</span> <span class="pre">=</span> <span class="pre">'none')</span></code>, 然後 <code class="docutils literal notranslate"><span class="pre">my_mse(y_hat_vector,</span> <span class="pre">y_true_vector)</span></code>，算出來的是 n 維的 mse loss</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>y 不一定要是向量，可以是矩陣或陣列：</p>
<ul>
<li><p>在統計上，學 loss 或 cost，都是從回歸的角度去學的，也就 向量 vs 向量， e.g. y = 100 維向量(100個sample)，y_hat 也是 100 維，那就可以算出 1 個 cost 和 100 個 loss.</p></li>
<li><p>但在 deep learning 裡面，y不一定是向量，y可以是矩陣，甚至多維陣列。</p></li>
<li><p>例如做 autoencoder 時</p>
<ul>
<li><p>y就是矩陣，比如 100 張圖片，每張圖片都是 8x8 的矩陣，那 y 可以定義成 (100, 8x8) 的 矩陣，(把圖片拉成 8x8 的向量)。</p></li>
<li><p>y_hat 是這些影像 reconstruct 後的結果，所以也是 100 x 64 的矩陣。</p></li>
<li><p>那我照樣用剛剛定義好的 loss function，我就可以算出 1 個 cost 和 100x8x8 = 6400 個 loss。</p></li>
<li><p>所以關鍵在：他都是 <code class="docutils literal notranslate"><span class="pre">by</span> <span class="pre">element</span></code> 算 loss, 然後紀錄有多少 <code class="docutils literal notranslate"><span class="pre">個數</span></code>, 最後再用 <code class="docutils literal notranslate"><span class="pre">sum</span></code> 或 <code class="docutils literal notranslate"><span class="pre">mean</span></code> 回給你一個 cost。</p></li>
<li><p>這樣，就不需要管 y 的 shape 了。</p></li>
<li><p>例如：我這次不要把 8x8 拉成向量，所以 y 就是 (100, 8, 8) 的 array，那也無所謂，放入我的 loss function，他就可以算出 6400 個 loss，然後依照你的 reduction 的設定 (none or sum or mean)，回給你 6400 個 loss 或是 1 個 cost</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>batch loss 是拿來更新參數用的， epoch loss 是用來檢查有無 overfitting 的</p>
<ul>
<li><p>deep learning 在 training or testing 時，都是一個 batch 一個 batch 做，最後再整合成一個 epoch</p></li>
<li><p>每個 batch 在做的時候，都要算這個 batch 的 cost，他的目的是用來更 gradient 時，要對這個 cost 做偏微分。所以每個 batch 結束，會得到一個 cost</p></li>
<li><p>每個 epoch 結束，要算的 cost 是跨所有樣本的。他的目的，是要去比較 training sample 的 cost 和 validation sample 的 cost，來判斷是否 overfitting 了，要不要做 early stop</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>epoch loss 的算法設計.</p>
<ul>
<li><p>最常見的設計，是直接拿 batch cost 的結果來 summarise，因位省時省力：</p>
<ul>
<li><p>舉例來說，我有 10 個 batch，每個 batch 有 32 個 batch size.</p></li>
<li><p>每個 batch 結束時，其實都拿到該 batch 的 1 個 cost 或 32 個 loss.</p></li>
<li><p>那算 epoch cost 時，我就可以把 10 個 batch cost 取平均，或是 10x32 = 320 個 loss 取平均，就得到 epoch cost。</p></li>
<li><p>pseudo code 就是</p>
<ul>
<li><p>先定義 <code class="docutils literal notranslate"><span class="pre">epoch_cost</span> <span class="pre">=</span> <span class="pre">0</span></code></p></li>
<li><p>然後 for 迴圈去 loop 10 個 batch</p></li>
<li><p>每次 batch 結束，就讓 <code class="docutils literal notranslate"><span class="pre">epoch_cost</span> <span class="pre">+=</span> <span class="pre">batch_cost</span></code>.</p></li>
<li><p>迴圈結束後，用 epoch_cost / 10，得到 mean cost。</p></li>
<li><p>如果要用 loss 的寫法也很簡單。最外面就是定義 <code class="docutils literal notranslate"><span class="pre">loss_list</span> <span class="pre">=</span> <span class="pre">[]</span></code>，然後每個回圈都是算出 batch_size 個 epoch_loss，然後 <code class="docutils literal notranslate"><span class="pre">loss_list.append(epoch_loss)</span></code>，最終再對 loss_list 取平均就好。</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="mse">
<h3><span class="section-number">1.11.2. </span>mse<a class="headerlink" href="#mse" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-1.6104,  0.4109,  1.3322,  1.2199, -0.6273], requires_grad=True)
tensor([ 0.7016, -1.6683,  1.0668,  0.9080, -1.2761])
</pre></div>
</div>
</div>
</div>
<div class="section" id="class">
<h4><span class="section-number">1.11.2.1. </span>class 版本<a class="headerlink" href="#class" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 算 loss</span>
<span class="n">my_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">my_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([5.3454, 4.3230, 0.0705, 0.0973, 0.4209], grad_fn=&lt;MseLossBackward&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 算 cost (i.e mean loss)</span>
<span class="n">my_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">my_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(2.0514, grad_fn=&lt;MseLossBackward&gt;)
tensor(2.0514, grad_fn=&lt;MeanBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 算 cost (i.e sum loss)</span>
<span class="n">my_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;sum&quot;</span><span class="p">)</span>
<span class="n">sum_cost</span> <span class="o">=</span> <span class="n">my_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sum_cost</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(10.2571, grad_fn=&lt;MseLossBackward&gt;)
tensor(10.2571, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="function">
<h4><span class="section-number">1.11.2.2. </span>function 版本<a class="headerlink" href="#function" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 用 function 做 cost</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_true</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-0.7780, -0.4672, -1.0941, -1.0928, -1.0654], requires_grad=True)
tensor([ 0.5094, -0.6637, -0.5560, -0.5600, -1.6072])
tensor(0.5126, grad_fn=&lt;MseLossBackward&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 用 function 做 loss</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([-0.9525,  0.9356, -0.1469, -0.3822,  2.0675], requires_grad=True)
tensor([-0.3021, -0.6323, -1.2846, -0.1762, -0.0629])
tensor([0.4230, 2.4583, 1.2943, 0.0424, 4.5388], grad_fn=&lt;MseLossBackward&gt;)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="mae">
<h3><span class="section-number">1.11.3. </span>mae<a class="headerlink" href="#mae" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="binary-cross-entropy">
<h3><span class="section-number">1.11.4. </span>binary cross entropy<a class="headerlink" href="#binary-cross-entropy" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_logit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.3552</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9071</span><span class="p">,</span>  <span class="mf">2.8323</span><span class="p">])</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.9133</span><span class="p">,</span> <span class="mf">0.2876</span><span class="p">,</span> <span class="mf">0.9444</span><span class="p">])</span> <span class="c1"># 就是 F.sigmoid(y_logit) 後的結果</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>y 是 vector/matrix/array 都可 (常見是 vector，element 個數就是樣本數)，值不是 0 就是 1。 e.g. [0, 1, 0] 表示三個樣本的真值。</p></li>
<li><p>y_hat 的 shape 同 y，值介於 0~1 之間。e.g. [0.3, 0.8, 0.1]，表示三個樣本的預測值。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">binary</span> <span class="pre">cross</span> <span class="pre">entropy</span></code>： <span class="math notranslate nohighlight">\(-\frac{1}{n}\sum_{i = 1}^{n}\left[ y_i log(\hat{y_i}) + (1-y_i)(1-log(\hat{y_i})\right]\)</span></p></li>
<li><p>這在這個定義式的中間這項就是 loss： <span class="math notranslate nohighlight">\(y_i log(\hat{y_i}) + (1-y_i)(1-log(\hat{y_i})\)</span> 。可用 <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">&quot;none&quot;</span></code> 來設定，就可拿到 n 個 loss</p></li>
<li><p>那算 cost，可以像定義式那樣，用平均來做，可用 <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">&quot;mean&quot;</span></code> 來設定。不寫也可，預設就是取 mean</p></li>
</ul>
<div class="section" id="id10">
<h4><span class="section-number">1.11.4.1. </span>class 版本<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss 版</span>
<span class="n">my_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">(</span><span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">my_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([2.4453, 0.3391, 2.8896])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># cost 版</span>
<span class="n">my_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">my_loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(1.8913)
tensor(1.8913)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id11">
<h4><span class="section-number">1.11.4.2. </span>function 版<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loss 版</span>
<span class="nb">print</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">))</span>

<span class="c1"># cost 版</span>
<span class="nb">print</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([2.4453, 0.3391, 2.8896])
tensor(1.8913)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 自己照定義算</span>
<span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_hat</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(1.8913)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>事實上，y和y_hat可以是任何shape，他都會幫你 by element 的去做 <span class="math notranslate nohighlight">\( y_i log(\hat{y_i}) + (1-y_i)(1-log(\hat{y_i})\)</span>，然後最後取總平均</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.2420, 0.5219, 0.5408, 0.7095, 0.1231],
        [0.3518, 0.2747, 0.9089, 0.8097, 0.4674],
        [0.2304, 0.0615, 0.1389, 0.2419, 0.7572]])
tensor([[1., 1., 0., 0., 1.],
        [0., 0., 1., 1., 1.],
        [0., 0., 1., 1., 1.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.7998)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>而且，y 也 不一定要是 0 or 1， y也可以是 0~1 的數，此時 binary entropy 就是在衡量 y 和 y_hat 的 distribution 像不像的一個指標</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.1801, 0.4587, 0.9839, 0.5115, 0.7780],
        [0.2146, 0.9854, 0.0592, 0.6360, 0.2658],
        [0.6827, 0.2666, 0.0440, 0.6086, 0.8917]])
tensor([[0.6732, 0.5078, 0.8481, 0.7030, 0.9484],
        [0.7353, 0.8262, 0.2038, 0.2685, 0.1202],
        [0.5659, 0.6011, 0.3651, 0.3918, 0.4598]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.8157)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>這其實就有用在 autoencoder 的 loss 上</p></li>
<li><p>y 是一張正規化後的影像(值都介於 0 到 1)，y_hat 是 reconstruct 後的影像，值也都介於 0 到 1 (因為最後有加 sigmoid)，此時算 loss 就可以用 binary_cross_entropy loss</p></li>
</ul>
</div>
</div>
<div class="section" id="binary-cross-entropy-with-logits">
<h3><span class="section-number">1.11.5. </span>binary cross entropy with logits<a class="headerlink" href="#binary-cross-entropy-with-logits" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_logit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.3552</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9071</span><span class="p">,</span>  <span class="mf">2.8323</span><span class="p">])</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.9133</span><span class="p">,</span> <span class="mf">0.2876</span><span class="p">,</span> <span class="mf">0.9444</span><span class="p">])</span> <span class="c1"># 就是 F.sigmoid(y_logit) 後的結果</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{y_i}\)</span> 在轉成機率值前叫 logit (從 deep learning 的角度，就是還沒做 sigmoid 前的值; 從統計角度，sigmoid 在做的就是 logit transform 的逆變換)。</p></li>
<li><p>所以他會幫你把這個 <span class="math notranslate nohighlight">\(\hat{y_i}\)</span> 轉成 <span class="math notranslate nohighlight">\(\frac{1}{1+e^{-\hat{y_i}}}\)</span> (這就是 sigmoid function 在做的事，也就是 logit transform 的逆變換)，再丟進去 binary cross entropy 裡面。</p></li>
<li><p>補充以下以前學過的統計知識：</p>
<ul>
<li><p>logit transform 是把 0 到 1 的機率值，轉成實數域。 e.g. p 介於 0 到 1， <span class="math notranslate nohighlight">\(y = log\left(\frac{p}{1-p}\right)\)</span>，此時 y 介於 -無窮 到 +無窮，此時的 y 被稱為 logits</p></li>
<li><p>logit transform 逆變換，是把時數域壓到 0 到 1 之間。 e.g. y 介於 -無窮 到 +無窮. <span class="math notranslate nohighlight">\(p = \frac{1}{1+e^{-y}}\)</span>，此時 p 介於 0 到 1, 此時的 p 被解釋為機率值</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="cross-entropy">
<h3><span class="section-number">1.11.6. </span>cross-entropy<a class="headerlink" href="#cross-entropy" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>先寫結論和用法，晚點補詳細的：</p>
<ul>
<li><p>input 的 y_hat 必須是 logit (還沒經過 softmax), y可以是 [0,c) 的 integer，或是 one-hot encoding(必須是 float32，為了通用於 blended-label).</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>y_hat 需要是 logit</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat_logit_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="o">-</span><span class="mf">2.3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span>
     <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<span class="p">)</span>
<span class="n">y_hat_logit_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat_logit_mat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-2.3000,  2.0000,  1.5000],
        [-1.0000,  2.0000,  3.0000]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>熟悉的 softmax 是這樣：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_hat_mat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.0084, 0.6172, 0.3744],
        [0.0132, 0.2654, 0.7214]], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>y 可以是 int 或 one-hot</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">y_one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>算 cross-entropy</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">,</span> <span class="n">y_int</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">,</span> <span class="n">y_one_hot</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([0.4825, 1.3266], dtype=torch.float64)
tensor([0.4825, 1.3266], dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">,</span> <span class="n">y_int</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">y_hat_logit_mat</span><span class="p">,</span> <span class="n">y_one_hot</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.9045, dtype=torch.float64)
tensor(0.9045, dtype=torch.float64)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id12">
<h3><span class="section-number">1.11.7. </span>自訂 loss<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="id13">
<h3><span class="section-number">1.11.8. </span>對比學習<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="autoencoder">
<h3><span class="section-number">1.11.9. </span>autoencoder<a class="headerlink" href="#autoencoder" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="optimizer">
<h2><span class="section-number">1.12. </span>Optimizer<a class="headerlink" href="#optimizer" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>官網很清楚： <a class="reference external" href="https://pytorch.org/docs/1.8.1/optim.html#how-to-adjust-learning-rate">https://pytorch.org/docs/1.8.1/optim.html#how-to-adjust-learning-rate</a></p></li>
</ul>
<div class="section" id="id14">
<h3><span class="section-number">1.12.1. </span>建立 optimizer<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="learning-rate">
<h3><span class="section-number">1.12.2. </span>不同 learning rate<a class="headerlink" href="#learning-rate" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="learning-rate-scheduler">
<h3><span class="section-number">1.12.3. </span>learning rate scheduler<a class="headerlink" href="#learning-rate-scheduler" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="training-loops">
<h2><span class="section-number">1.13. </span>Training loops<a class="headerlink" href="#training-loops" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id15">
<h3><span class="section-number">1.13.1. </span>完整版 (了解概念用)<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Data 準備</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># Training</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 1000 張 100 x 100 單色圖片</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 1000 個 labels</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">tsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">tsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">tsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Validation</span>
<span class="n">vX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 100 張 100 x 100 單色圖片</span>
<span class="n">vY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 100 個 labels</span>

<span class="n">vX</span><span class="p">,</span> <span class="n">vY</span> <span class="o">=</span> <span class="n">vX</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">vY</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">vtsrX</span><span class="p">,</span> <span class="n">vtsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vX</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vY</span><span class="p">)</span>
<span class="n">vtsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">vtsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">vtsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Validation 不需要 shuffle</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>model structure</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 傳入 model 的函數會經過 forward 做 inference</span>
        <span class="c1"># x = x.view(x.size(0), -1) # flatten 的意思，原本的 x.size = (batch_size, 100, 100, 1) -&gt; 改成 (batch_size, 100*100*1)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>確定 device</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">device</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;cpu&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model structure</span>
<span class="n">simpleNN</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                           <span class="c1"># 把 model 移到 GPU 計算</span>

<span class="c1"># optimizer</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>

<span class="c1"># loss</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>tensorboard 設定</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tensorboard setting</span>
<span class="o">%</span><span class="k">load_ext</span> tensorboard

<span class="kn">import</span> <span class="nn">os</span>
<span class="n">logs_base_dir</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span> <span class="c1"># training 的紀錄，放在這個路徑下</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">logs_base_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="n">tb</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>開始 Training， 本質就是跑一個迴圈，在每一次（叫一個 <strong>epoch</strong>）要做的事有——</p>
<ol class="simple">
<li><p>載入資料</p></li>
<li><p>經過 model 跑一次</p></li>
<li><p>比對資料的正確性，算誤差（loss）</p></li>
<li><p>把梯度清掉，然後根據這次誤差算新的梯度</p></li>
<li><p>根據 optimizer 更新參數</p></li>
<li><p>為了方便觀察，將本次 epoch 訓練的變化顯示出來，包括</p>
<ul>
<li><p>進度條（觀察訓練快慢）</p></li>
<li><p>batch loss （這個有時候會輸出太多東西）</p></li>
<li><p>epoch loss （記得累計並除掉資料數量）</p></li>
<li><p>記錄到其他變數中（方便作圖）</p></li>
<li><p>記錄到 Tensorboard 中（SummaryWriter）</p></li>
</ul>
</li>
</ol>
</li>
<li><p>為了避免 overfit，我們每個 epoch 還會進行一次 validation，事情少一些，變成——</p>
<ol class="simple">
<li><p>載入資料</p></li>
<li><p>經過 model 跑一次</p></li>
<li><p>比對資料的正確性，算誤差（loss）</p></li>
<li><p>為了方便觀察，將本次 epoch validate 的結果顯示出來，包括</p>
<ul>
<li><p>進度條（觀察訓練快慢）</p></li>
<li><p>batch loss （這個有時候會輸出太多東西）</p></li>
<li><p>epoch loss （記得累計並除掉資料數量）</p></li>
<li><p>記錄到其他變數中（方便作圖）</p></li>
<li><p>記錄到 Tensorboard 中（SummaryWriter）</p></li>
</ul>
</li>
</ol>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir {logs_base_dir} # 開啟 tensorboard
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># training loop</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="c1"># training step (training data)</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># 切換 simpleNN 為 training 模式，dropout 之類的操作會開啟</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>        <span class="c1"># 把 x tensor 移到 GPU 計算</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span> <span class="c1"># 把 y tensor 移到 GPU 計算，</span>
                                              <span class="c1">##  y_hat 因為是從 GPU model input GPU Tensor 出來的</span>
                                              <span class="c1">##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># 把 trainable variable/weights/parameters 的 gradient 給 歸 0</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># 利用 loss，計算出每個 trainable variable/weights/parameters 所對應的 gradient</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 更新 trainable variable/weights/parameters 的值： parameters_new = parameters_old - learning_rate * gradient</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">average_epoch_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">tsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training   Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">average_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;Loss/train&quot;</span><span class="p">,</span> <span class="n">average_epoch_loss</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 寫進 tensorboard</span>
    

    <span class="c1"># evaluation step (validation data)</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># 將 simpleNN 切換到 evaluation mode， dropout 之類的操作會關閉</span>
    <span class="n">vepoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">vtsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">vepoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">vaverage_epoch_loss</span> <span class="o">=</span> <span class="n">vepoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">vtsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">vaverage_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;Loss/val&quot;</span><span class="p">,</span> <span class="n">vaverage_epoch_loss</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 寫進 tensorboard</span>
<span class="n">tb</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># 加這個</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training   Epoch  1: Loss = 1.0920
Validation Epoch  1: Loss = 0.9851
Training   Epoch  2: Loss = 0.9812
Validation Epoch  2: Loss = 0.9269
Training   Epoch  3: Loss = 0.9155
Validation Epoch  3: Loss = 0.8980
Training   Epoch  4: Loss = 0.8593
Validation Epoch  4: Loss = 0.7541
Training   Epoch  5: Loss = 0.7777
Validation Epoch  5: Loss = 0.6951
Training   Epoch  6: Loss = 0.7110
Validation Epoch  6: Loss = 0.6363
Training   Epoch  7: Loss = 0.6274
Validation Epoch  7: Loss = 0.5730
Training   Epoch  8: Loss = 0.5564
Validation Epoch  8: Loss = 0.4740
Training   Epoch  9: Loss = 0.4752
Validation Epoch  9: Loss = 0.3994
Training   Epoch 10: Loss = 0.3927
Validation Epoch 10: Loss = 0.3577
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="deploy">
<h3><span class="section-number">1.13.2. </span>模組版 (實際做實驗, deploy 時用)<a class="headerlink" href="#deploy" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="sd">&quot;&quot;&quot;計算預測正確的數量&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cmp</span> <span class="o">=</span> <span class="n">y_hat</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">cmp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 計算 metric 時用的</span>
<span class="k">class</span> <span class="nc">Accumulator</span><span class="p">:</span>  <span class="c1">#@save</span>
    <span class="sd">&quot;&quot;&quot;在n个變量上累加&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span> <span class="c1"># [0.0, 0.0, ..., 0.0], 共 n 個 0.0</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span> <span class="o">+</span> <span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">args</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_iter</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="sd">&quot;&quot;&quot;計算在指定數據集上，模型的準確度&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 正确预测数、预测总数</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
            <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 單一 epoch 裡要做的事</span>
<span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>  <span class="c1">#@save</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="c1"># 訓練損失總和、訓練準確度總和、樣本數</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">Accumulator</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">l</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        
        <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()),</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="c1"># 返回訓練損失 &amp; 訓練準確度</span>
    <span class="k">return</span> <span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Animator</span><span class="p">:</span>  <span class="c1">#@save</span>
    <span class="sd">&quot;&quot;&quot;在動畫中繪製數據&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">ylim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xscale</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                 <span class="n">fmts</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;m--&#39;</span><span class="p">,</span> <span class="s1">&#39;g-.&#39;</span><span class="p">,</span> <span class="s1">&#39;r:&#39;</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)):</span>
        <span class="c1"># 增量地绘制多条线</span>
        <span class="k">if</span> <span class="n">legend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">legend</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">use_svg_display</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nrows</span> <span class="o">*</span> <span class="n">ncols</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">,</span> <span class="p">]</span>
        <span class="c1"># 使用lambda函数捕获参数</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config_axes</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">set_axes</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="p">,</span> <span class="n">xscale</span><span class="p">,</span> <span class="n">yscale</span><span class="p">,</span> <span class="n">legend</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmts</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fmts</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># 向图表中添加多个数据点</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">&quot;__len__&quot;</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;__len__&quot;</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fmt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmts</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fmt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config_axes</span><span class="p">()</span>
        <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="c1">#animator = Animator(xlabel=&#39;epoch&#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9],</span>
    <span class="c1">#                    legend=[&#39;train loss&#39;, &#39;train acc&#39;, &#39;test acc&#39;])</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">)</span>
        <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_iter</span><span class="p">)</span>
        <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">valid_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
    <span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
    <span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
    <span class="k">assert</span> <span class="n">valid_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">valid_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">valid_acc</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id16">
<h3><span class="section-number">1.13.3. </span>CNN<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
</div>
</div>
<div class="section" id="prediction">
<h2><span class="section-number">1.14. </span>Prediction<a class="headerlink" href="#prediction" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>data 準備 (testing data)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Testing</span>
<span class="n">tX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 100 張 100 x 100 單色圖片</span>
<span class="n">tY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 100 個 labels</span>

<span class="n">tX</span><span class="p">,</span> <span class="n">tY</span> <span class="o">=</span> <span class="n">tX</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tY</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">ttsrX</span><span class="p">,</span> <span class="n">ttsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tX</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tY</span><span class="p">)</span>
<span class="n">ttsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">ttsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">ttsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Testing 不需要 shuffle</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># prediction</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="p">[</span><span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ttsrdataloader</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">test_iter</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">trues</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_fashion_mnist_labels</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">get_fashion_mnist_labels</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="n">true</span> <span class="o">+</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">pred</span> <span class="k">for</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">trues</span><span class="p">,</span> <span class="n">preds</span><span class="p">)]</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">show_images</span><span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">titles</span><span class="o">=</span><span class="n">titles</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">])</span>

<span class="n">predict_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluation">
<h2><span class="section-number">1.15. </span>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="save-load-model">
<h2><span class="section-number">1.16. </span>Save/ load model<a class="headerlink" href="#save-load-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="weight">
<h3><span class="section-number">1.16.1. </span>只存 weight<a class="headerlink" href="#weight" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html">https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 假設我們 train 好的 model 是 VGG</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 只存 weight</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;model_weights.pth&#39;</span><span class="p">)</span>

<span class="c1"># 之後做預測，要先 initialize model</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># load weight</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;model_weights.pth&#39;</span><span class="p">))</span>

<span class="c1"># 開始做 inference</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># 關閉 batch normalization layer, dropout layer 等</span>
<span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="weight-model-structure">
<h3><span class="section-number">1.16.2. </span>存 weight 和 model structure<a class="headerlink" href="#weight-model-structure" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>如果把 model structure 和 weight 一起存起來，就可以 load 後，直接 predict</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="k">as</span> <span class="nn">models</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 存檔時，存整個 model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;model.pth&#39;</span><span class="p">)</span>

<span class="c1"># 讀檔時，直接讀整個 model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;model.pth&#39;</span><span class="p">)</span> <span class="c1"># 不需要 initialize 一個 model，再去讀 weight 了</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="checkpoints">
<h3><span class="section-number">1.16.3. </span>checkpoints<a class="headerlink" href="#checkpoints" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html</a></p></li>
<li><p>看官網這篇就 ok 了</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save model</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="c1"># 先移回 CPU</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">simpleNN</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;randmodel.model&quot;</span><span class="p">)</span>

<span class="c1"># Load model</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="n">model2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;randmodel.model&quot;</span><span class="p">))</span>

<span class="c1"># 確認是同一個 model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">model2</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="callbacks">
<h2><span class="section-number">1.17. </span>callbacks<a class="headerlink" href="#callbacks" title="Permalink to this headline">¶</a></h2>
<div class="section" id="early-stopping">
<h3><span class="section-number">1.17.1. </span>Early stopping<a class="headerlink" href="#early-stopping" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>修改自：<a class="reference external" href="https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch">https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EarlyStopper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">if_break</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">monitor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">validation_loss</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="o">=</span> <span class="n">validation_loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">elif</span> <span class="n">validation_loss</span> <span class="o">&gt;</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_validation_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">if_break</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="k">else</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>然後這樣用：</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">early_stopper</span> <span class="o">=</span> <span class="n">EarlyStopper</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_delta</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">)</span>
    <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">validate_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">validation_loader</span><span class="p">)</span>
    
    <span class="n">early_stopper</span><span class="o">.</span><span class="n">monitor</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">early_stopper</span><span class="o">.</span><span class="n">counter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;model.pth&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">early_stopper</span><span class="o">.</span><span class="n">if_break</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="visualization">
<h2><span class="section-number">1.18. </span>Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>tensorboard 參考這篇：</p>
<ul>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">https://pytorch.org/docs/stable/tensorboard.html</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html">https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="explaianation">
<h2><span class="section-number">1.19. </span>Explaianation<a class="headerlink" href="#explaianation" title="Permalink to this headline">¶</a></h2>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./pytorch"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Welcome to your Jupyter Book</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../old/1.tensor.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Introduction to Tensors</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book Community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>