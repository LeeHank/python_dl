
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>11. PyTorch 模型建構與訓練基礎介紹 – PyTorch Training Steps &amp; Tips &#8212; My sample book</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="10. Customization" href="../../hands_on_ml3/tf_customization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Cheat Sheet
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pytorch_cheatsheet.html">
   1. Pytorch Cheatsheet
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tensorflow basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/1.tensor.html">
   2. Introduction to Tensors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/2.variable.html">
   3. Introduction to Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/3.autodiff.html">
   4. Introduction to gradients and automatic differentiation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/5.intro_to_modules.html">
   5. Introduction to modules, layers, and models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/6.basic_training_loops.html">
   7. Basic training loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../old/7.keras_sequential_model.html">
   8. The Sequential model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tf_create_model.html">
   9. 三種搭建神經網路的方式
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../hands_on_ml3/tf_customization.html">
   10. Customization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pytorch basics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   11. PyTorch 模型建構與訓練基礎介紹 – PyTorch Training Steps &amp; Tips
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/pytorch/ch0_pytorch_tutorial/PyTorch_tutorial_newVersion.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpytorch/ch0_pytorch_tutorial/PyTorch_tutorial_newVersion.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/pytorch/ch0_pytorch_tutorial/PyTorch_tutorial_newVersion.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preprocessing">
   11.1. 資料前處理 - Data Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reading-files">
     11.1.1. 資料讀取 - Reading files
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-files">
       11.1.1.1. 文字檔案 - Text Files
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#csv-csv-files">
       11.1.1.2. CSV 檔案 - CSV Files
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#python-pure-python">
         11.1.1.2.1. Python 原生 - Pure Python
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pandas-pandas-library-faster">
         11.1.1.2.2. 使用 Pandas 套件（比較快！） — Pandas Library (Faster!)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-files">
       11.1.1.3. 圖片檔案 — Image Files
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-manipulation">
     11.1.2. 資料處理操作 – Data Manipulation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-data">
       11.1.2.1. 文字資料 — Text data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#numpy-numpy-array-data">
       11.1.2.2. Numpy 陣列 — Numpy Array data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-data">
       11.1.2.3. 圖片資料 — Image data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-augmentations">
         11.1.2.3.1. 常用的圖片轉換 Data augmentations
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#word2vec">
       11.1.2.4. 詞向量 — Word2Vec
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-dataloader-preparation">
     11.1.3. 資料準備 — Dataset / Dataloader Preparation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dataset-class">
       11.1.3.1. 自己寫
       <code class="docutils literal notranslate">
        <span class="pre">
         Dataset
        </span>
       </code>
       class
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensordataset">
       11.1.3.2. 直接用
       <code class="docutils literal notranslate">
        <span class="pre">
         TensorDataset
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mnist">
       11.1.3.3. 取內建資料集 – MNIST
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-construction-mark-tt-torch-nn-tt-mark">
   11.2. Model Construction –
   <mark>
    <tt>
     <strong>
      torch.nn
     </strong>
    </tt>
   </mark>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-nn-module">
     11.2.1. Model –
     <strong>
      <code class="docutils literal notranslate">
       <span class="pre">
        nn.Module
       </span>
      </code>
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wrapper-nn-sequential">
     11.2.2. Wrapper –
     <strong>
      <code class="docutils literal notranslate">
       <span class="pre">
        nn.Sequential
       </span>
      </code>
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-layers">
     11.2.3. Model Layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nn">
       11.2.3.1. NN
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cnn">
       11.2.3.2. CNN
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#convolution-layers">
         11.2.3.2.1. Convolution layers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pooling-layers">
         11.2.3.2.2. Pooling layers
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rnn">
       11.2.3.3. RNN
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#embedding-layers">
         11.2.3.3.1. Embedding layers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#loading-word2vec-models">
         11.2.3.3.2. Loading Word2Vec models
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#rnn-layers-lstm-gru">
         11.2.3.3.3. RNN layers (LSTM, GRU)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-functions">
     11.2.4. Activation functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   11.3. Loss functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizers">
   11.4. 優化器 — Optimizers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalization">
   11.5. Normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-validation-fine-tuning">
   11.6. Training (Validation) / Fine-Tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-saving-loading-checkpoints">
     11.6.1. – Model saving / loading (checkpoints)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-evaluation">
   11.7. 4. Testing / Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#result-post-processing">
   11.8. 5. Result Post-processing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#saving-files">
     11.8.1. 1 – Saving files
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kaggle-upload">
     11.8.2. 2 – Kaggle Upload
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#colaboratory-kaggle-notebook">
     11.8.3. 3 – Colaboratory / Kaggle Notebook
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   11.9. 6. Visualization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorboard">
     11.9.1. TensorBoard
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-usage">
   11.10. 7. GPU Usage
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#colaboratory">
     11.10.1. 1 – Colaboratory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pbs-usage">
     11.10.2. 2 – PBS Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#todo-for-next-version">
   11.11. TODO for next version
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-tips">
     11.11.1. Useful tips
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     11.11.2. Visualization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-vscode-connect-to-runtime">
     11.11.3. Jupyter / VSCode （Connect to runtime）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-examples">
     11.11.4. More Examples
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>PyTorch 模型建構與訓練基礎介紹 – PyTorch Training Steps & Tips</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-preprocessing">
   11.1. 資料前處理 - Data Preprocessing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reading-files">
     11.1.1. 資料讀取 - Reading files
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-files">
       11.1.1.1. 文字檔案 - Text Files
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#csv-csv-files">
       11.1.1.2. CSV 檔案 - CSV Files
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#python-pure-python">
         11.1.1.2.1. Python 原生 - Pure Python
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pandas-pandas-library-faster">
         11.1.1.2.2. 使用 Pandas 套件（比較快！） — Pandas Library (Faster!)
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-files">
       11.1.1.3. 圖片檔案 — Image Files
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-manipulation">
     11.1.2. 資料處理操作 – Data Manipulation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#text-data">
       11.1.2.1. 文字資料 — Text data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#numpy-numpy-array-data">
       11.1.2.2. Numpy 陣列 — Numpy Array data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-data">
       11.1.2.3. 圖片資料 — Image data
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#data-augmentations">
         11.1.2.3.1. 常用的圖片轉換 Data augmentations
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#word2vec">
       11.1.2.4. 詞向量 — Word2Vec
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-dataloader-preparation">
     11.1.3. 資料準備 — Dataset / Dataloader Preparation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dataset-class">
       11.1.3.1. 自己寫
       <code class="docutils literal notranslate">
        <span class="pre">
         Dataset
        </span>
       </code>
       class
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensordataset">
       11.1.3.2. 直接用
       <code class="docutils literal notranslate">
        <span class="pre">
         TensorDataset
        </span>
       </code>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mnist">
       11.1.3.3. 取內建資料集 – MNIST
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-construction-mark-tt-torch-nn-tt-mark">
   11.2. Model Construction –
   <mark>
    <tt>
     <strong>
      torch.nn
     </strong>
    </tt>
   </mark>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-nn-module">
     11.2.1. Model –
     <strong>
      <code class="docutils literal notranslate">
       <span class="pre">
        nn.Module
       </span>
      </code>
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wrapper-nn-sequential">
     11.2.2. Wrapper –
     <strong>
      <code class="docutils literal notranslate">
       <span class="pre">
        nn.Sequential
       </span>
      </code>
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-layers">
     11.2.3. Model Layers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nn">
       11.2.3.1. NN
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#cnn">
       11.2.3.2. CNN
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#convolution-layers">
         11.2.3.2.1. Convolution layers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#pooling-layers">
         11.2.3.2.2. Pooling layers
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#rnn">
       11.2.3.3. RNN
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#embedding-layers">
         11.2.3.3.1. Embedding layers
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#loading-word2vec-models">
         11.2.3.3.2. Loading Word2Vec models
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#rnn-layers-lstm-gru">
         11.2.3.3.3. RNN layers (LSTM, GRU)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activation-functions">
     11.2.4. Activation functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#loss-functions">
   11.3. Loss functions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimizers">
   11.4. 優化器 — Optimizers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#normalization">
   11.5. Normalization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-validation-fine-tuning">
   11.6. Training (Validation) / Fine-Tuning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-saving-loading-checkpoints">
     11.6.1. – Model saving / loading (checkpoints)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-evaluation">
   11.7. 4. Testing / Evaluation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#result-post-processing">
   11.8. 5. Result Post-processing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#saving-files">
     11.8.1. 1 – Saving files
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#kaggle-upload">
     11.8.2. 2 – Kaggle Upload
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#colaboratory-kaggle-notebook">
     11.8.3. 3 – Colaboratory / Kaggle Notebook
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualization">
   11.9. 6. Visualization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tensorboard">
     11.9.1. TensorBoard
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gpu-usage">
   11.10. 7. GPU Usage
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#colaboratory">
     11.10.1. 1 – Colaboratory
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pbs-usage">
     11.10.2. 2 – PBS Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#todo-for-next-version">
   11.11. TODO for next version
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-tips">
     11.11.1. Useful tips
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     11.11.2. Visualization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#jupyter-vscode-connect-to-runtime">
     11.11.3. Jupyter / VSCode （Connect to runtime）
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#more-examples">
     11.11.4. More Examples
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="pytorch-pytorch-training-steps-tips">
<h1><span class="section-number">11. </span>PyTorch 模型建構與訓練基礎介紹 – PyTorch Training Steps &amp; Tips<a class="headerlink" href="#pytorch-pytorch-training-steps-tips" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mounted at /content/drive
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/0. codepool_python/deep_learning_hylee2022/ch0_pytorch_tutorial&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown **下載所需的資料 Download the necessary files here!**</span>

<span class="o">%%</span><span class="k">bash</span>
COLAB_ICON=&quot;${COLAB_ICON}https://miro.medium.com/max/200/&quot;
COLAB_ICON=&quot;${COLAB_ICON}1*i_ncmAcN81MRMNRDcenKiw.png&quot;
wget -q -nc -O Colab_icon.png $COLAB_ICON

echo &quot;Hello! I am the data~. :P&quot; &gt; filename.txt

echo &quot;Col0,Col1,Col2,Col3&quot; &gt; data.csv
echo &quot;Row1,data11,data12,data13&quot; &gt;&gt; data.csv
echo &quot;Row2,data21,data22,data23&quot; &gt;&gt; data.csv
echo &quot;Row3,data31,data32,data33&quot; &gt;&gt; data.csv
echo &quot;Row4,data41,data42,data43&quot; &gt;&gt; data.csv
echo &quot;Row5,data51,data52,data53&quot; &gt;&gt; data.csv
echo &quot;Row6,data61,data62,data63&quot; &gt;&gt; data.csv
echo &quot;Row7,data71,data72,data73&quot; &gt;&gt; data.csv
printf &quot;%s&quot; &quot;Row8,data81,data82,data83&quot; &gt;&gt; data.csv

gdown --id &#39;19CzXudqN58R3D-1G8KeFWk8UDQwlb8is&#39; \
    --output food-11.zip # 下載資料集
unzip food-11.zip &gt; unziplog # 解壓縮
rm -f unziplog

wget -q -N https://download.pytorch.org/tutorial/faces.zip
if [ ! -d data ]; then mkdir data; fi
unzip -q -o faces.zip -d data &gt; unziplog
rm -f faces.zip
rm -f unziplog
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don&#39;t need to pass it anymore to use a file ID.
  category=FutureWarning,
Downloading...
From: https://drive.google.com/uc?id=19CzXudqN58R3D-1G8KeFWk8UDQwlb8is
To: /content/drive/MyDrive/0. codepool_python/deep_learning_hylee2022/ch0_pytorch_tutorial/food-11.zip
100%|██████████| 1.16G/1.16G [00:07&lt;00:00, 148MB/s] 
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>載入需要的套件和模組 Libraries</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">csv</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># %% 深度學習套件 deep learning related </span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>

<span class="c1"># %% 視覺化/製圖套件 visualization / plotting</span>
<span class="c1"># MacOSX 比較麻煩⋯⋯</span>
<span class="kn">from</span> <span class="nn">platform</span> <span class="kn">import</span> <span class="n">system</span>
<span class="k">if</span> <span class="n">system</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;Darwin&quot;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">matplotlib</span>
    <span class="n">matplotlib</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;TkAgg&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># %% 圖片處理套件 CV related</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

<span class="c1"># %% 文字處理套件 NLP related</span>
<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">word2vec</span>

<span class="c1"># %% 音訊處理套件 Speech related</span>
<span class="c1"># import torchaudio</span>
<span class="c1"># import librosa</span>

<span class="c1"># %% 好用的進度條和排版工具</span>
<span class="c1">##   progress bar and pretty print</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-preprocessing">
<h2><span class="section-number">11.1. </span>資料前處理 - Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>首先，我們需要將我們的資料整理成 model 可以處理的形式</p>
<div class="section" id="reading-files">
<h3><span class="section-number">11.1.1. </span>資料讀取 - Reading files<a class="headerlink" href="#reading-files" title="Permalink to this headline">¶</a></h3>
<div class="section" id="text-files">
<h4><span class="section-number">11.1.1.1. </span>文字檔案 - Text Files<a class="headerlink" href="#text-files" title="Permalink to this headline">¶</a></h4>
<p>這是最簡單的，直接如一般 Python 讀取就好
Simply follows that in other Python programs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;filename.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hello! I am the data~. :P
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="csv-csv-files">
<h4><span class="section-number">11.1.1.2. </span>CSV 檔案 - CSV Files<a class="headerlink" href="#csv-csv-files" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> 
    <span class="n">csv_data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Here comes a csv data:&quot;</span><span class="p">,</span> 
      <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">,</span> <span class="n">csv_data</span><span class="p">,</span> <span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Here comes a csv data:
============================================================
Col0,Col1,Col2,Col3
Row1,data11,data12,data13
Row2,data21,data22,data23
Row3,data31,data32,data33
Row4,data41,data42,data43
Row5,data51,data52,data53
Row6,data61,data62,data63
Row7,data71,data72,data73
Row8,data81,data82,data83
============================================================
</pre></div>
</div>
</div>
</div>
<div class="section" id="python-pure-python">
<h5><span class="section-number">11.1.1.2.1. </span>Python 原生 - Pure Python<a class="headerlink" href="#python-pure-python" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">csv_reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="c1"># If you have a &quot;tsv&quot;, do this:</span>
    <span class="c1">##  `csv_reader = csv.reader(f, delimiter=&#39;\t&#39;)`</span>
    <span class="n">csv_data1</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">csv_reader</span><span class="p">]</span>
<span class="n">csv_data1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[&#39;Col0&#39;, &#39;Col1&#39;, &#39;Col2&#39;, &#39;Col3&#39;],
 [&#39;Row1&#39;, &#39;data11&#39;, &#39;data12&#39;, &#39;data13&#39;],
 [&#39;Row2&#39;, &#39;data21&#39;, &#39;data22&#39;, &#39;data23&#39;],
 [&#39;Row3&#39;, &#39;data31&#39;, &#39;data32&#39;, &#39;data33&#39;],
 [&#39;Row4&#39;, &#39;data41&#39;, &#39;data42&#39;, &#39;data43&#39;],
 [&#39;Row5&#39;, &#39;data51&#39;, &#39;data52&#39;, &#39;data53&#39;],
 [&#39;Row6&#39;, &#39;data61&#39;, &#39;data62&#39;, &#39;data63&#39;],
 [&#39;Row7&#39;, &#39;data71&#39;, &#39;data72&#39;, &#39;data73&#39;],
 [&#39;Row8&#39;, &#39;data81&#39;, &#39;data82&#39;, &#39;data83&#39;]]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="pandas-pandas-library-faster">
<h5><span class="section-number">11.1.1.2.2. </span>使用 Pandas 套件（比較快！） — Pandas Library (Faster!)<a class="headerlink" href="#pandas-pandas-library-faster" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">csv_data2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">)</span>

<span class="c1"># Saved as a Pandas dataframe</span>
<span class="n">csv_data2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-6d989fc5-ea0e-47ab-9033-a03e14d205f0">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Col0</th>
      <th>Col1</th>
      <th>Col2</th>
      <th>Col3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Row1</td>
      <td>data11</td>
      <td>data12</td>
      <td>data13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Row2</td>
      <td>data21</td>
      <td>data22</td>
      <td>data23</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Row3</td>
      <td>data31</td>
      <td>data32</td>
      <td>data33</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Row4</td>
      <td>data41</td>
      <td>data42</td>
      <td>data43</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Row5</td>
      <td>data51</td>
      <td>data52</td>
      <td>data53</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Row6</td>
      <td>data61</td>
      <td>data62</td>
      <td>data63</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Row7</td>
      <td>data71</td>
      <td>data72</td>
      <td>data73</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Row8</td>
      <td>data81</td>
      <td>data82</td>
      <td>data83</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-6d989fc5-ea0e-47ab-9033-a03e14d205f0')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-6d989fc5-ea0e-47ab-9033-a03e14d205f0 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-6d989fc5-ea0e-47ab-9033-a03e14d205f0');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_columns</span> <span class="o">=</span> <span class="n">csv_data2</span><span class="o">.</span><span class="n">columns</span>
<span class="n">data_columns</span><span class="o">.</span><span class="n">values</span> <span class="c1"># `.values` to numpy arrays</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Col0&#39;, &#39;Col1&#39;, &#39;Col2&#39;, &#39;Col3&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>    <span class="c1"># after pandas ver.0.24.0</span>
    <span class="n">data_content</span> <span class="o">=</span> <span class="n">csv_data2</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="k">except</span><span class="p">:</span> <span class="c1"># before pandas ver.0.24.0</span>
    <span class="n">data_content</span> <span class="o">=</span> <span class="n">csv_data2</span><span class="o">.</span><span class="n">values</span>
<span class="n">data_content</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[&#39;Row1&#39;, &#39;data11&#39;, &#39;data12&#39;, &#39;data13&#39;],
       [&#39;Row2&#39;, &#39;data21&#39;, &#39;data22&#39;, &#39;data23&#39;],
       [&#39;Row3&#39;, &#39;data31&#39;, &#39;data32&#39;, &#39;data33&#39;],
       [&#39;Row4&#39;, &#39;data41&#39;, &#39;data42&#39;, &#39;data43&#39;],
       [&#39;Row5&#39;, &#39;data51&#39;, &#39;data52&#39;, &#39;data53&#39;],
       [&#39;Row6&#39;, &#39;data61&#39;, &#39;data62&#39;, &#39;data63&#39;],
       [&#39;Row7&#39;, &#39;data71&#39;, &#39;data72&#39;, &#39;data73&#39;],
       [&#39;Row8&#39;, &#39;data81&#39;, &#39;data82&#39;, &#39;data83&#39;]], dtype=object)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="image-files">
<h4><span class="section-number">11.1.1.3. </span>圖片檔案 — Image Files<a class="headerlink" href="#image-files" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title **看看圖片！ Run me to view image!**</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span> <span class="k">as</span> <span class="n">ImageColab</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;Colab_icon.png&quot;</span><span class="p">)</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">im</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;Colab_icon.png&quot;</span><span class="p">)</span>
<span class="n">ImageColab</span><span class="p">(</span><span class="s1">&#39;Colab_icon.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyTorch_tutorial_newVersion_19_0.png" src="../../_images/PyTorch_tutorial_newVersion_19_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># image = cv2.imread(&quot;image1.png&quot;)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;Colab_icon.png&quot;</span><span class="p">)</span>
<span class="n">image</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(200, 200, 3)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="data-manipulation">
<h3><span class="section-number">11.1.2. </span>資料處理操作 – Data Manipulation<a class="headerlink" href="#data-manipulation" title="Permalink to this headline">¶</a></h3>
<div class="section" id="text-data">
<h4><span class="section-number">11.1.2.1. </span>文字資料 — Text data<a class="headerlink" href="#text-data" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello, world!</span><span class="se">\n</span><span class="s2">I want to try tabs.</span><span class="se">\t</span><span class="s2">Like this!&quot;</span>
<span class="n">text_splitted</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">text_splitted</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>

<span class="c1"># List comprehension</span>
<span class="n">text_splitted</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span> 
     <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="numpy-numpy-array-data">
<h4><span class="section-number">11.1.2.2. </span>Numpy 陣列 — Numpy Array data<a class="headerlink" href="#numpy-numpy-array-data" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">arr1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">arr2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">arr6</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; arr1 is ...&quot;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">arr1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; arr2 is ...&quot;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">arr2</span><span class="p">)</span>

<span class="n">arr3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">arr1</span><span class="p">,</span> <span class="n">arr2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">arr4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">arr1</span><span class="p">,</span> <span class="n">arr2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">arr5</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">arr1</span><span class="p">)</span>
<span class="n">arr7</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">arr6</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">lst</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">76</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">45</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">arr8</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&gt;&gt;&gt; The shape of arr8 is </span><span class="si">{</span><span class="n">arr8</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">arr9</span> <span class="o">=</span> <span class="n">arr8</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; arr9 is ...&quot;</span><span class="p">);</span> <span class="nb">print</span><span class="p">(</span><span class="n">arr9</span><span class="p">)</span>

<span class="n">lst</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">arr10</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lst</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>
<span class="n">arr11</span> <span class="o">=</span> <span class="n">arr10</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&gt;&gt;&gt; The type of `lst` is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span><span class="si">}</span><span class="s2">,&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    but the type of `arr10` is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">arr10</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">new_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">arr10_reshaped</span> <span class="o">=</span> <span class="n">arr10</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; arr10_reshaped is ...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr10_reshaped</span><span class="p">)</span>

<span class="n">arr10_transposed</span> <span class="o">=</span> <span class="n">arr10</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&gt;&gt;&gt; arr10_transposed is ...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">arr10_transposed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; arr1 is ...
[[1 2]
 [3 4]
 [5 6]]
&gt;&gt;&gt; arr2 is ...
[[9 8]
 [7 6]
 [5 4]]
&gt;&gt;&gt; The shape of arr8 is (6,).
&gt;&gt;&gt; arr9 is ...
[  3.  76.   4. -45.   0.   6.]
&gt;&gt;&gt; The type of `lst` is &lt;class &#39;list&#39;&gt;,
    but the type of `arr10` is &lt;class &#39;numpy.ndarray&#39;&gt;.
&gt;&gt;&gt; arr10_reshaped is ...
[[[9 8 7]
  [6 5 4]]]
&gt;&gt;&gt; arr10_transposed is ...
[[9 7 5]
 [8 6 4]]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="image-data">
<h4><span class="section-number">11.1.2.3. </span>圖片資料 — Image data<a class="headerlink" href="#image-data" title="Permalink to this headline">¶</a></h4>
<p>把原來的圖片做伸縮</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">img_shape</span><span class="p">)]</span>
<span class="n">zeros_reserved</span> <span class="o">=</span> \
    <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="o">*</span><span class="n">img_shape</span><span class="p">),</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 100, 3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown 看轉換的圖片！ View resized image!</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">im</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;your_file.png&quot;</span><span class="p">)</span>
<span class="n">ImageColab</span><span class="p">(</span><span class="s2">&quot;your_file.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyTorch_tutorial_newVersion_28_0.png" src="../../_images/PyTorch_tutorial_newVersion_28_0.png" />
</div>
</div>
<div class="section" id="data-augmentations">
<h5><span class="section-number">11.1.2.3.1. </span>常用的圖片轉換 Data augmentations<a class="headerlink" href="#data-augmentations" title="Permalink to this headline">¶</a></h5>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="c1"># Basic transformations</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span> <span class="c1"># np.array  --&gt; PIL_image</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>    <span class="c1"># PIL_image --&gt; Tensor</span>
<span class="p">])</span>
</pre></div>
</div>
<p>下面有一些重複且被註解掉的部分，是因為版本差異造成。請注意應該只有一個會 work</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># For data augmentation</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span> 
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="n">DEGREE</span><span class="p">),</span> 
    <span class="c1"># transforms.RandomRotation(DEGREE, fill=(0,)),</span>
    <span class="c1"># transforms.RandomRotation(DEGREE, </span>
    <span class="c1">#     resample=False, expand=False, center=None),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>

<span class="c1"># Feature Scaling, </span>
<span class="c1">#     `mean` and `std` as np.array provided</span>
<span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> 
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="p">[</span><span class="n">mean</span><span class="p">],</span> <span class="p">[</span><span class="n">std</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># transforms.Normalize([mean], [std])</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="word2vec">
<h4><span class="section-number">11.1.2.4. </span>詞向量 — Word2Vec<a class="headerlink" href="#word2vec" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://en.wikipedia.org/wiki/Machine_learning</span>

<span class="n">article</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;Machine learning (ML) is the scientific </span>
<span class="s1">study of algorithms and statistical models that </span>
<span class="s1">computer systems use to perform a specific task </span>
<span class="s1">without using explicit instructions, relying on </span>
<span class="s1">patterns and inference instead. It is seen as a </span>
<span class="s1">subset of artificial intelligence. Machine learning </span>
<span class="s1">algorithms build a mathematical model based on sample </span>
<span class="s1">data, known as &quot;training data&quot;, in order to make </span>
<span class="s1">predictions or decisions without being explicitly </span>
<span class="s1">programmed to perform the task. Machine learning </span>
<span class="s1">algorithms are used in a wide variety of applications, </span>
<span class="s1">such as email filtering and computer vision, where it </span>
<span class="s1">is difficult or infeasible to develop a conventional </span>
<span class="s1">algorithm for effectively performing the task.</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">punctuation</span> <span class="ow">in</span> <span class="s2">&quot;,()</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">:</span>
    <span class="n">article</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">punctuation</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">tokenized_sentences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">article</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">sentence</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span> <span class="k">continue</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">sentence</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">+</span> <span class="n">sentence</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">tokenized_sentences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 這格有時可能要跑一段時間！ This cell may take time! </span>
<span class="n">w2vmodel</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span>
                    <span class="n">tokenized_sentences</span><span class="p">,</span> 
                    <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="c1"># Word embedding 的維度數</span>
                    <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">workers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="nb">iter</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="dataset-dataloader-preparation">
<h3><span class="section-number">11.1.3. </span>資料準備 — Dataset / Dataloader Preparation<a class="headerlink" href="#dataset-dataloader-preparation" title="Permalink to this headline">¶</a></h3>
<p>在處理訓練資料時，進行資料型態的前處理與分批（batch）等是相當麻煩的事。<br />
PyTorch 提供了一個很好的 dataset 與 dataloader 讓我們進行分裝以利訓練進行，還可以依需求自訂 dataset 的型態</p>
<p>簡言之，<code class="docutils literal notranslate"><span class="pre">dataset</span></code> 是用來做打包與預處理（例如輸入資料路徑自動讀取）；<br />
<code class="docutils literal notranslate"><span class="pre">Dataloader</span></code> 則是可以將整個資料集（dataset）按照 batch 進行迭代分裝或 shuffle（會得到一個 iterator 以利 for 迴圈讀取）</p>
<p>其中 <code class="docutils literal notranslate"><span class="pre">dataset</span></code> 必須給予 <code class="docutils literal notranslate"><span class="pre">__len__</span></code>（dataset 大小）與<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>（取得特定 index 的資料）的定義<br />
（否則會跳出 <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>）</p>
<p>另外 <code class="docutils literal notranslate"><span class="pre">Dataloader</span></code> 可以自訂 <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> 決定 batch 的分裝方式，可以參見<a class="reference external" href="https://pytorch.org/docs/stable/data.html#dataloader-collate-fn">這裡</a></p>
<div class="section" id="dataset-class">
<h4><span class="section-number">11.1.3.1. </span>自己寫 <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class<a class="headerlink" href="#dataset-class" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 1000 張 100 x 100 單色圖片</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 1000 個 labels</span>

<span class="k">class</span> <span class="nc">RandomDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>             <span class="c1"># 把資料存進 class object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="c1"># 確定資料有互相對應</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>                     <span class="c1"># 定義我們需要取得某筆資料的方式</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">randomdataset</span> <span class="o">=</span> <span class="n">RandomDataset</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">taken_x</span><span class="p">,</span> <span class="n">taken_y</span> <span class="o">=</span> <span class="n">randomdataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 原則上可以取得第一筆資料</span>
<span class="n">taken_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">taken_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((100, 100, 1), (10,))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 將 dataset 包裝成 dataloader</span>
<span class="n">randomdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">randomdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 跑一個 loop 確認拿到的 batch 是否正確</span>
<span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">randomdataloader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">((</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tensordataset">
<h4><span class="section-number">11.1.3.2. </span>直接用 <code class="docutils literal notranslate"><span class="pre">TensorDataset</span></code><a class="headerlink" href="#tensordataset" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># 把資料轉成 Tensor</span>
<span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="c1"># 然後就只要一行了！</span>
<span class="n">tsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="c1"># dataloader 本來就相對簡單</span>
<span class="n">tsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">tsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># 跑一個 loop 確認拿到的 batch 是否正確</span>
<span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">tsrdataloader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">((</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))
</pre></div>
</div>
</div>
</div>
<p>實際上資料處理還可以更加複雜，機器學習中資料的前處理也是相當的學問！</p>
</div>
<div class="section" id="mnist">
<h4><span class="section-number">11.1.3.3. </span>取內建資料集 – MNIST<a class="headerlink" href="#mnist" title="Permalink to this headline">¶</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                           <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                       <span class="p">]))</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                    <span class="p">]))</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">((</span><span class="n">batch_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batch_y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">break</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "794f2cc2ee5d4ac884acd48e232e06c0", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "a354a40742e041c48f7e74c4b12d1650", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "e005fbddc0ed42a68915dc5d15d658d6", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "2c5b976fc91d4693aea8cfc55cea2e1f", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw

(torch.Size([32, 1, 28, 28]), torch.Size([32]))
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="model-construction-mark-tt-torch-nn-tt-mark">
<h2><span class="section-number">11.2. </span>Model Construction – <mark><tt><strong>torch.nn</strong></tt></mark><a class="headerlink" href="#model-construction-mark-tt-torch-nn-tt-mark" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>常用的起手式就是以下兩行：</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
<div class="section" id="model-nn-module">
<h3><span class="section-number">11.2.1. </span>Model – <strong><code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></strong><a class="headerlink" href="#model-nn-module" title="Permalink to this headline">¶</a></h3>
<p>This is the basic module for PyTorch Neural network models. To build an NN model, inherit from it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># other layers or else...</span>
</pre></div>
</div>
</div>
<div class="section" id="wrapper-nn-sequential">
<h3><span class="section-number">11.2.2. </span>Wrapper – <strong><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></strong><a class="headerlink" href="#wrapper-nn-sequential" title="Permalink to this headline">¶</a></h3>
<p>PyTorch provides a convenient layer wrapper <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> for us.<br />
We can wrap a couple of layers together and use it for many times.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let us have 3 layers</span>
<span class="n">layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>

<span class="c1"># Data format: </span>
<span class="c1">#    - Input:  100 x 100</span>
<span class="c1">#    - Output: 100 x 7</span>
<span class="n">input_data</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">output_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Befor using `nn.Sequential`...&quot;</span><span class="p">)</span>
<span class="c1"># Originally, we need to write this.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input tensor shape: </span><span class="si">{</span><span class="n">input_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">layer1</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">layer2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">layer3</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output tensor shape: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Befor using `nn.Sequential`...
The input tensor shape: torch.Size([100, 100])
The output tensor shape: torch.Size([100, 7])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If we wrap them together, </span>
<span class="c1">##  we can just view the layers as a block.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;After using `nn.Sequential`...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input tensor shape: </span><span class="si">{</span><span class="n">input_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">layer_block</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">layer1</span><span class="p">,</span> <span class="n">layer2</span><span class="p">,</span> <span class="n">layer3</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">layer_block</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output tensor shape: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>After using `nn.Sequential`...
The input tensor shape: torch.Size([100, 100])
The output tensor shape: torch.Size([100, 7])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-layers">
<h3><span class="section-number">11.2.3. </span>Model Layers<a class="headerlink" href="#model-layers" title="Permalink to this headline">¶</a></h3>
<div class="section" id="nn">
<h4><span class="section-number">11.2.3.1. </span>NN<a class="headerlink" href="#nn" title="Permalink to this headline">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> – Often used fully-connected layer</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="sd">&quot;&quot;&quot;nn.Linear(in_dim, out_dim)&quot;&quot;&quot;</span>
<span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input data shape:  </span><span class="si">{</span><span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">Linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;The output data shape: &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">Linear_layer</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The input data shape:  torch.Size([32, 128])
The output data shape: torch.Size([32, 32])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="cnn">
<h4><span class="section-number">11.2.3.2. </span>CNN<a class="headerlink" href="#cnn" title="Permalink to this headline">¶</a></h4>
<div class="section" id="convolution-layers">
<h5><span class="section-number">11.2.3.2.1. </span>Convolution layers<a class="headerlink" href="#convolution-layers" title="Permalink to this headline">¶</a></h5>
<p><code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> – Basic 2D Convolutional Layer</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Input shape: <span class="math notranslate nohighlight">\((N, C_{in}, H_{in}, W_{in})\)</span><br />
Output shape: <span class="math notranslate nohighlight">\((N, C_{out}, H_{out}, W_{out})\)</span> where
$<span class="math notranslate nohighlight">\(H_{out}=\left \lfloor \cfrac{H_{in}+ 2 \times \text{padding}[0]-\text{dilation}[0]\times(\text{kernel_size}[0]-1)-1}{\text{stride}[0]} \right \rfloor+1\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(W_{out}=\left \lfloor \cfrac{H_{in}+ 2 \times \text{padding}[1]-\text{dilation}[1]\times(\text{kernel_size}[1]-1)-1}{\text{stride}[1]} \right \rfloor+1\)</span>$</p>
<p>The <code class="docutils literal notranslate"><span class="pre">[0]</span></code>, <code class="docutils literal notranslate"><span class="pre">[1]</span></code> in the formula means the same value if the variable is passed in as an integer. (They can be tuples.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input data shape:  </span><span class="si">{</span><span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The input data shape:  torch.Size([32, 3, 100, 100])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Deciding channels</span>
<span class="n">input_channels</span> <span class="o">=</span> <span class="mi">3</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">output_channels</span> <span class="o">=</span> <span class="mi">128</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Only `kernel_size`</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">7</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">Conv_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span>
                        <span class="n">output_channels</span><span class="p">,</span> 
                        <span class="n">kernel_size</span><span class="p">)</span>
<span class="n">output_res1</span> <span class="o">=</span> <span class="n">Conv_layer1</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conv_layer1 = nn.Conv2d(</span><span class="si">{</span><span class="n">input_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res1 = Conv_layer1(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res1.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;((⌊100 + 2 × 0 - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / 1) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">0</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

Conv_layer1 = nn.Conv2d(3, 128, 7)
output_res1 = Conv_layer1(fake_data)
print(f&quot;The output data shape: {output_res1.shape}&quot;)

#########################################################

Output `H_out` = ((⌊100 + 2 × 0 - 1 × (7 - 1) - 1⌋ / 1) + 1 = 94
The output data shape: torch.Size([32, 128, 94, 94])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Conv_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">output_res1</span> <span class="o">=</span> <span class="n">Conv_layer1</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 128, 94, 94])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title `kernel_size` and `stride`</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">9</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">stride</span> <span class="o">=</span>   <span class="mi">3</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">Conv_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span>
                        <span class="n">output_channels</span><span class="p">,</span> 
                        <span class="n">kernel_size</span><span class="p">,</span> 
                        <span class="n">stride</span><span class="p">)</span>
<span class="n">output_res2</span> <span class="o">=</span> <span class="n">Conv_layer2</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conv_layer2 = nn.Conv2d(</span><span class="si">{</span><span class="n">input_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res2 = Conv_layer2(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res2.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;((⌊100 + 2 × 0 - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">0</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;The output data shape: &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_res2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

Conv_layer2 = nn.Conv2d(3, 128, 9, 3)
output_res2 = Conv_layer2(fake_data)
print(f&quot;The output data shape: {output_res2.shape}&quot;)

#########################################################

Output `H_out` = ((⌊100 + 2 × 0 - 1 × (9 - 1) - 1⌋ / 3) + 1 = 31
The output data shape: torch.Size([32, 128, 31, 31])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Conv_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output_res2</span> <span class="o">=</span> <span class="n">Conv_layer2</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 128, 31, 31])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title `kernel_size` and `padding`</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">3</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">padding</span> <span class="o">=</span>   <span class="mi">1</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">Conv_layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span>
                        <span class="n">output_channels</span><span class="p">,</span> 
                        <span class="n">kernel_size</span><span class="p">,</span> 
                        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">)</span>
<span class="n">output_res3</span> <span class="o">=</span> <span class="n">Conv_layer3</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conv_layer3 = nn.Conv2d(</span><span class="si">{</span><span class="n">input_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, padding=</span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res3 = Conv_layer3(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res3.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;⌊((100 + 2 × </span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2"> - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / 1) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;The output data shape: &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_res3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

Conv_layer3 = nn.Conv2d(3, 128, 3, padding=1)
output_res3 = Conv_layer3(fake_data)
print(f&quot;The output data shape: {output_res3.shape}&quot;)

#########################################################

Output `H_out` = ⌊((100 + 2 × 1 - 1 × (3 - 1) - 1⌋ / 1) + 1 = 100
The output data shape: torch.Size([32, 128, 100, 100])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Conv_layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output_res3</span> <span class="o">=</span> <span class="n">Conv_layer3</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 128, 100, 100])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title `kernel_size`, `stride` and `padding`</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">6</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">stride</span> <span class="o">=</span>   <span class="mi">2</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">padding</span> <span class="o">=</span>   <span class="mi">3</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">Conv_layer4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span>
                        <span class="n">output_channels</span><span class="p">,</span> 
                        <span class="n">kernel_size</span><span class="p">,</span> 
                        <span class="n">stride</span><span class="p">,</span> 
                        <span class="n">padding</span><span class="p">)</span>
<span class="n">output_res4</span> <span class="o">=</span> <span class="n">Conv_layer4</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Conv_layer4 = nn.Conv2d(</span><span class="si">{</span><span class="n">input_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_channels</span><span class="si">}</span><span class="s2">, &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res4 = Conv_layer4(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res4.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;⌊((100 + 2 × </span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2"> - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;The output data shape: &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_res4</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

Conv_layer4 = nn.Conv2d(3, 128, 6, 2, 3)
output_res4 = Conv_layer4(fake_data)
print(f&quot;The output data shape: {output_res4.shape}&quot;)

#########################################################

Output `H_out` = ⌊((100 + 2 × 3 - 1 × (6 - 1) - 1⌋ / 2) + 1 = 51
The output data shape: torch.Size([32, 128, 51, 51])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Conv_layer4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">output_res4</span> <span class="o">=</span> <span class="n">Conv_layer4</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res4</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 128, 51, 51])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="pooling-layers">
<h5><span class="section-number">11.2.3.2.2. </span>Pooling layers<a class="headerlink" href="#pooling-layers" title="Permalink to this headline">¶</a></h5>
<p><code class="docutils literal notranslate"><span class="pre">nn.MaxPool2d</span></code> – Basic 2D Max Pooling Layer</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># stride default: kernel_size</span>
</pre></div>
</div>
<p>Input shape: <span class="math notranslate nohighlight">\((N, C, H_{in}, W_{in})\)</span><br />
Output shape: <span class="math notranslate nohighlight">\((N, C, H_{out}, W_{out})\)</span> where
$<span class="math notranslate nohighlight">\(H_{out}=\left \lfloor \cfrac{H_{in}+ 2 \times \text{padding}[0]-\text{dilation}[0]\times(\text{kernel_size}[0]-1)-1}{\text{stride}[0]} \right \rfloor+1\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(W_{out}=\left \lfloor \cfrac{H_{in}+ 2 \times \text{padding}[1]-\text{dilation}[1]\times(\text{kernel_size}[1]-1)-1}{\text{stride}[1]} \right \rfloor+1\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The input data shape:  </span><span class="si">{</span><span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The input data shape:  torch.Size([32, 3, 100, 100])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Only `kernel_size` {display-mode:&quot;form&quot;}</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">6</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">MaxPool_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
<span class="n">output_res1</span> <span class="o">=</span> <span class="n">MaxPool_layer1</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MaxPool_layer1 = nn.MaxPool2d(</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res1 = MaxPool_layer1(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res1.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;⌊((100 + 2 × 0 - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1) / </span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">⌋ + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">0</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">kernel_size</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

MaxPool_layer1 = nn.MaxPool2d(6)
output_res1 = MaxPool_layer1(fake_data)
print(f&quot;The output data shape: {output_res1.shape}&quot;)

#########################################################

Output `H_out` = ⌊((100 + 2 × 0 - 1 × (6 - 1) - 1) / 6⌋ + 1 = 16
The output data shape: torch.Size([32, 3, 16, 16])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MaxPool_layer1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">output_res1</span> <span class="o">=</span> <span class="n">MaxPool_layer1</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 3, 16, 16])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title `kernel_size` ≠ `stride` {display-mode:&quot;form&quot;}</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">7</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">stride</span> <span class="o">=</span>   <span class="mi">9</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">MaxPool_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
<span class="n">output_res2</span> <span class="o">=</span> <span class="n">MaxPool_layer2</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MaxPool_layer2 = nn.MaxPool2d(</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res2 = MaxPool_layer2(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res2.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;⌊((100 + 2 × 0 - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">0</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

MaxPool_layer2 = nn.MaxPool2d(7, 9)
output_res2 = MaxPool_layer2(fake_data)
print(f&quot;The output data shape: {output_res2.shape}&quot;)

#########################################################

Output `H_out` = ⌊((100 + 2 × 0 - 1 × (7 - 1) - 1⌋ / 9) + 1 = 11
The output data shape: torch.Size([32, 3, 11, 11])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MaxPool_layer2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">output_res2</span> <span class="o">=</span> <span class="n">MaxPool_layer2</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 3, 11, 11])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title `kernel_size`, `stride` and `padding`</span>
<span class="n">kernel_size</span> <span class="o">=</span>   <span class="mi">5</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">stride</span> <span class="o">=</span>   <span class="mi">3</span><span class="c1">#@param {type:&quot;integer&quot;}</span>
<span class="n">padding</span> <span class="o">=</span>   <span class="mi">2</span><span class="c1">#@param {type:&quot;integer&quot;}</span>

<span class="n">MaxPool_layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
<span class="n">output_res3</span> <span class="o">=</span> <span class="n">MaxPool_layer3</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;############### Try the following code... ###############</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;MaxPool_layer3 = nn.MaxPool2d(</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output_res3 = MaxPool_layer3(fake_data)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;print(f</span><span class="se">\&quot;</span><span class="s2">The output data shape: </span><span class="si">{output_res3.shape}</span><span class="se">\&quot;</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">#########################################################</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output `H_out` =&quot;</span><span class="p">,</span>
     <span class="sa">f</span><span class="s2">&quot;⌊((100 + 2 × </span><span class="si">{</span><span class="n">padding</span><span class="si">}</span><span class="s2"> - 1 × (</span><span class="si">{</span><span class="n">kernel_size</span><span class="si">}</span><span class="s2"> - 1) - 1⌋ / </span><span class="si">{</span><span class="n">stride</span><span class="si">}</span><span class="s2">) + 1 =&quot;</span><span class="p">,</span>
      <span class="nb">int</span><span class="p">((</span><span class="mi">100</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">padding</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span> <span class="s2">&quot;The output data shape: &quot;</span>\
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">output_res3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>############### Try the following code... ###############

MaxPool_layer3 = nn.MaxPool2d(5, 3, 2)
output_res3 = MaxPool_layer3(fake_data)
print(f&quot;The output data shape: {output_res3.shape}&quot;)

#########################################################

Output `H_out` = ⌊((100 + 2 × 2 - 1 × (5 - 1) - 1⌋ / 3) + 1 = 34
The output data shape: torch.Size([32, 3, 34, 34])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MaxPool_layer3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">output_res3</span> <span class="o">=</span> <span class="n">MaxPool_layer3</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The output data shape: </span><span class="si">{</span><span class="n">output_res3</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The output data shape: torch.Size([32, 3, 34, 34])
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="rnn">
<h4><span class="section-number">11.2.3.3. </span>RNN<a class="headerlink" href="#rnn" title="Permalink to this headline">¶</a></h4>
<div class="section" id="embedding-layers">
<h5><span class="section-number">11.2.3.3.1. </span>Embedding layers<a class="headerlink" href="#embedding-layers" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Embedding_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">The input data shape:  </span><span class="si">{}</span><span class="s2"></span>
<span class="s2">The output data shape: </span><span class="si">{}</span><span class="s2">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span>
<span class="p">(</span><span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Embedding_layer</span><span class="p">(</span><span class="n">fake_data</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The input data shape:  torch.Size([2, 4])
The output data shape: torch.Size([2, 4, 3])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="loading-word2vec-models">
<h5><span class="section-number">11.2.3.3.2. </span>Loading Word2Vec models<a class="headerlink" href="#loading-word2vec-models" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Embedding_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">w2vmodel</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">Embedding_layer</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">w2vmodel</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span><span class="p">))</span>
<span class="n">fix_embedding</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">Embedding_layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">fix_embedding</span>

<span class="n">word2index</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">ind</span> \
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">w2vmodel</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">index2word</span><span class="p">)}</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Our embedding dimesion is </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w2vmodel</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vector_size</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Our embedding dimesion is 100.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sent_ori</span> <span class="o">=</span> <span class="s2">&quot;The model is used for training.&quot;</span>
<span class="n">sent</span> <span class="o">=</span> <span class="n">sent_ori</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
<span class="n">list_of_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">word2index</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sent</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
<span class="n">tensor_of_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">list_of_indices</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The sentence is:</span><span class="se">\n</span><span class="s2">   </span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">sent_ori</span> <span class="o">+</span> <span class="s1">&#39;&quot;&#39;</span><span class="p">,</span>
<span class="sd">&quot;&quot;&quot;\nWe pass {} tokens into the model,</span>
<span class="sd">    which is treated as a LongTensor with shape &quot;{}&quot;.</span>
<span class="sd">The embedding layer transformed it to shape &quot;{}&quot;.</span>
<span class="sd">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_of_indices</span><span class="p">),</span> 
           <span class="n">tensor_of_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
           <span class="n">Embedding_layer</span><span class="p">(</span><span class="n">tensor_of_indices</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The sentence is:
   &quot; The model is used for training.&quot; 
We pass 6 tokens into the model,
    which is treated as a LongTensor with shape &quot;torch.Size([6])&quot;.
The embedding layer transformed it to shape &quot;torch.Size([6, 100])&quot;.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="rnn-layers-lstm-gru">
<h5><span class="section-number">11.2.3.3.3. </span>RNN layers (LSTM, GRU)<a class="headerlink" href="#rnn-layers-lstm-gru" title="Permalink to this headline">¶</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LSTM_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">LSTM_layer</span><span class="p">(</span><span class="n">fake_data</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Input shape: </span><span class="si">{}</span><span class="s2"></span>
<span class="s2">Output shape: </span><span class="si">{}</span><span class="s2">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">cn</span><span class="o">.</span><span class="n">shape</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input shape: torch.Size([5, 3, 100])
Output shape: (torch.Size([5, 3, 80]), (torch.Size([2, 3, 80]), torch.Size([2, 3, 80])))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">GRU_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">fake_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">GRU_layer</span><span class="p">(</span><span class="n">fake_data</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;Input shape: </span><span class="si">{}</span><span class="s2"></span>
<span class="s2">Output shape: </span><span class="si">{}</span><span class="s2">&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="n">fake_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">hn</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input shape: torch.Size([5, 3, 100])
Output shape: (torch.Size([5, 3, 80]), torch.Size([2, 3, 80]))
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="activation-functions">
<h3><span class="section-number">11.2.4. </span>Activation functions<a class="headerlink" href="#activation-functions" title="Permalink to this headline">¶</a></h3>
<p>You have two choices for your activation functions:</p>
<ol class="simple">
<li><p>In <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code>, we have model layer modules.</p></li>
<li><p>In <code class="docutils literal notranslate"><span class="pre">torch.nn.functionals</span></code>, we have function implementations of activation functions, loss functions, and so on.</p></li>
</ol>
<p>Just to list a few…</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>activation function</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span> <span class="pre">as</span> <span class="pre">nn</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span> <span class="pre">as</span> <span class="pre">F</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>Sigmoid</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sigmoid()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.sigmoid</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>Softmax</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Softmax(dim=None)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.softmax</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>ReLU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.relu</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>LeakyReLU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.LeakyReLU(negative_slope=0.01)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.leaky_relu</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>Tanh</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Tanh()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.tanh</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>GELU</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.GELU()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.gelu</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>ReLU6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU6()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.relu6</span></code></p></td>
</tr>
</tbody>
</table>
<h2>Python Tips</h2>  
<h3>Functions vs. Objects</h3>  
<p>What you get from calling <code class="docutils literal notranslate"><span class="pre">nn.Sigmoid()</span></code> (and others…) is an <b><mark>object</mark></b> initialized from the module.<br />
Hence, if you want to pass a tensor to that “layer object”, you should write this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># `x` is a tensor.</span>
<span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span> <span class="c1"># Note that this is a &quot;constructor&quot;!</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>       <span class="c1"># i.e. `out = nn.Sigmoid()(x)` is valid,</span>
                          <span class="c1"># but the object is discarded if you do that.</span>
</pre></div>
</div>
<p>On the other hand, if you simply want to use functions, do this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># `x` is a tensor.</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>        <span class="c1"># Since `F.sigmoid` is already a &quot;function&quot;!</span>
</pre></div>
</div>
<p>For most time, <b><mark>both are valid</mark></b>. It’s just two coding styles.</p>
</div>
</div>
<div class="section" id="loss-functions">
<h2><span class="section-number">11.3. </span>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>兩種寫 loss 的方式，一種是 class, 一種是 function</p></li>
</ul>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>loss functions</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn</span> <span class="pre">as</span> <span class="pre">nn</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">torch.nn.functional</span> <span class="pre">as</span> <span class="pre">F</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Mean Square Error</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MSELoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.mse_loss(input,</span> <span class="pre">target)</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Cross Entropy (Multi-label)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.cross_entropy(input,</span> <span class="pre">target)</span></code></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Binary Cross Entropy</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BCELoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.binary_cross_entropy(input,</span> <span class="pre">target)</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Negative Log Likelihood</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">NLLLoss()</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">F.nll_loss(F.log_softmax(input),</span> <span class="pre">target)</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="optimizers">
<h2><span class="section-number">11.4. </span>優化器 — Optimizers<a class="headerlink" href="#optimizers" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>用來更新參數的方法（<code class="docutils literal notranslate"><span class="pre">SGD</span></code>、<code class="docutils literal notranslate"><span class="pre">Adagrad</span></code>、<code class="docutils literal notranslate"><span class="pre">Adam</span></code>⋯⋯）</p></li>
<li><p>在 PyTorch 中要經過 <code class="docutils literal notranslate"><span class="pre">backward()</span></code> 函數計算 gradient，</p></li>
<li><p>而在這之前要先用 <code class="docutils literal notranslate"><span class="pre">optim.zero_grad()</span></code> 將 gradient 清掉，否則 PyTorch 會將 gradient 累加起來</p></li>
<li><p>（以下請注意 model 參數更新的方向）</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">small_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Take a look at model params:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">small_model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">7</span><span class="p">,)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Given input X:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">And target Y:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">small_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">The output Y:&quot;</span><span class="p">)</span>
<span class="n">temp_Y</span> <span class="o">=</span> <span class="n">small_model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">temp_Y</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Calculate their MSE Loss = &quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">temp_Y</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">##### Update a step! #####&quot;</span><span class="p">)</span>
<span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Take a look at </span><span class="se">\&quot;</span><span class="s2">updated</span><span class="se">\&quot;</span><span class="s2">model params:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">small_model</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="n">updated_params</span> <span class="o">=</span> <span class="n">small_model</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Take a look at model params:
Parameter containing:
tensor([[ 0.0458,  0.5581,  0.2630],
        [-0.0966, -0.5707, -0.4858],
        [-0.4740, -0.5006, -0.0467],
        [ 0.1894,  0.4758, -0.2796],
        [ 0.3748, -0.0029, -0.3990],
        [-0.3965, -0.2291, -0.5162],
        [ 0.2167,  0.0915, -0.3886]], requires_grad=True)

Given input X:
tensor([0.8153, 0.2770, 0.2055])

And target Y:
tensor([0.2356, 0.1756, 0.9553, 0.8135, 0.6706, 0.7289, 0.2415])

The output Y:
tensor([ 0.3008, -0.7839,  0.0222,  0.2534,  0.7063, -0.1808, -0.2983],
       grad_fn=&lt;AddBackward0&gt;)

Calculate their MSE Loss = 0.461369127035141

##### Update a step! #####

Take a look at &quot;updated&quot;model params:
Parameter containing:
tensor([[ 0.0456,  0.5580,  0.2630],
        [-0.0944, -0.5700, -0.4852],
        [-0.4718, -0.4999, -0.0462],
        [ 0.1907,  0.4762, -0.2792],
        [ 0.3747, -0.0030, -0.3990],
        [-0.3943, -0.2284, -0.5157],
        [ 0.2179,  0.0919, -0.3883]], requires_grad=True)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="normalization">
<h2><span class="section-number">11.5. </span>Normalization<a class="headerlink" href="#normalization" title="Permalink to this headline">¶</a></h2>
<p>PyTorch 提供不少 normalization 的方法，在初期用得到的主要是 CNN 的 batch normalization</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-validation-fine-tuning">
<h2><span class="section-number">11.6. </span>Training (Validation) / Fine-Tuning<a class="headerlink" href="#training-validation-fine-tuning" title="Permalink to this headline">¶</a></h2>
<p>先像上面一樣處理隨機資料</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">TensorDataset</span>

<span class="c1"># Training</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 1000 張 100 x 100 單色圖片</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 1000 個 labels</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="n">tsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">tsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">tsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Validation</span>
<span class="n">vX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 100 張 100 x 100 單色圖片</span>
<span class="n">vY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 100 個 labels</span>

<span class="n">vX</span><span class="p">,</span> <span class="n">vY</span> <span class="o">=</span> <span class="n">vX</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">vY</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">vtsrX</span><span class="p">,</span> <span class="n">vtsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vX</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">vY</span><span class="p">)</span>
<span class="n">vtsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">vtsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">vtsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Validation 不需要 shuffle</span>

<span class="c1"># Testing</span>
<span class="n">tX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># 虛構 100 張 100 x 100 單色圖片</span>
<span class="n">tY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span> <span class="c1"># 虛構 100 個 labels</span>

<span class="n">tX</span><span class="p">,</span> <span class="n">tY</span> <span class="o">=</span> <span class="n">tX</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tY</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">ttsrX</span><span class="p">,</span> <span class="n">ttsrY</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tX</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tY</span><span class="p">)</span>
<span class="n">ttsrdataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">tsrX</span><span class="p">,</span> <span class="n">tsrY</span><span class="p">)</span>

<span class="n">ttsrdataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">ttsrdataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Testing 不需要 shuffle</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div>
</div>
</div>
</div>
<p>在訓練之前，先根據我們前面全部的東西搭一個簡單的 model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">500</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 傳入 model 的函數會經過 forward 做 inference</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># flatten 的意思，原本的 x.size = (batch_size, 100, 100, 1) -&gt; 改成 (batch_size, 100*100*1)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">simpleNN</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>接著準備 optimizer 跟 loss function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">simpleNN</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                         <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>接著進入 training<br />
Training 的本質就是跑一個迴圈，在每一次（叫一個 <strong>epoch</strong>）要做的事有——</p>
<ol class="simple">
<li><p>載入資料</p></li>
<li><p>經過 model 跑一次</p></li>
<li><p>比對資料的正確性，算誤差（loss）</p></li>
<li><p>把梯度清掉，然後根據這次誤差算新的梯度</p></li>
<li><p>根據 optimizer 更新參數</p></li>
<li><p>為了方便觀察，將本次 epoch 訓練的變化顯示出來，包括</p>
<ul class="simple">
<li><p>進度條（觀察訓練快慢）</p></li>
<li><p>batch loss （這個有時候會輸出太多東西）</p></li>
<li><p>epoch loss （記得累計並除掉資料數量）</p></li>
<li><p>記錄到其他變數中（方便作圖）</p></li>
<li><p>記錄到 Tensorboard 中（SummaryWriter）</p></li>
</ul>
</li>
</ol>
<p>為了避免 overfit，我們每個 epoch 還會進行一次 validation，事情少一些，變成——</p>
<ol class="simple">
<li><p>載入資料</p></li>
<li><p>經過 model 跑一次</p></li>
<li><p>比對資料的正確性，算誤差（loss）</p></li>
<li><p>為了方便觀察，將本次 epoch validate 的結果顯示出來，包括</p>
<ul class="simple">
<li><p>進度條（觀察訓練快慢）</p></li>
<li><p>batch loss （這個有時候會輸出太多東西）</p></li>
<li><p>epoch loss （記得累計並除掉資料數量）</p></li>
<li><p>記錄到其他變數中（方便作圖）</p></li>
<li><p>記錄到 Tensorboard 中（SummaryWriter）</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">average_epoch_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">tsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training   Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">average_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">vepoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">vtsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">vepoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">vaverage_epoch_loss</span> <span class="o">=</span> <span class="n">vepoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">vtsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">vaverage_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training   Epoch  1: Loss = 1.1901
Validation Epoch  1: Loss = 0.9613
Training   Epoch  2: Loss = 0.9284
Validation Epoch  2: Loss = 0.7341
Training   Epoch  3: Loss = 0.7754
Validation Epoch  3: Loss = 0.7614
Training   Epoch  4: Loss = 0.6181
Validation Epoch  4: Loss = 0.4514
Training   Epoch  5: Loss = 0.4494
Validation Epoch  5: Loss = 0.3682
Training   Epoch  6: Loss = 0.3269
Validation Epoch  6: Loss = 0.2154
Training   Epoch  7: Loss = 0.2071
Validation Epoch  7: Loss = 0.1433
Training   Epoch  8: Loss = 0.1292
Validation Epoch  8: Loss = 0.1190
Training   Epoch  9: Loss = 0.0766
Validation Epoch  9: Loss = 0.0466
Training   Epoch 10: Loss = 0.0421
Validation Epoch 10: Loss = 0.0397
</pre></div>
</div>
</div>
</div>
<p>嘛⋯⋯畢竟是隨機生成的，所以發生 overfit 什麼的也不要太意外，不過有時好像會 train 起來？？！</p>
<p>覺得跑很慢嗎？我們有 GPU 為什麼不用呢？？！來看看怎麼用！</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">device</span> <span class="c1"># Check if GPU available</span>
<span class="c1"># 其實寫 x.to(device) 之外也可以寫 x.cuda()</span>
<span class="c1"># 但是前者會自動根據環境決定是否使用 GPU 比較彈性</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;cuda&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simpleNN</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                           <span class="c1"># 把 model 移到 GPU 計算</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>        <span class="c1"># 把 x tensor 移到 GPU 計算</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span> <span class="c1"># 把 y tensor 移到 GPU 計算，</span>
                                              <span class="c1">##  y_hat 因為是從 GPU model input GPU Tensor 出來的</span>
                                              <span class="c1">##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">average_epoch_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">tsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training   Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">average_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">vepoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">vtsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">vepoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">vaverage_epoch_loss</span> <span class="o">=</span> <span class="n">vepoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">vtsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">vaverage_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training   Epoch  1: Loss = 1.2024
Validation Epoch  1: Loss = 1.1204
Training   Epoch  2: Loss = 0.9753
Validation Epoch  2: Loss = 0.8663
Training   Epoch  3: Loss = 0.7765
Validation Epoch  3: Loss = 0.5975
Training   Epoch  4: Loss = 0.6070
Validation Epoch  4: Loss = 0.5318
Training   Epoch  5: Loss = 0.4657
Validation Epoch  5: Loss = 0.4495
Training   Epoch  6: Loss = 0.3318
Validation Epoch  6: Loss = 0.2707
Training   Epoch  7: Loss = 0.2139
Validation Epoch  7: Loss = 0.2161
Training   Epoch  8: Loss = 0.1349
Validation Epoch  8: Loss = 0.0770
Training   Epoch  9: Loss = 0.0797
Validation Epoch  9: Loss = 0.0439
Training   Epoch 10: Loss = 0.0440
Validation Epoch 10: Loss = 0.0437
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-saving-loading-checkpoints">
<h3><span class="section-number">11.6.1. </span>– Model saving / loading (checkpoints)<a class="headerlink" href="#model-saving-loading-checkpoints" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save model</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="c1"># 先移回 CPU</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">simpleNN</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;randmodel.model&quot;</span><span class="p">)</span>

<span class="c1"># Load model</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="n">model2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;randmodel.model&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;All keys matched successfully&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 確認是同一個 model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">model2</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="testing-evaluation">
<h2><span class="section-number">11.7. </span>4. Testing / Evaluation<a class="headerlink" href="#testing-evaluation" title="Permalink to this headline">¶</a></h2>
<p>這裡當然也可以開 GPU，用法相同</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">tepoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ttsrdataloader</span><span class="p">:</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
    <span class="n">tepoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">taverage_epoch_loss</span> <span class="o">=</span> <span class="n">tepoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ttsrdataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Testing Loss = </span><span class="si">{</span><span class="n">taverage_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing Loss = 0.0437
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="result-post-processing">
<h2><span class="section-number">11.8. </span>5. Result Post-processing<a class="headerlink" href="#result-post-processing" title="Permalink to this headline">¶</a></h2>
<div class="section" id="saving-files">
<h3><span class="section-number">11.8.1. </span>1 – Saving files<a class="headerlink" href="#saving-files" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;loss.txt&quot;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">taverage_epoch_loss</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>如果已經把答案存成一個 np.array 或 list，叫做 <code class="docutils literal notranslate"><span class="pre">answer</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;result.csv&quot;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;index,ans</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">answer</span><span class="p">):</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="kaggle-upload">
<h3><span class="section-number">11.8.2. </span>2 – Kaggle Upload<a class="headerlink" href="#kaggle-upload" title="Permalink to this headline">¶</a></h3>
<p>Kaggle 有提供方便的 API 可以直接在 Colab 或是 terminal 上傳，只要先弄好 token，以下列指令</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kaggle competitions submit -c &lt;competition_name&gt; -f &lt;filename&gt; -m &lt;message&gt;
</pre></div>
</div>
<p>就可以上傳，例如作業３</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kaggle competitions submit -c ml2020spring-hw3 -f result.csv -m <span class="s2">&quot;The first try!&quot;</span>
</pre></div>
</div>
<p>另外要看自己的 submissions</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># kaggle competitions submissions -c &lt;competition_name&gt;</span>
  kaggle competitions submissions -c ml2020spring-hw3
</pre></div>
</div>
<p>或是排行榜</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># kaggle competitions leaderboard -c &lt;competition_name&gt; --show</span>
  kaggle competitions leaderboard -c ml2020spring-hw3 --show
</pre></div>
</div>
<p>（記得把競賽名對應改掉）</p>
</div>
<div class="section" id="colaboratory-kaggle-notebook">
<h3><span class="section-number">11.8.3. </span>3 – Colaboratory / Kaggle Notebook<a class="headerlink" href="#colaboratory-kaggle-notebook" title="Permalink to this headline">¶</a></h3>
<p>你現在在用的這個環境本質是 Jupyter Notebook，Kaggle 也有提供一樣的環境可以操作<br />
（不過在比賽中還是不要用的好，大家都想先藏招嘛！ B-) ）</p>
<p><img alt="" src="https://i.imgur.com/YCiTKl9.png" /></p>
<p>另外 Jupyter Notebook 也是可以開本地端的（如去年和前年有 DeepQ 贊助運算資源即是以此為介面）</p>
</div>
</div>
<div class="section" id="visualization">
<h2><span class="section-number">11.9. </span>6. Visualization<a class="headerlink" href="#visualization" title="Permalink to this headline">¶</a></h2>
<div class="section" id="tensorboard">
<h3><span class="section-number">11.9.1. </span>TensorBoard<a class="headerlink" href="#tensorboard" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> tensorboard
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">logs_base_dir</span> <span class="o">=</span> <span class="s2">&quot;runs&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">logs_base_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">tensorboard</span> --logdir {logs_base_dir}
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output hidden; open in https://colab.research.google.com to view.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.tensorboard</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>
<span class="n">tb</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">()</span>

<span class="n">simpleNN</span> <span class="o">=</span> <span class="n">SimpleNN</span><span class="p">()</span>
<span class="n">simpleNN</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>                           <span class="c1"># 把 model 移到 GPU 計算</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">simpleNN</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>        <span class="c1"># 把 x tensor 移到 GPU 計算</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span> <span class="c1"># 把 y tensor 移到 GPU 計算，</span>
                                              <span class="c1">##  y_hat 因為是從 GPU model input GPU Tensor 出來的</span>
                                              <span class="c1">##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">average_epoch_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">tsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training   Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">average_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;Loss/train&quot;</span><span class="p">,</span> <span class="n">average_epoch_loss</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 加這個</span>

    <span class="n">simpleNN</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">vepoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">vtsrdataloader</span><span class="p">:</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">simpleNN</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">vepoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">vaverage_epoch_loss</span> <span class="o">=</span> <span class="n">vepoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">vtsrdataset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">:</span><span class="s2">2d</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">vaverage_epoch_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="s2">&quot;Loss/val&quot;</span><span class="p">,</span> <span class="n">vaverage_epoch_loss</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 加這個</span>
<span class="n">tb</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># 加這個</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training   Epoch  1: Loss = 1.1834
Validation Epoch  1: Loss = 0.9316
Training   Epoch  2: Loss = 0.9446
Validation Epoch  2: Loss = 0.7346
Training   Epoch  3: Loss = 0.7585
Validation Epoch  3: Loss = 0.5875
Training   Epoch  4: Loss = 0.6048
Validation Epoch  4: Loss = 0.4823
Training   Epoch  5: Loss = 0.4672
Validation Epoch  5: Loss = 0.3465
Training   Epoch  6: Loss = 0.3253
Validation Epoch  6: Loss = 0.2362
Training   Epoch  7: Loss = 0.2127
Validation Epoch  7: Loss = 0.1778
Training   Epoch  8: Loss = 0.1236
Validation Epoch  8: Loss = 0.0781
Training   Epoch  9: Loss = 0.0720
Validation Epoch  9: Loss = 0.0429
Training   Epoch 10: Loss = 0.0419
Validation Epoch 10: Loss = 0.0446
Training   Epoch 11: Loss = 0.0238
Validation Epoch 11: Loss = 0.0203
Training   Epoch 12: Loss = 0.0134
Validation Epoch 12: Loss = 0.0114
Training   Epoch 13: Loss = 0.0080
Validation Epoch 13: Loss = 0.0060
Training   Epoch 14: Loss = 0.0057
Validation Epoch 14: Loss = 0.0042
Training   Epoch 15: Loss = 0.0042
Validation Epoch 15: Loss = 0.0046
Training   Epoch 16: Loss = 0.0039
Validation Epoch 16: Loss = 0.0037
Training   Epoch 17: Loss = 0.0051
Validation Epoch 17: Loss = 0.0044
Training   Epoch 18: Loss = 0.0083
Validation Epoch 18: Loss = 0.0175
Training   Epoch 19: Loss = 0.0155
Validation Epoch 19: Loss = 0.0206
Training   Epoch 20: Loss = 0.0254
Validation Epoch 20: Loss = 0.0372
Training   Epoch 21: Loss = 0.0360
Validation Epoch 21: Loss = 0.0306
Training   Epoch 22: Loss = 0.0401
Validation Epoch 22: Loss = 0.0264
Training   Epoch 23: Loss = 0.0352
Validation Epoch 23: Loss = 0.0388
Training   Epoch 24: Loss = 0.0277
Validation Epoch 24: Loss = 0.0459
Training   Epoch 25: Loss = 0.0207
Validation Epoch 25: Loss = 0.0216
Training   Epoch 26: Loss = 0.0155
Validation Epoch 26: Loss = 0.0207
Training   Epoch 27: Loss = 0.0126
Validation Epoch 27: Loss = 0.0141
Training   Epoch 28: Loss = 0.0142
Validation Epoch 28: Loss = 0.0088
Training   Epoch 29: Loss = 0.0180
Validation Epoch 29: Loss = 0.0158
Training   Epoch 30: Loss = 0.0196
Validation Epoch 30: Loss = 0.0444
Training   Epoch 31: Loss = 0.0198
Validation Epoch 31: Loss = 0.0188
Training   Epoch 32: Loss = 0.0196
Validation Epoch 32: Loss = 0.0106
Training   Epoch 33: Loss = 0.0201
Validation Epoch 33: Loss = 0.0154
Training   Epoch 34: Loss = 0.0218
Validation Epoch 34: Loss = 0.0219
Training   Epoch 35: Loss = 0.0198
Validation Epoch 35: Loss = 0.0109
Training   Epoch 36: Loss = 0.0178
Validation Epoch 36: Loss = 0.0177
Training   Epoch 37: Loss = 0.0143
Validation Epoch 37: Loss = 0.0103
Training   Epoch 38: Loss = 0.0115
Validation Epoch 38: Loss = 0.0174
Training   Epoch 39: Loss = 0.0124
Validation Epoch 39: Loss = 0.0113
Training   Epoch 40: Loss = 0.0152
Validation Epoch 40: Loss = 0.0164
Training   Epoch 41: Loss = 0.0164
Validation Epoch 41: Loss = 0.0099
Training   Epoch 42: Loss = 0.0166
Validation Epoch 42: Loss = 0.0201
Training   Epoch 43: Loss = 0.0181
Validation Epoch 43: Loss = 0.0160
Training   Epoch 44: Loss = 0.0176
Validation Epoch 44: Loss = 0.0139
Training   Epoch 45: Loss = 0.0156
Validation Epoch 45: Loss = 0.0113
Training   Epoch 46: Loss = 0.0148
Validation Epoch 46: Loss = 0.0147
Training   Epoch 47: Loss = 0.0152
Validation Epoch 47: Loss = 0.0109
Training   Epoch 48: Loss = 0.0141
Validation Epoch 48: Loss = 0.0201
Training   Epoch 49: Loss = 0.0140
Validation Epoch 49: Loss = 0.0077
Training   Epoch 50: Loss = 0.0133
Validation Epoch 50: Loss = 0.0078
Training   Epoch 51: Loss = 0.0129
Validation Epoch 51: Loss = 0.0124
Training   Epoch 52: Loss = 0.0136
Validation Epoch 52: Loss = 0.0131
Training   Epoch 53: Loss = 0.0139
Validation Epoch 53: Loss = 0.0105
Training   Epoch 54: Loss = 0.0125
Validation Epoch 54: Loss = 0.0179
Training   Epoch 55: Loss = 0.0131
Validation Epoch 55: Loss = 0.0170
Training   Epoch 56: Loss = 0.0134
Validation Epoch 56: Loss = 0.0118
Training   Epoch 57: Loss = 0.0133
Validation Epoch 57: Loss = 0.0114
Training   Epoch 58: Loss = 0.0144
Validation Epoch 58: Loss = 0.0232
Training   Epoch 59: Loss = 0.0137
Validation Epoch 59: Loss = 0.0176
Training   Epoch 60: Loss = 0.0131
Validation Epoch 60: Loss = 0.0144
Training   Epoch 61: Loss = 0.0130
Validation Epoch 61: Loss = 0.0108
Training   Epoch 62: Loss = 0.0133
Validation Epoch 62: Loss = 0.0094
Training   Epoch 63: Loss = 0.0119
Validation Epoch 63: Loss = 0.0103
Training   Epoch 64: Loss = 0.0116
Validation Epoch 64: Loss = 0.0119
Training   Epoch 65: Loss = 0.0120
Validation Epoch 65: Loss = 0.0076
Training   Epoch 66: Loss = 0.0116
Validation Epoch 66: Loss = 0.0143
Training   Epoch 67: Loss = 0.0111
Validation Epoch 67: Loss = 0.0100
Training   Epoch 68: Loss = 0.0101
Validation Epoch 68: Loss = 0.0084
Training   Epoch 69: Loss = 0.0114
Validation Epoch 69: Loss = 0.0094
Training   Epoch 70: Loss = 0.0121
Validation Epoch 70: Loss = 0.0145
Training   Epoch 71: Loss = 0.0118
Validation Epoch 71: Loss = 0.0092
Training   Epoch 72: Loss = 0.0113
Validation Epoch 72: Loss = 0.0101
Training   Epoch 73: Loss = 0.0106
Validation Epoch 73: Loss = 0.0184
Training   Epoch 74: Loss = 0.0100
Validation Epoch 74: Loss = 0.0068
Training   Epoch 75: Loss = 0.0092
Validation Epoch 75: Loss = 0.0163
Training   Epoch 76: Loss = 0.0099
Validation Epoch 76: Loss = 0.0082
Training   Epoch 77: Loss = 0.0111
Validation Epoch 77: Loss = 0.0103
Training   Epoch 78: Loss = 0.0116
Validation Epoch 78: Loss = 0.0123
Training   Epoch 79: Loss = 0.0120
Validation Epoch 79: Loss = 0.0136
Training   Epoch 80: Loss = 0.0117
Validation Epoch 80: Loss = 0.0143
Training   Epoch 81: Loss = 0.0113
Validation Epoch 81: Loss = 0.0116
Training   Epoch 82: Loss = 0.0105
Validation Epoch 82: Loss = 0.0066
Training   Epoch 83: Loss = 0.0097
Validation Epoch 83: Loss = 0.0125
Training   Epoch 84: Loss = 0.0093
Validation Epoch 84: Loss = 0.0115
Training   Epoch 85: Loss = 0.0092
Validation Epoch 85: Loss = 0.0080
Training   Epoch 86: Loss = 0.0099
Validation Epoch 86: Loss = 0.0089
Training   Epoch 87: Loss = 0.0099
Validation Epoch 87: Loss = 0.0088
Training   Epoch 88: Loss = 0.0104
Validation Epoch 88: Loss = 0.0086
Training   Epoch 89: Loss = 0.0101
Validation Epoch 89: Loss = 0.0074
Training   Epoch 90: Loss = 0.0092
Validation Epoch 90: Loss = 0.0128
Training   Epoch 91: Loss = 0.0092
Validation Epoch 91: Loss = 0.0076
Training   Epoch 92: Loss = 0.0081
Validation Epoch 92: Loss = 0.0071
Training   Epoch 93: Loss = 0.0076
Validation Epoch 93: Loss = 0.0083
Training   Epoch 94: Loss = 0.0078
Validation Epoch 94: Loss = 0.0072
Training   Epoch 95: Loss = 0.0108
Validation Epoch 95: Loss = 0.0097
Training   Epoch 96: Loss = 0.0129
Validation Epoch 96: Loss = 0.0126
Training   Epoch 97: Loss = 0.0123
Validation Epoch 97: Loss = 0.0091
Training   Epoch 98: Loss = 0.0093
Validation Epoch 98: Loss = 0.0105
Training   Epoch 99: Loss = 0.0075
Validation Epoch 99: Loss = 0.0088
Training   Epoch 100: Loss = 0.0072
Validation Epoch 100: Loss = 0.0115
</pre></div>
</div>
</div>
</div>
<p>應該會像這樣子（左下角只會有一個顏色才是，此處請忽略）
<img alt="" src="https://i.imgur.com/25qVrAH.png" /></p>
</div>
</div>
<div class="section" id="gpu-usage">
<h2><span class="section-number">11.10. </span>7. GPU Usage<a class="headerlink" href="#gpu-usage" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="k">bash</span>
nvidia-smi
echo
echo &quot;沒有跑出來請看下面&quot;
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Wed Mar 25 22:22:23 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |
| N/A   39C    P0    32W / 250W |    877MiB / 16280MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+

沒有跑出來請看下面
</pre></div>
</div>
</div>
</div>
<div class="section" id="colaboratory">
<h3><span class="section-number">11.10.1. </span>1 – Colaboratory<a class="headerlink" href="#colaboratory" title="Permalink to this headline">¶</a></h3>
<ol class="simple">
<li><p>如果不知道怎麼切 GPU 的，看左上角<br />
<img alt="" src="https://i.imgur.com/ZuZSvKe.png" /></p></li>
<li><p>然後<br />
<img alt="" src="https://i.imgur.com/wLmRD3V.png" /><br />
其實還有 TPU 可以用，就自己去研究吧！</p></li>
</ol>
</div>
<div class="section" id="pbs-usage">
<h3><span class="section-number">11.10.2. </span>2 – PBS Usage<a class="headerlink" href="#pbs-usage" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa">這裡</a>有我之前錄製的用法，如果有人有機會用到計中或臺灣杉之類的排程工作站可以學一下</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%html</span>
<span class="p">&lt;</span><span class="nt">script</span> <span class="na">id</span><span class="o">=</span><span class="s">&quot;asciicast-T10wcvFwIzXgH4ZdERexBjtKa&quot;</span> <span class="na">src</span><span class="o">=</span><span class="s">&quot;https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa.js&quot;</span> <span class="na">async</span><span class="p">&gt;&lt;/</span><span class="nt">script</span><span class="p">&gt;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><script id="asciicast-T10wcvFwIzXgH4ZdERexBjtKa" src="https://asciinema.org/a/T10wcvFwIzXgH4ZdERexBjtKa.js" async></script></div></div>
</div>
</div>
</div>
<div class="section" id="todo-for-next-version">
<h2><span class="section-number">11.11. </span>TODO for next version<a class="headerlink" href="#todo-for-next-version" title="Permalink to this headline">¶</a></h2>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> argparse</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> Transformer 用法</p></li>
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> Colab 其他進階用法</p></li>
</ul>
<div class="section" id="useful-tips">
<h3><span class="section-number">11.11.1. </span>Useful tips<a class="headerlink" href="#useful-tips" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Save at best</p></li>
<li><p>Early Stopping</p></li>
<li><p>Learning rate scheduler</p></li>
</ul>
</div>
<div class="section" id="id1">
<h3><span class="section-number">11.11.2. </span>Visualization<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Matplotlib Usage</p></li>
</ul>
</div>
<div class="section" id="jupyter-vscode-connect-to-runtime">
<h3><span class="section-number">11.11.3. </span>Jupyter / VSCode （Connect to runtime）<a class="headerlink" href="#jupyter-vscode-connect-to-runtime" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="more-examples">
<h3><span class="section-number">11.11.4. </span>More Examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¶</a></h3>
<ul class="contains-task-list simple">
<li class="task-list-item"><p><input class="task-list-item-checkbox" disabled="disabled" type="checkbox"> MNIST</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./pytorch/ch0_pytorch_tutorial"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../../hands_on_ml3/tf_customization.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">10. </span>Customization</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book Community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>