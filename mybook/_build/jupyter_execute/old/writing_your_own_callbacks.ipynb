{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* keras 在 training, evaluation, 和 inference 的時候，會對應到 `model.fit()`, `model.evaluate()` 和 `model.predict()` 這三個高階的 function. \n",
    "* 這三個高階的 function，運行過程中都幫你做了很多事，而 `callbacks`，就是用來客製化這三個 function 進行過程中的行為\n",
    "* callback 可以介入的時間點包括：\n",
    "  * Global methods:\n",
    "    * on_(train|test|predict)_begin(self, logs=None): Called at the beginning of fit/evaluate/predict。例如：\n",
    "    * on_(train|test|predict)_end(self, logs=None): Called at the end of fit/evaluate/predict。例如：\n",
    "  * Batch-level methods for training/testing/predicting\n",
    "    * on_(train|test|predict)_batch_begin(self, batch, logs=None): Called right before processing a batch during training/testing/predicting。\n",
    "    * on_(train|test|predict)_batch_end(self, batch, logs=None): Called at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the metrics results.\n",
    "  * Epoch-level methods (training only)\n",
    "    * on_epoch_begin(self, epoch, logs=None): Called at the beginning of an epoch during training.\n",
    "    * on_epoch_end(self, epoch, logs=None): Called at the end of an epoch during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Question: MNIST 分類問題\n",
    "\n",
    "# model\n",
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(1, input_dim=784))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[\"mean_absolute_error\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# data & preprocess\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "\n",
    "# Limit the data to 1000 samples\n",
    "x_train = x_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "# model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainingCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"Starting training; got log keys: {keys}\")\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"Start epoch {epoch} of training; got log keys: {keys}\")\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"...Training: start of batch {batch}; got log keys: {keys}\")\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"...Training: end of batch {batch}; got log keys: {keys}\")\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"End epoch {epoch} of training; got log keys: {keys}\")\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(f\"Stop training; got log keys: {keys}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 從上面的定義，可以看到，他把 training 會經過的各個階段都定義了：  \n",
    "  * training 開始前，我們可以做一些事 (e.g. 這邊就只是列出，這個階段的 logs 字典，裡面有哪些 key)\n",
    "  * epoch 開始前，我們可以做哪些事\n",
    "  * 每個 batch 開始前，我們可以做哪些事  \n",
    "  * 每個 batch 結束時，系統會預設幫你算 training loss/metric，所以這時可以看到 log 的 key，就是你有定義的 loss/metric\n",
    "  * epoch 結束時，系統也會預設幫你算整個 epoch 下來的 training loss/metric，以及 evaluate 在 validation 上的 loss/metric。 所以這時的 log 的 key，也應該看到這些 loss/metric/val_loss/val_metric \n",
    "  * training 結束時，會把各個 epoch 結束時結算的 loss/metric/val_loss/val_metric 一起收起來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training; got log keys: []\n",
      "Start epoch 0 of training; got log keys: []\n",
      "...Training: start of batch 0; got log keys: []\n",
      "...Training: end of batch 0; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 1; got log keys: []\n",
      "...Training: end of batch 1; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 2; got log keys: []\n",
      "...Training: end of batch 2; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 3; got log keys: []\n",
      "...Training: end of batch 3; got log keys: ['loss', 'mean_absolute_error']\n",
      "End epoch 0 of training; got log keys: ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']\n",
      "Start epoch 1 of training; got log keys: []\n",
      "...Training: start of batch 0; got log keys: []\n",
      "...Training: end of batch 0; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 1; got log keys: []\n",
      "...Training: end of batch 1; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 2; got log keys: []\n",
      "...Training: end of batch 2; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Training: start of batch 3; got log keys: []\n",
      "...Training: end of batch 3; got log keys: ['loss', 'mean_absolute_error']\n",
      "End epoch 1 of training; got log keys: ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']\n",
      "Stop training; got log keys: ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    verbose=0,\n",
    "    validation_split=0.5,\n",
    "    callbacks=[CustomTrainingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 和前面想的一樣  \n",
    "* 再看一下 history 物件，就可以看到，這就是 stop training 時的最終 log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [214.4588165283203, 5.383535861968994],\n",
       " 'mean_absolute_error': [9.524913787841797, 1.912700891494751],\n",
       " 'val_loss': [6.457273960113525, 4.805582046508789],\n",
       " 'val_mean_absolute_error': [2.095306873321533, 1.7563560009002686]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestingCallback(keras.callbacks.Callback):    \n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    \n",
    "    def on_test_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop testing; got log keys: {}\".format(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing; got log keys: []\n",
      "...Evaluating: start of batch 0; got log keys: []\n",
      "...Evaluating: end of batch 0; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 1; got log keys: []\n",
      "...Evaluating: end of batch 1; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 2; got log keys: []\n",
      "...Evaluating: end of batch 2; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 3; got log keys: []\n",
      "...Evaluating: end of batch 3; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 4; got log keys: []\n",
      "...Evaluating: end of batch 4; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 5; got log keys: []\n",
      "...Evaluating: end of batch 5; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 6; got log keys: []\n",
      "...Evaluating: end of batch 6; got log keys: ['loss', 'mean_absolute_error']\n",
      "...Evaluating: start of batch 7; got log keys: []\n",
      "...Evaluating: end of batch 7; got log keys: ['loss', 'mean_absolute_error']\n",
      "Stop testing; got log keys: ['loss', 'mean_absolute_error']\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(\n",
    "    x_test, y_test, batch_size=128, verbose=0, callbacks=[CustomTestingCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPredictCallback(keras.callbacks.Callback):    \n",
    "    \n",
    "    def on_predict_begin(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Start predicting; got log keys: {}\".format(keys))    \n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "    \n",
    "    def on_predict_end(self, logs=None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop predicting; got log keys: {}\".format(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting; got log keys: []\n",
      "...Predicting: start of batch 0; got log keys: []\n",
      "...Predicting: end of batch 0; got log keys: ['outputs']\n",
      "...Predicting: start of batch 1; got log keys: []\n",
      "...Predicting: end of batch 1; got log keys: ['outputs']\n",
      "...Predicting: start of batch 2; got log keys: []\n",
      "...Predicting: end of batch 2; got log keys: ['outputs']\n",
      "...Predicting: start of batch 3; got log keys: []\n",
      "...Predicting: end of batch 3; got log keys: ['outputs']\n",
      "...Predicting: start of batch 4; got log keys: []\n",
      "...Predicting: end of batch 4; got log keys: ['outputs']\n",
      "...Predicting: start of batch 5; got log keys: []\n",
      "...Predicting: end of batch 5; got log keys: ['outputs']\n",
      "...Predicting: start of batch 6; got log keys: []\n",
      "...Predicting: end of batch 6; got log keys: ['outputs']\n",
      "...Predicting: start of batch 7; got log keys: []\n",
      "...Predicting: end of batch 7; got log keys: ['outputs']\n",
      "Stop predicting; got log keys: []\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(x_test, batch_size=128, callbacks=[CustomPredictCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `logs` dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如上面所見， logs 就是個 dictionary，他會在：  \n",
    "  * 每個 batch 結束時，紀錄 training 的 loss/metrics\n",
    "  * 每個 epoch 結束時，紀錄 training 和 validation 的 loss/metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `self.model` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模仿 fit 的 verbose 行為"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 想做的就是：\n",
    "  * 每個 batch 結束 print loss\n",
    "  * 每個 epoch 結束，print training & validation 的 loss/metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MimicFitVerbose(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"Start epoch {epoch} of training\")\n",
    "    \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\n",
    "            f\"Up to batch {batch}, the average loss is {logs['loss']}\"\n",
    "        )    \n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\n",
    "            f\"Up to batch {batch}, the average loss is {logs['loss']}\"\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\n",
    "            \"The average loss for epoch {} is {:7.2f} \"\n",
    "            \"and mean absolute error is {:7.2f}.\".format(\n",
    "                epoch, logs[\"loss\"], logs[\"mean_absolute_error\"]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0 of training\n",
      "Up to batch 0, the average loss is 28.585102081298828\n",
      "Up to batch 1, the average loss is 422.77685546875\n",
      "Up to batch 2, the average loss is 290.0121765136719\n",
      "Up to batch 3, the average loss is 219.7867889404297\n",
      "Up to batch 4, the average loss is 177.09408569335938\n",
      "Up to batch 5, the average loss is 148.7606964111328\n",
      "Up to batch 6, the average loss is 128.3433837890625\n",
      "Up to batch 7, the average loss is 115.52252197265625\n",
      "The average loss for epoch 0 is  115.52 and mean absolute error is    5.87.\n",
      "Start epoch 1 of training\n",
      "Up to batch 0, the average loss is 4.604754447937012\n",
      "Up to batch 1, the average loss is 4.610485553741455\n",
      "Up to batch 2, the average loss is 4.679413318634033\n",
      "Up to batch 3, the average loss is 4.785181999206543\n",
      "Up to batch 4, the average loss is 4.626808166503906\n",
      "Up to batch 5, the average loss is 4.516804218292236\n",
      "Up to batch 6, the average loss is 4.380861282348633\n",
      "Up to batch 7, the average loss is 4.522708415985107\n",
      "The average loss for epoch 1 is    4.52 and mean absolute error is    1.69.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149da5f70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    verbose=0,\n",
    "    callbacks=[MimicFitVerbose()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}