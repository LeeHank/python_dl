{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkQwGmM64L88"
   },
   "source": [
    "# Pytorch Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2mIcaFQ4L9A"
   },
   "source": [
    "* settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33333,
     "status": "ok",
     "timestamp": 1671629496799,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "zEROVAar4L9C",
    "outputId": "173ff722-413d-4b3f-eb3f-884984624eb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2021,
     "status": "ok",
     "timestamp": 1671629567419,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "1ND4WTmJ4L9D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/0. codepool_python/python_dl/mybook/pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 3763,
     "status": "ok",
     "timestamp": 1671629573162,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "I2RfHMp54L9E"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOB3V12G4L9E"
   },
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 tensor 的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.empty(), torch.zeros(), torch.ones(), torch.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, -0.0000e+00, 0.0000e+00, -0.0000e+00],\n",
      "        [1.1210e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# 建立出指定 shape 的 placeholder\n",
    "x = torch.empty(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 這些數字都是假的，實際上只是在 memory 上幫你開好 (3, 4) 這種 shape 的 placeholder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6128, 0.1519, 0.0453],\n",
       "        [0.5035, 0.9978, 0.3884]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 3) # 生出 0~1 的隨機數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.manual_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 設 seed 後，接續的第一、第二...、第 n 次生成，結果會不同，但只要再設一次 seed，那結果就會和之前的第一、第二、...、第 n 次相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.empty_like(), torch.zeros_like(), torch.ones_like(), torch.rand_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.0000e+00, -0.0000e+00, 0.0000e+00],\n",
      "         [-0.0000e+00, 5.6107e-18, 4.5901e-41]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00,        nan, 0.0000e+00]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0.0000e+00, -0.0000e+00,  8.3198e+01],\n",
      "         [-2.5250e-29,  2.1071e-08,  1.4013e-45]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00,  1.4013e-45],\n",
      "         [ 0.0000e+00,  2.0860e-13,  4.5901e-41]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]],\n",
      "\n",
      "        [[0.5062, 0.8469, 0.2588],\n",
      "         [0.2707, 0.4115, 0.6839]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dtype = torch.int16` and `tensor_obj.to(torch.int32)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 常見的 dtype\n",
    "  * torch.bool\n",
    "  * torch.int8\n",
    "  * torch.uint8\n",
    "  * torch.int16\n",
    "  * torch.int32\n",
    "  * torch.int64\n",
    "  * torch.half\n",
    "  * torch.float\n",
    "  * torch.double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 建立想要的 dtype 的 3 種方式:  \n",
    "  * 直接給小數點. \n",
    "  * 用 dtype = ...  \n",
    "  * 用 tensor_obj.to(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 2.7183],\n",
      "        [1.6180, 0.0073]])\n",
      "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# 直接給小數點\n",
    "\n",
    "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
    "print(some_constants)\n",
    "\n",
    "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
    "print(some_integers)\n",
    "\n",
    "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
    "print(more_integers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[11.2406, 11.2083, 11.6692],\n",
      "        [18.3283,  0.2118, 18.4972]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 指定 type\n",
    "a = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 11, 11],\n",
      "        [18,  0, 18]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 轉換 type\n",
    "c = b.to(torch.int32)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor_obj.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensor 是 mutable 的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., 561.],\n",
      "        [  1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a\n",
    "\n",
    "a[0][1] = 561  # we change a...\n",
    "print(b)       # ...and b is also altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 所以記得用 tensro_obj.clone() 來做 copy (就是 df.copy() 的類似寫法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a.clone()\n",
    "\n",
    "assert b is not a      # different objects in memory...\n",
    "print(torch.eq(a, b))  # ...but still with the same contents!\n",
    "\n",
    "a[0][1] = 561          # a changes...\n",
    "print(b)               # ...but b is still all ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor_obj.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .detach() 的意思，主要就是刪掉 gradient 紀錄  \n",
    "* 這主要是用在：\n",
    "  * NN 計算到一半時，你想拿某個中間產物，出去算一些暫時的結果，然後再回來. \n",
    "  * 這時，你不希望中間跑出去算的哪些過程，也被記錄下來，導致去做 backpropagation 時，還會更新到那些 gradient，進而影想到真正的 variable 的 gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6865, 0.3614],\n",
      "        [0.6493, 0.2633]], requires_grad=True)\n",
      "tensor([[0.6865, 0.3614],\n",
      "        [0.6493, 0.2633]], grad_fn=<CloneBackward0>)\n",
      "tensor([[0.6865, 0.3614],\n",
      "        [0.6493, 0.2633]])\n",
      "tensor([[0.6865, 0.3614],\n",
      "        [0.6493, 0.2633]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
    "print(a)\n",
    "\n",
    "b = a.clone()\n",
    "print(b)\n",
    "\n",
    "c = a.detach().clone()\n",
    "print(c)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 解釋一下這邊發生的事：  \n",
    "  * 我們用 `requires_grad = True` 建立了 a ，所以去 print(a) 時，他告訴我們： requires_grad = True，表示 autograd 和 computation history tracking 都有被 turn on. \n",
    "  * 當我們單純把 a clone 到 b 時，他不僅繼承了 a 的 requires_grad，他也記錄了你的這次 computation history: clone，所以寫成 CloneBackward. \n",
    "  * 但如果我們先把 a detach，再把 a clone 給 c，就可以發現 c 乾乾淨淨的沒有任何 gradient 的痕跡。  \n",
    "  * `detach()` 會 detaches the tensor from its computation history。他等於在說：不管接下來你要做啥計算，都把 autograd 給關起來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `tensor_obj.unsqueeze(dim=xx)` 增軸; `tensor_obj.squeeze(dim=xx)` 減軸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 我們常常想把單一一張 img 的 shape，增軸成 batch = 1 的一張 img (i.e. 把 shape = (3, 266, 266) 增軸成 (1, 3, 266, 266))\n",
    "* 那 unsqueeze 就是增軸，例如這邊，我想增在 第 0 軸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3, 226, 226)\n",
    "print(a.shape)\n",
    "\n",
    "b = a.unsqueeze(dim = 0)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 相反的，我們有時候拿到帶有 batch 資訊的資料時，我們想把他 un-batch. \n",
    "* 例如，我拿到 shape = (1, 1) 的 output，但最前面的 1 其實是 batch_size，他就等於 1 而已. \n",
    "* 我想把他拔掉，就用 squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6759]])\n",
      "torch.Size([1, 1])\n",
      "tensor([0.6759])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,1)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "\n",
    "b = a.squeeze(dim = 0)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[0.0746, 0.2186, 0.8389, 0.3639, 0.2582, 0.1838, 0.3514, 0.2332, 0.5520,\n",
      "         0.4285, 0.5416, 0.2346, 0.0468, 0.4869, 0.5096, 0.9663, 0.0631, 0.1065,\n",
      "         0.7211, 0.5715]])\n",
      "torch.Size([20])\n",
      "tensor([0.0746, 0.2186, 0.8389, 0.3639, 0.2582, 0.1838, 0.3514, 0.2332, 0.5520,\n",
      "        0.4285, 0.5416, 0.2346, 0.0468, 0.4869, 0.5096, 0.9663, 0.0631, 0.1065,\n",
      "        0.7211, 0.5715])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 20)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "b = a.squeeze(0)\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pytorch 很聰明的，如果你的原始軸不是 1 ，他不會幫你 squeeze，例如下例就沒改變任何東西："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1736, 0.8499],\n",
      "        [0.9200, 0.4837]])\n",
      "torch.Size([2, 2])\n",
      "tensor([[0.1736, 0.8499],\n",
      "        [0.9200, 0.4837]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "c = torch.rand(2, 2)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "\n",
    "d = c.squeeze(0)\n",
    "print(d)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o2S6Y8E4h9_"
   },
   "source": [
    "### Moving to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671629637438,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "JSSZNWQs4L9E",
    "outputId": "a7e807b9-8a7c-4978-9ba8-cb6b217edf55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-55p_x0t5Jze"
   },
   "source": [
    "* 建立時直接指定 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5443,
     "status": "ok",
     "timestamp": 1671629710811,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "iUAk15vv5Hl5",
    "outputId": "b9a3d2e8-3c10-4fd8-fb17-4342f76cef88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1151, 0.3213],\n",
       "        [0.0268, 0.3337]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 2, device = device)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3o9kLzu5h_n"
   },
   "source": [
    "* 確認 目前變數的 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1671629795001,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "A4i_sH1A5lfF",
    "outputId": "b93310cc-047a-409c-b7af-3b53eed0c691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPAcUxkG5R6F"
   },
   "source": [
    "* 轉換 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1671629860010,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "Kp3C1SRK5Uv6",
    "outputId": "b29bfe91-a286-4f51-b077-2ec53a4cad92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "y1 = torch.rand(2, 2)\n",
    "print(y1.device)\n",
    "\n",
    "y2 = y1.to(device)\n",
    "print(y2.device)\n",
    "\n",
    "y3 = y2.to(torch.device(\"cpu\"))\n",
    "print(y3.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN5cx7a6581J"
   },
   "source": [
    "* tensor 做計算時，必須在同一個 device 上才能算 (都在 GPU or 都在 CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "executionInfo": {
     "elapsed": 755,
     "status": "error",
     "timestamp": 1671629928941,
     "user": {
      "displayName": "Han-Yueh Lee",
      "userId": "16164657475335713235"
     },
     "user_tz": -480
    },
    "id": "jdFDlqL56D8k",
    "outputId": "2815e591-4d2b-41d4-f7e4-2bea7b13c657"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d8d3d884488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m  \u001b[0;31m# exception will be thrown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, ort, xla, lazy, vulkan, mps, meta, hpu, privateuseone device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2, device='gpu')\n",
    "z = x + y  # exception will be thrown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.from_numpy(np_array)` and `tensor_obj.clone().numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 把 numpy 改成 tensor 的目的：  \n",
    "  * 可以放到 GPU 上加速  \n",
    "  * 可以做 autograd. \n",
    "* 把 tensor 改成 numpy 的目的：  \n",
    "  * 做些中途的計算 & 產出，但不會涉及到 gradient 紀錄. \n",
    "  * 特別小心，如果直接用 `tensor_obj.numpy()`，那他們是共享同個記憶體，是 mutable 的，所以改動 numpy 時，會影響到 tensor。所以才要先 clone() 再 numpy() (至於 detach 就不必要了，因為當你轉成 numpy 時，本來就不會有 gradient 紀錄了)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_array = np.ones((2, 3))\n",
    "print(numpy_array)\n",
    "\n",
    "pytorch_tensor = torch.from_numpy(numpy_array)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 直接做 `tensor_obj.numpy()`，那會是 mutable，改一個，影響另一個："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7552, 0.4874, 0.7107],\n",
      "        [0.6109, 0.6544, 0.7272]])\n",
      "[[0.7551676 0.4873578 0.7107467]\n",
      " [0.6108871 0.6544106 0.7271516]]\n"
     ]
    }
   ],
   "source": [
    "pytorch_rand = torch.rand(2, 3)\n",
    "print(pytorch_rand)\n",
    "\n",
    "numpy_rand = pytorch_rand.numpy()\n",
    "print(numpy_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
      "[[ 0.7551676  0.4873578  0.7107467]\n",
      " [ 0.6108871 17.         0.7271516]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array[1, 1] = 23\n",
    "print(pytorch_tensor)\n",
    "\n",
    "pytorch_rand[1, 1] = 17\n",
    "print(numpy_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 但如果先 clone 再 .numpy，那就是不同記憶體了，彼此不影響："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3561, 0.8712, 0.8384],\n",
      "        [0.5608, 0.1938, 0.8030]])\n",
      "[[0.3561455  0.87122315 0.83837247]\n",
      " [0.560761   0.19379157 0.80295706]]\n"
     ]
    }
   ],
   "source": [
    "pytorch_rand = torch.rand(2, 3)\n",
    "print(pytorch_rand)\n",
    "\n",
    "numpy_rand = pytorch_rand.clone().numpy()\n",
    "print(numpy_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
      "[[0.3561455  0.87122315 0.83837247]\n",
      " [0.560761   0.19379157 0.80295706]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array[1, 1] = 23\n",
    "print(pytorch_tensor)\n",
    "\n",
    "pytorch_rand[1, 1] = 17\n",
    "print(numpy_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用數學計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1\n",
    "twos = torch.ones(2, 2) * 2\n",
    "threes = (torch.ones(2, 2) * 7 - 1) / 2\n",
    "fours = twos ** 2 # 次方計算\n",
    "sqrt2s = twos ** 0.5 # 開根號\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common functions:\n",
      "tensor([[0.8304, 0.7952, 0.6749, 0.4929],\n",
      "        [0.4727, 0.2614, 0.9301, 0.8193]])\n",
      "tensor([[-0., -0., -0., -0.],\n",
      "        [1., 1., -0., -0.]])\n",
      "tensor([[-1., -1., -1., -1.],\n",
      "        [ 0.,  0., -1., -1.]])\n",
      "tensor([[-0.5000, -0.5000, -0.5000, -0.4929],\n",
      "        [ 0.4727,  0.2614, -0.5000, -0.5000]])\n"
     ]
    }
   ],
   "source": [
    "# common functions\n",
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sine and arcsine:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n"
     ]
    }
   ],
   "source": [
    "# trigonometric functions and their inverses\n",
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('\\nSine and arcsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bitwise XOR:\n",
      "tensor([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# bitwise operations\n",
    "print('\\nBitwise XOR:')\n",
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "print(torch.bitwise_xor(b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Broadcasted, element-wise equality comparison:\n",
      "tensor([[ True, False],\n",
      "        [False, False]])\n"
     ]
    }
   ],
   "source": [
    "# comparisons:\n",
    "print('\\nBroadcasted, element-wise equality comparison:')\n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "print(torch.eq(d, e)) # returns a tensor of type bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduction ops:\n",
      "tensor(4.)\n",
      "4.0\n",
      "tensor(2.5000)\n",
      "tensor(1.2910)\n",
      "tensor(24.)\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# reductions:\n",
    "print('\\nReduction ops:')\n",
    "print(torch.max(d))        # returns a single-element tensor\n",
    "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
    "print(torch.mean(d))       # average\n",
    "print(torch.std(d))        # standard deviation\n",
    "print(torch.prod(d))       # product of all numbers\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectors & Matrices:\n",
      "tensor([ 0.,  0., -1.])\n",
      "tensor([[0.0685, 0.9392],\n",
      "        [0.2532, 0.6231]])\n",
      "tensor([[0.2055, 2.8177],\n",
      "        [0.7597, 1.8692]])\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.8183, -0.5748],\n",
      "        [-0.5748,  0.8183]]),\n",
      "S=tensor([3.4338, 0.5115]),\n",
      "V=tensor([[-0.1762,  0.9844],\n",
      "        [-0.9844, -0.1762]]))\n"
     ]
    }
   ],
   "source": [
    "# vector and linear algebra operations\n",
    "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "m1 = torch.rand(2, 2)                   # random matrix\n",
    "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
    "\n",
    "print('\\nVectors & Matrices:')\n",
    "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
    "print(m1)\n",
    "m3 = torch.matmul(m1, m2)\n",
    "print(m3)                  # 3 times m1\n",
    "print(torch.svd(m3))       # singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIS0ljOL4L9F"
   },
   "source": [
    "## 自動微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT1crLmW4L9F"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcf7Osi64L9G"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPb52zVD4L9G"
   },
   "source": [
    "### Dataset - 自訂 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnqOFGvr4L9H"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, feature_matrix, label_vector):             # 把資料存進 class object\n",
    "        self.feature_matrix = feature_matrix\n",
    "        self.label_vector = label_vector\n",
    "    def __len__(self):\n",
    "        assert len(self.feature_matrix) == len(self.label_vector) # 確定資料有互相對應\n",
    "        return len(self.feature_matrix)\n",
    "    def __getitem__(self, idx):                     # 定義我們需要取得某筆資料的方式\n",
    "        return self.feature_matrix[idx], self.label_vector[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SdXZbeAZ4L9I",
    "outputId": "5ca2722c-855c-4fe6-bf5e-db0536957600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100, 1), (10,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 測試看看\n",
    "\n",
    "X = np.random.rand(1000, 100, 100, 1)   # 虛構 1000 張 100 x 100 單色圖片\n",
    "Y = np.random.randint(0, 7, [1000, 10]) # 虛構 1000 個 labels\n",
    "\n",
    "my_dataset = MyDataset(X.astype(np.float32), Y.astype(np.float32))\n",
    "taken_x, taken_y = my_dataset[0] # 取得第一筆資料\n",
    "taken_x.shape, taken_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWDIwPoS4L9J"
   },
   "source": [
    "### Dataset - 直接用 `TensorDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o06ryKhX4L9K"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# 手上有的資料，先轉成 Tensor\n",
    "X = np.random.rand(1000, 100, 100, 1)   # 虛構 1000 張 100 x 100 單色圖片\n",
    "Y = np.random.randint(0, 7, [1000, 10]) # 虛構 1000 個 labels\n",
    "tsrX, tsrY = torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "# 餵到 TensorDataset 裡面\n",
    "tsrdataset = TensorDataset(tsrX, tsrY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufHwGTIi4L9K",
    "outputId": "e9f57751-904a-46c2-b210-f38d96b5310d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "torch.Size([100, 100, 1]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 幾個重要的用法\n",
    "print(tsrdataset.__len__()) # 幾張圖\n",
    "taken_x, taken_y = tsrdataset[0] # 取得第一筆資料\n",
    "print(taken_x.shape, taken_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t_vRU-64L9L"
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iccIfheQ4L9L",
    "outputId": "9b8f70f9-7091-4532-85ac-7f45dfa9bef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4, 100, 100, 1]), torch.Size([4, 10]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 將 dataset 包裝成 dataloader\n",
    "my_dataloader = DataLoader(\n",
    "    my_dataset, \n",
    "    batch_size=4,\n",
    "    shuffle=True #, \n",
    "    # num_workers=4\n",
    ")\n",
    "\n",
    "# 跑一個 loop 確認拿到的 batch 是否正確\n",
    "for batch_x, batch_y in my_dataloader:\n",
    "    print((batch_x.shape, batch_y.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S44x0TW4L9M"
   },
   "source": [
    "### 內建 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOq2f30o4L9M"
   },
   "source": [
    "#### 圖片類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U4u4tgo4L9N"
   },
   "source": [
    "##### 無 transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UZNPk0a4L9N"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# dataset\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_NFTcGJ4L9N"
   },
   "source": [
    "* 此時為 dataset 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7os5wKxB4L9O",
    "outputId": "0063e6cb-47f9-475d-8259-a3b27bc84bab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALktl29f4L9P"
   },
   "source": [
    "* 用 index 可以取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqeJNYn64L9P"
   },
   "outputs": [],
   "source": [
    "x, y = mnist_train[0] # 第 0 筆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_SlrD8Z4L9P"
   },
   "source": [
    "* x 會是 PIL 物件, y 是 lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsSFnSBN4L9P",
    "outputId": "e516b8f1-608f-4278-cf96-7e1f7d8bd890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owGAU_LU4L9Q",
    "outputId": "d8f8433a-080a-4728-e1c5-02f27fc55050"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x13D41C100>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hRV0llv4L9Q",
    "outputId": "512d51ee-159d-4a9e-f6c5-1acbd1212c37"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-CYSZo94L9R",
    "outputId": "a873f759-1efc-4ec2-e1e1-2b76e8fee425"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPPirh4p4L9S"
   },
   "source": [
    "* 可以把 x 轉成 numpy 看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0AfEt_y4L9S",
    "outputId": "607f16c5-123e-4d0a-f20e-52bbde7e1b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "uint8\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "x_array = np.asarray(x)\n",
    "print(x_array.shape)\n",
    "print(x_array.dtype)\n",
    "print(x_array.min())\n",
    "print(x_array.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHeBkOCm4L9S"
   },
   "source": [
    "* 可以看到是 28x28 的圖，且是 uint8 type，介於 0~255 整數值  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1McesDe4L9T"
   },
   "source": [
    "##### 有 transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj2xBIER4L9T"
   },
   "source": [
    "* 圖片類資料庫，通常都會做以下 transform:  \n",
    "  * 把圖片改成 float32 浮點數 type. \n",
    "  * 把圖片正規化到 0~1 之間\n",
    "  * 轉成 tensor (灰階圖，會變成 (1,28,28), RGB圖仍是 (3, 28, 28)) \n",
    "* 這其實就是 `torchvision.transforms.ToTensor()` 在做的事\n",
    "* 看一下剛剛的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzbsQ6xf4L9T",
    "outputId": "c047bbe0-9c6f-4651-9c89-6d752fe4f1b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "uint8\n",
      "<class 'torch.Tensor'>\n",
      "torch.float32\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(np.asarray(x).dtype)\n",
    "\n",
    "trans = torchvision.transforms.ToTensor()\n",
    "x_trans = trans(x)\n",
    "print(type(x_trans))\n",
    "print(x_trans.dtype)\n",
    "print(x_trans.min())\n",
    "print(x_trans.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqy6qj5S4L9T"
   },
   "source": [
    "* 讀檔時，就可以把這個放進去："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6hw3N994L9T"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "trans = transforms.ToTensor()\n",
    "\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aZDD_X_4L9T",
    "outputId": "c58ceda4-0c69-4407-d240-300a9bf41cfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnCIa0zU4L9U",
    "outputId": "94d3a4f8-f13f-4182-d3b4-8a3dd354fcb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x, y = mnist_train[0]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPrzHHk34L9U",
    "outputId": "867da894-daf9-4de5-b7c5-1a81f3e3280a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LMUdfbC4L9U"
   },
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcFWBIlu4L9U",
    "tags": []
   },
   "source": [
    "## NN structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEBz3zPN4L9U"
   },
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbseHBdC4L9V"
   },
   "source": [
    "* 萬用起手式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oofR9Vwi4L9V"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5q6s5KM4L9V"
   },
   "source": [
    "## activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-q7xHij4L9V"
   },
   "source": [
    "### 內建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6mXTNG84L9V"
   },
   "source": [
    "| activation function | `torch.nn as nn`                    | `torch.nn.functional as F` |\n",
    "|:-------------------:| ----------------------------------- | -------------------------- |\n",
    "| Sigmoid             | `nn.Sigmoid()`                      | `F.sigmoid`                |\n",
    "| Softmax             | `nn.Softmax(dim=None)`              | `F.softmax`                |\n",
    "| ReLU                | `nn.ReLU()`                         | `F.relu`                   |\n",
    "| LeakyReLU           | `nn.LeakyReLU(negative_slope=0.01)` | `F.leaky_relu`             |\n",
    "| Tanh                | `nn.Tanh()`                         | `F.tanh`                   |\n",
    "| GELU                | `nn.GELU()`                         | `F.gelu`                   |\n",
    "| ReLU6               | `nn.ReLU6()`                        | `F.relu6`                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAf0qwmF4L9V"
   },
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7w3Hqa4L9V"
   },
   "source": [
    "* 主要重點：  \n",
    "  * $ReLU(x) = max(x, 0)$  \n",
    "  * $\\frac{x}{dx} ReLU(x) = 1$ if x > 0; $\\frac{x}{dx} ReLU(x) = 0$ if x <= 0\n",
    "  * relu 的導數，在 x = 0 時，數學上是不存在，但在工程上 \"定義\" 導數為 0，這樣就能繼續做了  \n",
    "  * relu 的優點是求導的結果簡單，不是 0 就是 1，在 backward 更新參數時， `weight_new = weight_old - learning_rate * grad`，那 grad 不是 0 就是 1，減輕了以往NN的梯度消失問題。  \n",
    "* 簡單範例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHm-JKTx4L9V",
    "outputId": "b49d2df1-57f5-4fd0-fbc7-a5184df2b175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000, 1.8000,\n",
      "        1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000,\n",
      "        2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000,\n",
      "        3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000, 4.5000,\n",
      "        4.6000, 4.7000, 4.8000, 4.9000, 5.0000, 5.1000, 5.2000, 5.3000, 5.4000,\n",
      "        5.5000, 5.6000, 5.7000, 5.8000, 5.9000, 6.0000, 6.1000, 6.2000, 6.3000,\n",
      "        6.4000, 6.5000, 6.6000, 6.7000, 6.8000, 6.9000, 7.0000, 7.1000, 7.2000,\n",
      "        7.3000, 7.4000, 7.5000, 7.6000, 7.7000, 7.8000, 7.9000],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "activation = nn.ReLU()\n",
    "\n",
    "x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\n",
    "y = activation(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wi0ONP8u4L9W",
    "outputId": "169ee231-bbde-42eb-fe9b-6f77cdff6ff0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x.detach(), y.detach());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzl_AgHw4L9W",
    "outputId": "64fb72cc-195a-46bb-dd95-43229da37eb1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.backward(torch.ones_like(x), retain_graph=True)\n",
    "plt.plot(x.detach(), x.grad); # gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjE99U0Z4L9W"
   },
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0nKQRYp4L9W"
   },
   "source": [
    "* 主要重點：  \n",
    "  * $sigmoid(x) = \\frac{1}{1 + exp(-x)}$  \n",
    "  * $\\frac{x}{dx} sigmoid(x) = sigmoid(x)(1-sigmoid(x))$  \n",
    "  * 從導數的性質，可以發現，gradient 在 x 靠近 0 時，值較大 (參數更新較快）， x 遠離 0 時， gradient 趨近於 0 (參數停止更新)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AR2EYWFp4L9W",
    "outputId": "b4b069b9-a137-4388-a423-b7ea0df96a0e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "activation = nn.Sigmoid()\n",
    "\n",
    "x = torch.arange(-8.0, 8.0, 0.1, requires_grad=True)\n",
    "y = activation(x)\n",
    "\n",
    "plt.plot(x.detach(), y.detach());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2hmDuMp4L9W",
    "outputId": "ab61bc77-67ac-46da-8fa6-849e01948188"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gradients\n",
    "y.backward(torch.ones_like(x),retain_graph=True)\n",
    "plt.plot(x.detach(), x.grad);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaIjNfPs4L9X"
   },
   "source": [
    "### 自訂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbqtPqly4L9X"
   },
   "source": [
    "* 直接定義一個 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTu1bBmA4L9X"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    a = torch.zeros_like(x) # shape 會與 x 一樣\n",
    "    return torch.max(x, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7Tgshco4L9Y",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## custom layers & block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1faUIXm14L9Z"
   },
   "source": [
    "* 幾個名詞定義一下：  \n",
    "  * layer: 只要是 input n 個 neruon, output m 個 neuron 的 function，就被稱為一個 layer。例如 `nn.Linear(in_dim, out_dim)` 就是個 linear layer. \n",
    "  * block: \n",
    "    * 多個 layer 組合在一起，稱為一個 block。例如一個 VGG block，就是由數個 conv, pooling layer 所組成. \n",
    "    * 通常用 sequential 來把 layer 組成 block; 或用 sub-class 來把 layer 組成 block\n",
    "  * model: \n",
    "    * 由 layers or/and blocks 組起來，只要 input 是 feature/images/sentences..，output 是 回歸/分類...結果，就都可稱為 model。\n",
    "    * 例如一個 linear layer 可以是 model (e.g. linear regression)，一個 block 可以是 model (e.g. 多層感知機)，多個 block 組在一起 (e.g. resnet) 也可以是 model  \n",
    "    * 所以，可以用 `layer` 來做出 model，也可以用 `sequential` 組成 model，也可以用 `sub-class` 組成 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5_u2lgB4L9Z"
   },
   "source": [
    "### custom layer (不帶參數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uZhCvT14L9Z"
   },
   "outputs": [],
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    \"\"\"用來做中心化(去平均)的layer\n",
    "    args:\n",
    "      X: 任何 shape，但通常是 (n, p)，然後我們想把 feature 都 de-mean\n",
    "    \"\"\"\n",
    "    def __init__(self, dim = 1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean(dim = self.dim, keepdim = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1_nvttC4L9Z",
    "outputId": "9a1a91b7-8e9c-454b-bd87-984af7ac0aa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9273,  0.1359],\n",
       "        [-1.1151, -1.3790],\n",
       "        [-0.5349, -4.1247],\n",
       "        [-1.9496,  0.5590],\n",
       "        [-1.4850,  1.3104]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做 5 個 sample，每個 sample 都有 2 個 feature 的 X\n",
    "X = torch.randn(5, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aYFCEdC4L9a",
    "outputId": "2ea46d1f-ddf2-4537-8ffc-eba72f293296"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5316,  0.5316],\n",
       "        [ 0.1319, -0.1319],\n",
       "        [ 1.7949, -1.7949],\n",
       "        [-1.2543,  1.2543],\n",
       "        [-1.3977,  1.3977]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_Hoivp54L9a"
   },
   "source": [
    "* 可以清楚看到，de-mean 後，每個 row 現在相加都是 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twthuUnS4L9a"
   },
   "source": [
    "* 之後，這種 layer 就可以當作前處理，然後這樣用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9P_Xs_tr4L9a",
    "outputId": "a1968274-aacd-460c-f64c-007230258e59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8472],\n",
       "        [ 0.4268],\n",
       "        [-0.6269],\n",
       "        [ 1.3052],\n",
       "        [ 1.3961]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    CenteredLayer(), # 前處理用，de-mean\n",
    "    nn.Linear(2, 1) # linear regression\n",
    ")\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmQ574D14L9b"
   },
   "source": [
    "### custom layer (帶參數)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4DdqIQZ4L9b"
   },
   "source": [
    "* 重點在，weight, bias 要用 `nn.Parameter()` 來造，這樣就可以保有計算 gradient 等功能(預設 requires_grad = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8boW830X4L9b",
    "outputId": "21e84c3d-38b5-41a0-bd21-6df4a9f15194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m  \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A kind of Tensor that is to be considered a module parameter.\n",
       "\n",
       "Parameters are :class:`~torch.Tensor` subclasses, that have a\n",
       "very special property when used with :class:`Module` s - when they're\n",
       "assigned as Module attributes they are automatically added to the list of\n",
       "its parameters, and will appear e.g. in :meth:`~Module.parameters` iterator.\n",
       "Assigning a Tensor doesn't have such effect. This is because one might\n",
       "want to cache some temporary state, like last hidden state of the RNN, in\n",
       "the model. If there was no such class as :class:`Parameter`, these\n",
       "temporaries would get registered too.\n",
       "\n",
       "Args:\n",
       "    data (Tensor): parameter tensor.\n",
       "    requires_grad (bool, optional): if the parameter requires gradient. See\n",
       "        :ref:`locally-disable-grad-doc` for more details. Default: `True`\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/torch/nn/parameter.py\n",
       "\u001b[0;31mType:\u001b[0m           _ParameterMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     UninitializedParameter\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Tyert_G4L9b"
   },
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \"\"\" 自己寫一個 dense 層 \"\"\"\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_dim, out_dim))\n",
    "        self.bias = nn.Parameter(torch.randn(out_dim,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zauuux3x4L9c"
   },
   "source": [
    "* 看一下實例化後，起始參數："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY4Pagsl4L9c",
    "outputId": "d2d9d0aa-ab17-4458-b51f-84ca15df2029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3640,  1.5913,  0.4055],\n",
       "        [-1.0218,  0.4775, -1.1235],\n",
       "        [-1.7111,  0.8637, -0.4625],\n",
       "        [-0.5543, -0.6704, -0.0141],\n",
       "        [-1.1417,  0.6179,  0.6895]], requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVAVAte44L9c"
   },
   "source": [
    "* 用用看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vLMgK9R4L9c",
    "outputId": "71b1a31d-6df3-4079-8f34-38852309aacb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.2610, -0.1284, -1.8087],\n",
       "        [ 0.6928,  1.0955, -1.3039],\n",
       "        [-3.6307,  2.3802, -0.8923],\n",
       "        [-1.7597,  1.9472, -0.6151],\n",
       "        [-2.2773,  0.8810, -1.5115],\n",
       "        [-0.4681,  1.1092,  1.5497],\n",
       "        [-1.9127,  1.2226, -0.9216],\n",
       "        [-2.4812,  1.8624,  0.1789],\n",
       "        [-0.7259,  1.6919,  1.7905],\n",
       "        [-0.0247, -1.7735, -0.9420]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(10, 5)\n",
    "linear(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hgf_RZL4L9d"
   },
   "source": [
    "### sequential block (`nn.Sequential(layer1, block2, ...)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0751e-01, -1.2425e-01,  1.4933e-01,  7.5487e-02,  2.6889e-01,\n",
       "         -2.4903e-01,  3.5666e-05, -7.2805e-02,  2.4102e-02, -7.0524e-02],\n",
       "        [-1.1472e-01, -4.5277e-02,  1.8385e-01, -1.1014e-01,  3.0093e-01,\n",
       "         -2.1793e-01, -7.2202e-02, -1.2279e-01,  1.7267e-01, -3.3422e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(20, 256), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential `for` tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 我們可以建立一個自己的 sequential，就可以看到實際運作狀況："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # args 就是 user 隨意要丟幾個 layer, block 進來，所組成的 list\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 來試試看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3512,  0.0382, -0.0272, -0.0299,  0.1932, -0.0300,  0.0591,  0.0224,\n",
       "          0.0579,  0.1903],\n",
       "        [ 0.3129,  0.1721,  0.1292,  0.0103,  0.2904,  0.1143, -0.0841, -0.1001,\n",
       "          0.2664,  0.1742]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(\n",
    "    nn.Linear(20, 256), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir7Npw2n4L9c",
    "tags": []
   },
   "source": [
    "### custom block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 雖然 sequential block 很方便，但有時我們會需要在 forward 的時候，做一些靈活的控制，例如以下這個刻意做出來的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "rPfKY2I44L9d"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.hidden(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.out(X)\n",
    "        # 這邊開始是 flexible 的設計, 這就是 sequential 辦不到的\n",
    "        # 我希望控制輸出，當輸出的 tensor 的 L1 norm > 1 時，我就把他除以2，直到輸出的 L1 norm 壓在 1 以內\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 來試一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0155, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(2, 20)\n",
    "\n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參數管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 假設 model 長這樣："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-4)\n",
    "\n",
    "# loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0542],\n",
      "        [-0.1957]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# fake data: batch_size = 2\n",
    "X = torch.rand(size=(2, 4))\n",
    "y = torch.tensor([0.7, 0.2])\n",
    "\n",
    "# one-epoch training\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "y_hat = model(X)        # 把 x tensor 移到 GPU 計算\n",
    "print(y_hat)\n",
    "\n",
    "loss = criterion(y, y_hat) # 把 y tensor 移到 GPU 計算，\n",
    "                                      ##  y_hat 因為是從 GPU model input GPU Tensor 出來的\n",
    "                                      ##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||\n",
    "optim.zero_grad() # 把 trainable variable/weights/parameters 的 gradient 給 歸 0\n",
    "loss.backward() # 利用 loss，計算出每個 trainable variable/weights/parameters 所對應的 gradient\n",
    "optim.step() # 更新 trainable variable/weights/parameters 的值： parameters_new = parameters_old - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看 model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到，他用 index 來表明每一層的 layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 看單一層的 weight, bias, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 例如，看第 0 個 index 的 參數："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.state_dict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "                      [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "                      [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "                      [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "                      [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "                      [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "                      [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "                      [ 0.1895,  0.3306,  0.0714,  0.4956]])),\n",
       "             ('bias',\n",
       "              tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021]))])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 所以，要取得 weight 或 bias 的資料可以這樣拿："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "        [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "        [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "        [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "        [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "        [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "        [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "        [ 0.1895,  0.3306,  0.0714,  0.4956]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].state_dict()['bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.weight`, `.weight.data`, `.weight.grad`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 除了這種做法外，也可以用 `.weight` 取得 weight 物件，再往下去取得 data 和 gradient 資訊："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
      "        [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
      "        [-0.1534, -0.2841,  0.3249, -0.2912],\n",
      "        [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
      "        [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
      "        [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
      "        [-0.1031, -0.1659, -0.3799,  0.4556],\n",
      "        [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "print(model[0].weight) # 這是物件\n",
    "print(type(model[0].weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "        [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "        [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "        [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "        [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "        [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "        [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "        [ 0.1895,  0.3306,  0.0714,  0.4956]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取這個物件，底下的 data (i.e. value)\n",
    "model[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1611,  0.1510,  0.1755,  0.1280],\n",
       "        [-0.2097, -0.1966, -0.2285, -0.1666],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0678,  0.0636,  0.0739,  0.0539],\n",
       "        [ 0.0354,  0.0331,  0.0385,  0.0281],\n",
       "        [ 0.0608,  0.0955,  0.0774,  0.0291],\n",
       "        [ 0.1630,  0.1528,  0.1776,  0.1295],\n",
       "        [ 0.1269,  0.1189,  0.1383,  0.1008]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gradient\n",
    "model[0].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.bias`, `.bias.data`, `.bias.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2477, -0.3225,  0.0000,  0.1043,  0.0544,  0.0989,  0.2507,  0.1951])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.parameters()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 也可以用 `.parameters`，出來的會是物件："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x13e20ee40>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "         [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "         [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "         [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "         [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "         [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "         [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "         [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model[0].parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到，list 裡面的第一個 element，很明顯是 weight, 第二個 element，很明顯是 bias，兩個都是物件，所以真的要取資料時，可以這樣取："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
      "        [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
      "        [-0.1534, -0.2841,  0.3249, -0.2912],\n",
      "        [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
      "        [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
      "        [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
      "        [-0.1031, -0.1659, -0.3799,  0.4556],\n",
      "        [ 0.1895,  0.3306,  0.0714,  0.4956]])\n",
      "tensor([[ 0.1611,  0.1510,  0.1755,  0.1280],\n",
      "        [-0.2097, -0.1966, -0.2285, -0.1666],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0678,  0.0636,  0.0739,  0.0539],\n",
      "        [ 0.0354,  0.0331,  0.0385,  0.0281],\n",
      "        [ 0.0608,  0.0955,  0.0774,  0.0291],\n",
      "        [ 0.1630,  0.1528,  0.1776,  0.1295],\n",
      "        [ 0.1269,  0.1189,  0.1383,  0.1008]])\n",
      "1\n",
      "tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])\n",
      "tensor([ 0.2477, -0.3225,  0.0000,  0.1043,  0.0544,  0.0989,  0.2507,  0.1951])\n"
     ]
    }
   ],
   "source": [
    "for idx, param in enumerate(model[0].parameters()):\n",
    "    print(idx)\n",
    "    print(param.data)\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `.named_parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "          [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "          [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "          [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "          [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "          [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "          [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "          [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model[0].named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 看所有的 parameters, weight, bias, gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 有了前面的練習，應該就不難理解一次看全部的結果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "                      [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "                      [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "                      [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "                      [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "                      [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "                      [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "                      [ 0.1895,  0.3306,  0.0714,  0.4956]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.2377,  0.3098, -0.2583, -0.1001, -0.0521, -0.1530, -0.2406, -0.1873]])),\n",
       "             ('2.bias', tensor([0.1550]))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 可以看到 weight 和 bias 前面，有加上 index (i.e. 0 和 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x13c52fe40>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.3048,  0.2219,  0.2388,  0.3435],\n",
       "          [ 0.3939, -0.3583, -0.3972,  0.4755],\n",
       "          [-0.1534, -0.2841,  0.3249, -0.2912],\n",
       "          [ 0.1784,  0.4749, -0.1225,  0.1678],\n",
       "          [ 0.2339,  0.4488, -0.2803,  0.1215],\n",
       "          [ 0.3486,  0.4914,  0.0383, -0.4629],\n",
       "          [-0.1031, -0.1659, -0.3799,  0.4556],\n",
       "          [ 0.1895,  0.3306,  0.0714,  0.4956]], requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0700,  0.3040,  0.0767, -0.1222,  0.4878, -0.1032,  0.4792, -0.0021],\n",
       "         requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.2377,  0.3098, -0.2583, -0.1001, -0.0521, -0.1530, -0.2406, -0.1873]],\n",
       "         requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.1550], requires_grad=True))]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### block factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果我們把 block 給 nested 在一起，那要如何做參數管理？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4301],\n",
       "        [-0.4301]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    \n",
    "    out = nn.Sequential(\n",
    "        nn.Linear(4, 8), \n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 4), \n",
    "        nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    return out \n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在這裡 nested\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 那要取資訊時，就是一層一層往下取就好："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3477,  0.0886,  0.2932,  0.3275, -0.1417,  0.2814,  0.1715, -0.3397])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet[0][1][0].bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參數初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 知道如何訪問參數後，現在來講如何初始化參數. \n",
    "* 這要用到 pytorch 的 `nn.init` module 提供的多種方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0105,  0.0073, -0.0162,  0.0021],\n",
       "         [-0.0090, -0.0050, -0.0081,  0.0137],\n",
       "         [-0.0094,  0.0131, -0.0050, -0.0125],\n",
       "         [-0.0123, -0.0004, -0.0149,  0.0064],\n",
       "         [ 0.0014,  0.0075, -0.0244,  0.0135],\n",
       "         [ 0.0065, -0.0017, -0.0205,  0.0050],\n",
       "         [ 0.0271,  0.0054,  0.0010,  0.0047],\n",
       "         [ 0.0182,  0.0035,  0.0027, -0.0007]]),\n",
       " tensor([ 0.0125, -0.3895, -0.2890, -0.0959, -0.4549, -0.3239,  0.0046,  0.3682]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight 和 bias 的初始值都設為 N(0, 0.01) 的 init\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "        \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 8), \n",
    "    nn.ReLU(), \n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "model.apply(init_normal)\n",
    "model[0].weight.data, model[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight 的 初始值都設為 1, bias 都設為 0\n",
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_constant)\n",
    "\n",
    "model[0].weight.data, model[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6934,  0.4680, -0.3913,  0.0849],\n",
       "         [ 0.1309,  0.5539, -0.4249, -0.5450],\n",
       "         [-0.1842, -0.2299, -0.4047,  0.2514],\n",
       "         [-0.6546,  0.4458, -0.6788, -0.1312],\n",
       "         [-0.1920,  0.0308,  0.1797, -0.3841],\n",
       "         [ 0.6221, -0.3523,  0.5078, -0.3886],\n",
       "         [-0.3136,  0.3043, -0.3935,  0.2180],\n",
       "         [ 0.5874, -0.5117, -0.5833,  0.0361]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xavier\n",
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model.apply(init_xavier)\n",
    "\n",
    "model[0].weight.data, model[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 7.3381, -6.7319, -5.7735,  8.2337],\n",
       "        [ 9.4036, -8.0004, -5.2134,  0.0000],\n",
       "        [ 0.0000, -8.1653, -5.6182, -0.0000],\n",
       "        [-0.0000,  0.0000,  5.3923, -0.0000],\n",
       "        [ 0.0000, -0.0000,  9.4830, -0.0000],\n",
       "        [ 0.0000,  0.0000,  5.3328,  9.0293],\n",
       "        [-0.0000, -5.9543,  5.0917, -0.0000],\n",
       "        [ 0.0000, -9.4781,  0.0000, -0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自訂義初始化\n",
    "# weight 有 1/4 的可能性，來自 U(5, 10), 1/4 可能性來自 U(-10, -5), 1/2 可能性是 0\n",
    "\n",
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "model.apply(my_init)\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 我們也可以自己設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000, -5.7319, -4.7735,  9.2337])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.data[:] += 1\n",
    "model[0].weight.data[0, 0] = 42\n",
    "model[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuVwkwv74L9X",
    "tags": []
   },
   "source": [
    "## Classical Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KwfCDA84L9X"
   },
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3u9SGDNv4L9X"
   },
   "source": [
    "#### `nn.Linear(in_dim, out_dim)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kA1p_DR4L9X"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zjSWiDF4L9X"
   },
   "source": [
    "#### convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcENycuX4L9Y"
   },
   "source": [
    "* 2d convolution: `nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)`  \n",
    "* 1d convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuwfPgtG4L9Y"
   },
   "source": [
    "#### pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYg2bmEZ4L9Y"
   },
   "source": [
    "* maximum pooling:  `nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1)`   \n",
    "* average pooling:   \n",
    "* global maximum pooling:   \n",
    "* global average pooling:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ba1ZADwe4L9Y"
   },
   "source": [
    "#### VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkHcJGg24L9Y"
   },
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9OhratU4L9Y"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRQUC1jl4L9d"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3No7oWdD4L9d"
   },
   "source": [
    "### overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXHRHGVw4L9d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZKQZIon4L9d"
   },
   "source": [
    "* 官網連結: https://pytorch.org/docs/stable/nn.html#loss-functions  \n",
    "* 常用的整理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJpYa7UJ4L9e"
   },
   "source": [
    "| loss function                    | `torch.nn as nn`                    | `torch.nn.functional as F` |\n",
    "|:--------------------------------:| ----------------------------------- | -------------------------- |\n",
    "| Binary cross entropy             | `nn.BCELoss()`                      | `F.binary_cross_entropy`   |\n",
    "| Binary cross entropy with logits | `nn.BCEWithLogitsLoss()`            | `F.binary_cross_entropy_with_logits` |\n",
    "| categorical cross entropy        | `nn.CrossEntropyLoss()`             | `F.relu`                   |\n",
    "| mse                              | `nn.MSELoss()`                      | `F.leaky_relu`             |\n",
    "| mae                              | `nn.L1Loss()`                       | `F.tanh`                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEOS33cC4L9e"
   },
   "source": [
    "* 概念講一下：\n",
    "  * loss 在統計的定義，是對 \"單一\" sample 算 loss，例如 square error loss = $(y_i - \\hat{y_i})^2$\n",
    "  * 然後 mse 是 cost，不是 loss，所以 mse cost = $\\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y_i})^2$  \n",
    "  * 但在 pytorch/tensorflow 中，這兩個已經被混用了，都叫做 loss. \n",
    "  * 至於，如何區別這兩者呢？靠 class/function 中的參數定義來決定。  \n",
    "  * 例如： `my_mse = nn.MSELoss()`, 然後 `my_mse(y_hat_vector, y_true_vector)`，算出來的就是 mse cost. \n",
    "  * 但如果 `my_mse = nn.MSELoss(reduction = 'none')`, 然後 `my_mse(y_hat_vector, y_true_vector)`，算出來的是 n 維的 mse loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cm1Ie_tU4L9e"
   },
   "source": [
    "* y 不一定要是向量，可以是矩陣或陣列：  \n",
    "  * 在統計上，學 loss 或 cost，都是從回歸的角度去學的，也就 向量 vs 向量， e.g. y = 100 維向量(100個sample)，y_hat 也是 100 維，那就可以算出 1 個 cost 和 100 個 loss. \n",
    "  * 但在 deep learning 裡面，y不一定是向量，y可以是矩陣，甚至多維陣列。\n",
    "  * 例如做 autoencoder 時\n",
    "    * y就是矩陣，比如 100 張圖片，每張圖片都是 8x8 的矩陣，那 y 可以定義成 (100, 8x8) 的 矩陣，(把圖片拉成 8x8 的向量)。\n",
    "    * y_hat 是這些影像 reconstruct 後的結果，所以也是 100 x 64 的矩陣。\n",
    "    * 那我照樣用剛剛定義好的 loss function，我就可以算出 1 個 cost 和 100x8x8 = 6400 個 loss。\n",
    "    * 所以關鍵在：他都是 `by element` 算 loss, 然後紀錄有多少 `個數`, 最後再用 `sum` 或 `mean` 回給你一個 cost。\n",
    "    * 這樣，就不需要管 y 的 shape 了。\n",
    "    * 例如：我這次不要把 8x8 拉成向量，所以 y 就是 (100, 8, 8) 的 array，那也無所謂，放入我的 loss function，他就可以算出 6400 個 loss，然後依照你的 reduction 的設定 (none or sum or mean)，回給你 6400 個 loss 或是 1 個 cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-ea1fdV4L9e"
   },
   "source": [
    "* batch loss 是拿來更新參數用的， epoch loss 是用來檢查有無 overfitting 的\n",
    "  * deep learning 在 training or testing 時，都是一個 batch 一個 batch 做，最後再整合成一個 epoch  \n",
    "  * 每個 batch 在做的時候，都要算這個 batch 的 cost，他的目的是用來更 gradient 時，要對這個 cost 做偏微分。所以每個 batch 結束，會得到一個 cost\n",
    "  * 每個 epoch 結束，要算的 cost 是跨所有樣本的。他的目的，是要去比較 training sample 的 cost 和 validation sample 的 cost，來判斷是否 overfitting 了，要不要做 early stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7x2Fnjh4L9e"
   },
   "source": [
    "* epoch loss 的算法設計.   \n",
    "  * 最常見的設計，是直接拿 batch cost 的結果來 summarise，因位省時省力：  \n",
    "    * 舉例來說，我有 10 個 batch，每個 batch 有 32 個 batch size. \n",
    "    * 每個 batch 結束時，其實都拿到該 batch 的 1 個 cost 或 32 個 loss. \n",
    "    * 那算 epoch cost 時，我就可以把 10 個 batch cost 取平均，或是 10x32 = 320 個 loss 取平均，就得到 epoch cost。\n",
    "    * pseudo code 就是  \n",
    "      * 先定義 `epoch_cost = 0`  \n",
    "      * 然後 for 迴圈去 loop 10 個 batch  \n",
    "      * 每次 batch 結束，就讓 `epoch_cost += batch_cost`. \n",
    "      * 迴圈結束後，用 epoch_cost / 10，得到 mean cost。\n",
    "      * 如果要用 loss 的寫法也很簡單。最外面就是定義 `loss_list = []`，然後每個回圈都是算出 batch_size 個 epoch_loss，然後 `loss_list.append(epoch_loss)`，最終再對 loss_list 取平均就好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrgCMpXn4L9f",
    "tags": []
   },
   "source": [
    "### mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sKEmsrV4L9f",
    "outputId": "1c68e431-c560-43d4-f360-71972d268657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6104,  0.4109,  1.3322,  1.2199, -0.6273], requires_grad=True)\n",
      "tensor([ 0.7016, -1.6683,  1.0668,  0.9080, -1.2761])\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.randn(5, requires_grad=True)\n",
    "y_true = torch.randn(5)\n",
    "print(y_hat)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ip7_JjqP4L9f"
   },
   "source": [
    "#### class 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp1oodqd4L9f",
    "outputId": "5425e20e-e33c-4226-a386-879772c3b5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3454, 4.3230, 0.0705, 0.0973, 0.4209], grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 算 loss\n",
    "my_loss = nn.MSELoss(reduction = \"none\")\n",
    "loss = my_loss(y_hat, y_true)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uMC33QP4L9g",
    "outputId": "fc06f4fd-c01a-4a46-e189-a05e1be7e7bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0514, grad_fn=<MseLossBackward>)\n",
      "tensor(2.0514, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 算 cost (i.e mean loss)\n",
    "my_loss = nn.MSELoss()\n",
    "cost = my_loss(y_hat, y_true)\n",
    "print(cost)\n",
    "print(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2njHObn4L9g",
    "outputId": "aaf4c131-c20b-4a05-8265-bbd3094fc83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2571, grad_fn=<MseLossBackward>)\n",
      "tensor(10.2571, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 算 cost (i.e sum loss)\n",
    "my_loss = nn.MSELoss(reduction = \"sum\")\n",
    "sum_cost = my_loss(y_hat, y_true)\n",
    "print(sum_cost)\n",
    "print(loss.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl-GKJ0N4L9g"
   },
   "source": [
    "#### function 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNwShra64L9g",
    "outputId": "98ac32bf-0d5d-4729-ed74-ddad594cc3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7780, -0.4672, -1.0941, -1.0928, -1.0654], requires_grad=True)\n",
      "tensor([ 0.5094, -0.6637, -0.5560, -0.5600, -1.6072])\n",
      "tensor(0.5126, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 用 function 做 cost\n",
    "y_hat = torch.randn(5, requires_grad=True)\n",
    "y_true = torch.randn(5)\n",
    "\n",
    "print(y_hat)\n",
    "print(y_true)\n",
    "print(F.mse_loss(y_hat, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnFDY6354L9h",
    "outputId": "8784f3d4-d9e1-48aa-cf97-7c368cc279fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9525,  0.9356, -0.1469, -0.3822,  2.0675], requires_grad=True)\n",
      "tensor([-0.3021, -0.6323, -1.2846, -0.1762, -0.0629])\n",
      "tensor([0.4230, 2.4583, 1.2943, 0.0424, 4.5388], grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 用 function 做 loss\n",
    "y_hat = torch.randn(5, requires_grad=True)\n",
    "y_true = torch.randn(5)\n",
    "\n",
    "print(y_hat)\n",
    "print(y_true)\n",
    "print(F.mse_loss(y_hat, y_true, reduction=\"none\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHgYnmjw4L9h"
   },
   "source": [
    "### mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-nPmzMu4L9h"
   },
   "source": [
    "### binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ks-Q3HJv4L9h"
   },
   "outputs": [],
   "source": [
    "y_logit = torch.tensor([2.3552, -0.9071,  2.8323])\n",
    "y_hat = torch.tensor([0.9133, 0.2876, 0.9444]) # 就是 F.sigmoid(y_logit) 後的結果\n",
    "y = torch.tensor([0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIo5kVdk4L9i"
   },
   "source": [
    "* y 是 vector/matrix/array 都可 (常見是 vector，element 個數就是樣本數)，值不是 0 就是 1。 e.g. [0, 1, 0] 表示三個樣本的真值。\n",
    "* y_hat 的 shape 同 y，值介於 0~1 之間。e.g. [0.3, 0.8, 0.1]，表示三個樣本的預測值。\n",
    "* `binary cross entropy`： $-\\frac{1}{n}\\sum_{i = 1}^{n}\\left[ y_i log(\\hat{y_i}) + (1-y_i)(1-log(\\hat{y_i})\\right]$ \n",
    "* 這在這個定義式的中間這項就是 loss： $y_i log(\\hat{y_i}) + (1-y_i)(1-log(\\hat{y_i})$ 。可用 `reduction = \"none\"` 來設定，就可拿到 n 個 loss\n",
    "* 那算 cost，可以像定義式那樣，用平均來做，可用 `reduction = \"mean\"` 來設定。不寫也可，預設就是取 mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9x0jejd4L9i"
   },
   "source": [
    "#### class 版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOqF1bJM4L9k",
    "outputId": "2251be81-76ef-4d99-c9e2-fadbae34b4a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4453, 0.3391, 2.8896])\n"
     ]
    }
   ],
   "source": [
    "# loss 版\n",
    "my_loss = nn.BCELoss(reduction = \"none\")\n",
    "loss = my_loss(y_hat, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obZG0qeD4L9k",
    "outputId": "3c59ee6b-ef1d-4a2b-9b12-af42b16e5f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8913)\n",
      "tensor(1.8913)\n"
     ]
    }
   ],
   "source": [
    "# cost 版\n",
    "my_loss = nn.BCELoss()\n",
    "cost = my_loss(y_hat, y)\n",
    "print(cost)\n",
    "print(loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVuqTBdu4L9k"
   },
   "source": [
    "#### function 版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RG7wJbLu4L9k",
    "outputId": "91a14819-2a76-4ee7-c561-61bdbf017bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4453, 0.3391, 2.8896])\n",
      "tensor(1.8913)\n"
     ]
    }
   ],
   "source": [
    "# loss 版\n",
    "print(F.binary_cross_entropy(y_hat, y, reduction = \"none\"))\n",
    "\n",
    "# cost 版\n",
    "print(F.binary_cross_entropy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnV1YudC4L9l",
    "outputId": "b52dabe8-ad61-40fc-9845-b49fb1c26f3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8913)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自己照定義算\n",
    "-1*(torch.log(1-y_hat)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiRkrM5G4L9l"
   },
   "source": [
    "* 事實上，y和y_hat可以是任何shape，他都會幫你 by element 的去做 $ y_i log(\\hat{y_i}) + (1-y_i)(1-log(\\hat{y_i})$，然後最後取總平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K432Lc5r4L9l",
    "outputId": "6888de18-f669-4a58-e6e5-e2282e8a7dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2420, 0.5219, 0.5408, 0.7095, 0.1231],\n",
      "        [0.3518, 0.2747, 0.9089, 0.8097, 0.4674],\n",
      "        [0.2304, 0.0615, 0.1389, 0.2419, 0.7572]])\n",
      "tensor([[1., 1., 0., 0., 1.],\n",
      "        [0., 0., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.rand((3,5))\n",
    "y = np.random.randint(low = 0, high = 2, size = (3,5))\n",
    "y = torch.tensor(y, dtype = torch.float32)\n",
    "\n",
    "print(y_hat)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUSyaitf4L9l",
    "outputId": "81c0adbf-bad5-40a7-e884-a9ac9a2dc782"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7998)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XETBixQg4L9l"
   },
   "source": [
    "* 而且，y 也 不一定要是 0 or 1， y也可以是 0~1 的數，此時 binary entropy 就是在衡量 y 和 y_hat 的 distribution 像不像的一個指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFNaOGht4L9l",
    "outputId": "0c9580e6-203f-4e1a-cd72-e1d87f338220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1801, 0.4587, 0.9839, 0.5115, 0.7780],\n",
      "        [0.2146, 0.9854, 0.0592, 0.6360, 0.2658],\n",
      "        [0.6827, 0.2666, 0.0440, 0.6086, 0.8917]])\n",
      "tensor([[0.6732, 0.5078, 0.8481, 0.7030, 0.9484],\n",
      "        [0.7353, 0.8262, 0.2038, 0.2685, 0.1202],\n",
      "        [0.5659, 0.6011, 0.3651, 0.3918, 0.4598]])\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.rand((3,5))\n",
    "y = torch.rand((3,5))\n",
    "\n",
    "print(y_hat)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HloBQaGt4L9m",
    "outputId": "68185d3b-31a8-49a5-bd38-33f07a88e781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8157)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJPwkOiu4L9m"
   },
   "source": [
    "* 這其實就有用在 autoencoder 的 loss 上\n",
    "* y 是一張正規化後的影像(值都介於 0 到 1)，y_hat 是 reconstruct 後的影像，值也都介於 0 到 1 (因為最後有加 sigmoid)，此時算 loss 就可以用 binary_cross_entropy loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfekcdKh4L9m"
   },
   "source": [
    "### binary cross entropy with logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDg24NRy4L9m"
   },
   "outputs": [],
   "source": [
    "y_logit = torch.tensor([2.3552, -0.9071,  2.8323])\n",
    "y_hat = torch.tensor([0.9133, 0.2876, 0.9444]) # 就是 F.sigmoid(y_logit) 後的結果\n",
    "y = torch.tensor([0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkkrMe_Y4L9m"
   },
   "source": [
    "* $\\hat{y_i}$ 在轉成機率值前叫 logit (從 deep learning 的角度，就是還沒做 sigmoid 前的值; 從統計角度，sigmoid 在做的就是 logit transform 的逆變換)。  \n",
    "* 所以他會幫你把這個 $\\hat{y_i}$ 轉成 $\\frac{1}{1+e^{-\\hat{y_i}}}$ (這就是 sigmoid function 在做的事，也就是 logit transform 的逆變換)，再丟進去 binary cross entropy 裡面。\n",
    "* 補充以下以前學過的統計知識：  \n",
    "  * logit transform 是把 0 到 1 的機率值，轉成實數域。 e.g. p 介於 0 到 1， $y = log\\left(\\frac{p}{1-p}\\right)$，此時 y 介於 -無窮 到 +無窮，此時的 y 被稱為 logits\n",
    "  * logit transform 逆變換，是把時數域壓到 0 到 1 之間。 e.g. y 介於 -無窮 到 +無窮. $p = \\frac{1}{1+e^{-y}}$，此時 p 介於 0 到 1, 此時的 p 被解釋為機率值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpgkhGt84L9n"
   },
   "source": [
    "### cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqS_2zMv4L9n"
   },
   "source": [
    "* 先寫結論和用法，晚點補詳細的：  \n",
    "  * input 的 y_hat 必須是 logit (還沒經過 softmax), y可以是 [0,c) 的 integer，或是 one-hot encoding(必須是 float32，為了通用於 blended-label). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hhkl52E84L9n"
   },
   "source": [
    "* y_hat 需要是 logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_JWTUpy4L9n"
   },
   "outputs": [],
   "source": [
    "y_hat_logit_mat = np.array(\n",
    "    [[-2.3, 2, 1.5],\n",
    "     [-1, 2, 3]]\n",
    ")\n",
    "y_hat_logit_mat = torch.tensor(y_hat_logit_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSKr_kFv4L9o",
    "outputId": "843da3cd-4bc4-4fc9-9e45-2fb9525da897"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3000,  2.0000,  1.5000],\n",
       "        [-1.0000,  2.0000,  3.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_logit_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgWSIrwn4L9o"
   },
   "source": [
    "* 熟悉的 softmax 是這樣："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9h1yvaG4L9p",
    "outputId": "73474212-1d57-4ccc-8ef2-446eefe1cfb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0084, 0.6172, 0.3744],\n",
       "        [0.0132, 0.2654, 0.7214]], dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_mat = torch.nn.functional.softmax(y_hat_logit_mat, dim = 1)\n",
    "y_hat_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ufs9QDJh4L9q"
   },
   "source": [
    "* y 可以是 int 或 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2GrY84D4L9q"
   },
   "outputs": [],
   "source": [
    "y_int = torch.tensor([1,1])\n",
    "y_one_hot = torch.tensor([[0,1,0],[0,1,0]], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwvuEdOC4L9q"
   },
   "source": [
    "* 算 cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3gFiXQW4L9q",
    "outputId": "272b3f67-254d-49fc-87e0-26991a4da1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4825, 1.3266], dtype=torch.float64)\n",
      "tensor([0.4825, 1.3266], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "print(loss(y_hat_logit_mat, y_int))\n",
    "print(loss(y_hat_logit_mat, y_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaPyHokI4L9r",
    "outputId": "2ca07faf-9c8b-4105-d8fd-a5dbc48576d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9045, dtype=torch.float64)\n",
      "tensor(0.9045, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "print(loss(y_hat_logit_mat, y_int))\n",
    "print(loss(y_hat_logit_mat, y_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pONWEvRH4L9r"
   },
   "source": [
    "### 自訂 loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAswDLa_4L9r"
   },
   "source": [
    "### 對比學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HhgkUXk4L9r"
   },
   "source": [
    "### autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjIMFaNK4L9r"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 官網很清楚： https://pytorch.org/docs/1.8.1/optim.html#how-to-adjust-learning-rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxGOncFe4L9r"
   },
   "source": [
    "### 建立 optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同 learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXMcYqun4L9r"
   },
   "source": [
    "### learning rate scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ydCVEIN4L9r"
   },
   "source": [
    "## Training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8HxS-7_4L9s"
   },
   "source": [
    "### 完整版 (了解概念用)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4Qavpxp4L9s"
   },
   "source": [
    "* Data 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9RpJqOk4L9s"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Training\n",
    "X = np.random.rand(1000, 100, 100, 1)   # 虛構 1000 張 100 x 100 單色圖片\n",
    "Y = np.random.randint(0, 7, [1000, 10]) # 虛構 1000 個 labels\n",
    "\n",
    "X, Y = X.astype(np.float32), Y.astype(np.float32)\n",
    "tsrX, tsrY = torch.tensor(X), torch.tensor(Y)\n",
    "tsrdataset = TensorDataset(tsrX, tsrY)\n",
    "\n",
    "tsrdataloader = DataLoader(\n",
    "    tsrdataset, batch_size=4,\n",
    "    shuffle=True, num_workers=4)\n",
    "\n",
    "# Validation\n",
    "vX = np.random.rand(100, 100, 100, 1)   # 虛構 100 張 100 x 100 單色圖片\n",
    "vY = np.random.randint(0, 7, [100, 10]) # 虛構 100 個 labels\n",
    "\n",
    "vX, vY = vX.astype(np.float32), vY.astype(np.float32)\n",
    "vtsrX, vtsrY = torch.tensor(vX), torch.tensor(vY)\n",
    "vtsrdataset = TensorDataset(tsrX, tsrY)\n",
    "\n",
    "vtsrdataloader = DataLoader(\n",
    "    vtsrdataset, batch_size=4,\n",
    "    shuffle=False, num_workers=4) # Validation 不需要 shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io1Ey6mJ4L9s"
   },
   "source": [
    "* model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBRu5MWk4L9s"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(10000, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # 傳入 model 的函數會經過 forward 做 inference\n",
    "        # x = x.view(x.size(0), -1) # flatten 的意思，原本的 x.size = (batch_size, 100, 100, 1) -> 改成 (batch_size, 100*100*1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iry9GjJB4L9s"
   },
   "source": [
    "* 確定 device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wma47Zft4L9s",
    "outputId": "3dd82151-0556-42a0-b13c-f759d85c9bd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBeH2CER4L9t"
   },
   "outputs": [],
   "source": [
    "# model structure\n",
    "simpleNN = SimpleNN()\n",
    "simpleNN.to(device)                           # 把 model 移到 GPU 計算\n",
    "\n",
    "# optimizer\n",
    "optim = torch.optim.Adam(\n",
    "    simpleNN.parameters(), lr=1e-4)\n",
    "\n",
    "# loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWxqWVU-4L9t"
   },
   "source": [
    "* tensorboard 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oY9KV_Dm4L9t"
   },
   "outputs": [],
   "source": [
    "# tensorboard setting\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "logs_base_dir = \"runs\" # training 的紀錄，放在這個路徑下\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQN8RxJG4L9t"
   },
   "source": [
    "* 開始 Training， 本質就是跑一個迴圈，在每一次（叫一個 **epoch**）要做的事有——\n",
    "  1. 載入資料\n",
    "  2. 經過 model 跑一次\n",
    "  3. 比對資料的正確性，算誤差（loss）\n",
    "  4. 把梯度清掉，然後根據這次誤差算新的梯度\n",
    "  5. 根據 optimizer 更新參數\n",
    "  6. 為了方便觀察，將本次 epoch 訓練的變化顯示出來，包括\n",
    "     - 進度條（觀察訓練快慢）\n",
    "     - batch loss （這個有時候會輸出太多東西）\n",
    "     - epoch loss （記得累計並除掉資料數量）\n",
    "     - 記錄到其他變數中（方便作圖）\n",
    "     - 記錄到 Tensorboard 中（SummaryWriter）\n",
    "\n",
    "* 為了避免 overfit，我們每個 epoch 還會進行一次 validation，事情少一些，變成——\n",
    "  1. 載入資料\n",
    "  2. 經過 model 跑一次\n",
    "  3. 比對資料的正確性，算誤差（loss）\n",
    "  4. 為了方便觀察，將本次 epoch validate 的結果顯示出來，包括\n",
    "     - 進度條（觀察訓練快慢）\n",
    "     - batch loss （這個有時候會輸出太多東西）\n",
    "     - epoch loss （記得累計並除掉資料數量）\n",
    "     - 記錄到其他變數中（方便作圖）\n",
    "     - 記錄到 Tensorboard 中（SummaryWriter）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWzueQdz4L9t"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir {logs_base_dir} # 開啟 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhG8zkLP4L9t",
    "outputId": "0fb3e03b-3512-480d-bf67-4ac958fa495e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   Epoch  1: Loss = 1.0920\n",
      "Validation Epoch  1: Loss = 0.9851\n",
      "Training   Epoch  2: Loss = 0.9812\n",
      "Validation Epoch  2: Loss = 0.9269\n",
      "Training   Epoch  3: Loss = 0.9155\n",
      "Validation Epoch  3: Loss = 0.8980\n",
      "Training   Epoch  4: Loss = 0.8593\n",
      "Validation Epoch  4: Loss = 0.7541\n",
      "Training   Epoch  5: Loss = 0.7777\n",
      "Validation Epoch  5: Loss = 0.6951\n",
      "Training   Epoch  6: Loss = 0.7110\n",
      "Validation Epoch  6: Loss = 0.6363\n",
      "Training   Epoch  7: Loss = 0.6274\n",
      "Validation Epoch  7: Loss = 0.5730\n",
      "Training   Epoch  8: Loss = 0.5564\n",
      "Validation Epoch  8: Loss = 0.4740\n",
      "Training   Epoch  9: Loss = 0.4752\n",
      "Validation Epoch  9: Loss = 0.3994\n",
      "Training   Epoch 10: Loss = 0.3927\n",
      "Validation Epoch 10: Loss = 0.3577\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    # training step (training data)\n",
    "    simpleNN.train() # 切換 simpleNN 為 training 模式，dropout 之類的操作會開啟\n",
    "    epoch_loss = 0.0\n",
    "    for x, y in tsrdataloader:\n",
    "        y_hat = simpleNN(x.to(device))        # 把 x tensor 移到 GPU 計算\n",
    "        loss = criterion(y.to(device), y_hat) # 把 y tensor 移到 GPU 計算，\n",
    "                                              ##  y_hat 因為是從 GPU model input GPU Tensor 出來的\n",
    "                                              ##  所以不用再次 .to(device) 當然要也是沒差啦 =_=|||\n",
    "        optim.zero_grad() # 把 trainable variable/weights/parameters 的 gradient 給 歸 0\n",
    "        loss.backward() # 利用 loss，計算出每個 trainable variable/weights/parameters 所對應的 gradient\n",
    "        optim.step() # 更新 trainable variable/weights/parameters 的值： parameters_new = parameters_old - learning_rate * gradient\n",
    "        epoch_loss += loss.item()\n",
    "    average_epoch_loss = epoch_loss / len(tsrdataset)\n",
    "    print(f\"Training   Epoch {epoch + 1:2d}: Loss = {average_epoch_loss:.4f}\")\n",
    "    tb.add_scalar(\"Loss/train\", average_epoch_loss, epoch + 1) # 寫進 tensorboard\n",
    "    \n",
    "\n",
    "    # evaluation step (validation data)\n",
    "    simpleNN.eval() # 將 simpleNN 切換到 evaluation mode， dropout 之類的操作會關閉\n",
    "    vepoch_loss = 0.0\n",
    "    for x, y in vtsrdataloader:\n",
    "        y_hat = simpleNN(x.to(device))\n",
    "        loss = criterion(y.to(device), y_hat)\n",
    "        vepoch_loss += loss.item()\n",
    "    vaverage_epoch_loss = vepoch_loss / len(vtsrdataset)\n",
    "    print(f\"Validation Epoch {epoch + 1:2d}: Loss = {vaverage_epoch_loss:.4f}\")\n",
    "    tb.add_scalar(\"Loss/val\", vaverage_epoch_loss, epoch + 1) # 寫進 tensorboard\n",
    "tb.close() # 加這個"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qaS4EmV4L9u"
   },
   "source": [
    "### 模組版 (實際做實驗, deploy 時用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-lBCVh14L9u"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"計算預測正確的數量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlZJRlsg4L9u"
   },
   "outputs": [],
   "source": [
    "# 計算 metric 時用的\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个變量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n # [0.0, 0.0, ..., 0.0], 共 n 個 0.0\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-s7sWEV4L9u"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_iter):  #@save\n",
    "    \"\"\"計算在指定數據集上，模型的準確度\"\"\"\n",
    "    if isinstance(model, torch.nn.Module):\n",
    "        model.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBnPalve4L9u"
   },
   "outputs": [],
   "source": [
    "# 單一 epoch 裡要做的事\n",
    "def train_epoch(model, train_iter, loss, optimizer):  #@save\n",
    "    \n",
    "    model.train()\n",
    "    # 訓練損失總和、訓練準確度總和、樣本數\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = model(X)\n",
    "        l = loss(y_hat, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.mean().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回訓練損失 & 訓練準確度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CT31ehqb4L9u"
   },
   "outputs": [],
   "source": [
    "class Animator:  #@save\n",
    "    \"\"\"在動畫中繪製數據\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrGUZb1E4L9v"
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, valid_iter, loss, num_epochs, optimizer):  #@save\n",
    "    #animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "    #                    legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(model, train_iter, loss, updater)\n",
    "        valid_acc = evaluate_accuracy(model, valid_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (valid_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert valid_acc <= 1 and valid_acc > 0.7, valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdbpVFeZ4L9v"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1BId39k4L9v"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_93ERddN4L9v"
   },
   "source": [
    "* data 準備 (testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z8Q71904L9v"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "tX = np.random.rand(100, 100, 100, 1)   # 虛構 100 張 100 x 100 單色圖片\n",
    "tY = np.random.randint(0, 7, [100, 10]) # 虛構 100 個 labels\n",
    "\n",
    "tX, tY = tX.astype(np.float32), tY.astype(np.float32)\n",
    "ttsrX, ttsrY = torch.tensor(tX), torch.tensor(tY)\n",
    "ttsrdataset = TensorDataset(tsrX, tsrY)\n",
    "\n",
    "ttsrdataloader = DataLoader(\n",
    "    ttsrdataset, batch_size=4,\n",
    "    shuffle=False, num_workers=4) # Testing 不需要 shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y86AgtMd4L9w"
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "simpleNN.eval()\n",
    "y_hat = [simpleNN(x) for x, y in ttsrdataloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M5xpWNl4L9w"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_iter, n=6):  #@save\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    d2l.show_images(\n",
    "        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
    "\n",
    "predict_ch3(net, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9K_XAaZ4L9w"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqb0XiGk4L9w"
   },
   "source": [
    "## Save/ load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只存 weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設我們 train 好的 model 是 VGG\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# 只存 weight\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# 之後做預測，要先 initialize model\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# load weight\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "# 開始做 inference\n",
    "model.eval() # 關閉 batch normalization layer, dropout layer 等\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存 weight 和 model structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果把 model structure 和 weight 一起存起來，就可以 load 後，直接 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# 存檔時，存整個 model\n",
    "torch.save(model, 'model.pth')\n",
    "\n",
    "# 讀檔時，直接讀整個 model\n",
    "model = torch.load('model.pth') # 不需要 initialize 一個 model，再去讀 weight 了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNInaCoS4L9w"
   },
   "source": [
    "### checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\n",
    "* 看官網這篇就 ok 了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-3knBui4L9w"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "simpleNN.cpu() # 先移回 CPU\n",
    "torch.save(simpleNN.state_dict(), \"randmodel.model\")\n",
    "\n",
    "# Load model\n",
    "model2 = SimpleNN()\n",
    "model2.load_state_dict(torch.load(\"randmodel.model\"))\n",
    "\n",
    "# 確認是同一個 model\n",
    "torch.equal(model2(x), simpleNN(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 修改自：https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "        self.if_break = False\n",
    "\n",
    "    def monitor(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "        self.if_break = True if self.counter >= self.patience else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 然後這樣用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
    "for epoch in np.arange(n_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader)\n",
    "    validation_loss = validate_one_epoch(model, validation_loader)\n",
    "    \n",
    "    early_stopper.monitor(validation_loss)\n",
    "    if early_stopper.counter == 0:\n",
    "        torch.save(model, 'model.pth')\n",
    "    if early_stopper.if_break:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BoTTxEi4L9w"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensorboard 參考這篇：\n",
    "  * https://pytorch.org/docs/stable/tensorboard.html\n",
    "  * https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEi7Oqoi4L9x"
   },
   "source": [
    "## Explaianation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXBgYeF64L9z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
