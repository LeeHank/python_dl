
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Image classification reference training scripts &#8212; My sample book</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My sample book</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../intro.html">
   Welcome to your Jupyter Book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Cheat Sheet
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../pytorch/pytorch_cheatsheet.html">
   1. Pytorch Cheatsheet
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tensorflow basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/1.tensor.html">
   2. Introduction to Tensors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/2.variable.html">
   3. Introduction to Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/3.autodiff.html">
   4. Introduction to gradients and automatic differentiation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/5.intro_to_modules.html">
   5. Introduction to modules, layers, and models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/6.basic_training_loops.html">
   7. Basic training loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../old/7.keras_sequential_model.html">
   8. The Sequential model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../tf_create_model.html">
   9. 三種搭建神經網路的方式
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../hands_on_ml3/tf_customization.html">
   10. Customization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pytorch resource summarise
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../pytorch/d2l/d2l_linear_regression.html">
   11. Linear regression (d2l)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../pytorch/d2l/d2l_softmax_regression.html">
   12. Softmax regression (d2l)
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/others/vision/references/classification/README.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fothers/vision/references/classification/README.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alexnet-and-vgg">
   AlexNet and VGG
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#googlenet">
   GoogLeNet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inception-v3">
   Inception V3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnet">
   ResNet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnext">
   ResNext
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mobilenetv2">
   MobileNetV2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mobilenetv3-large-small">
   MobileNetV3 Large &amp; Small
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#efficientnet-v1">
   EfficientNet-V1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#efficientnet-v2">
   EfficientNet-V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regnet">
   RegNet
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#small-models">
     Small models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#medium-models">
     Medium models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-models">
     Large models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vision-transformer">
   Vision Transformer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-b-16">
     vit_b_16
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-b-32">
     vit_b_32
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-l-16">
     vit_l_16
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-l-32">
     vit_l_32
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convnext">
   ConvNeXt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#swintransformer">
   SwinTransformer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#swintransformer-v2">
   SwinTransformer V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maxvit">
   MaxViT
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shufflenet-v2">
   ShuffleNet V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mixed-precision-training">
   Mixed precision training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantized">
   Quantized
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#post-training-quantized-models">
     Post training quantized models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantized-shufflenet-v2">
     Quantized ShuffleNet V2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#qat-mobilenetv2">
     QAT MobileNetV2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#qat-mobilenetv3">
     QAT MobileNetV3
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#command-to-evaluate-quantized-models-using-the-pre-trained-weights">
     Command to evaluate quantized models using the pre-trained weights:
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Image classification reference training scripts</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#alexnet-and-vgg">
   AlexNet and VGG
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#googlenet">
   GoogLeNet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#inception-v3">
   Inception V3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnet">
   ResNet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resnext">
   ResNext
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mobilenetv2">
   MobileNetV2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mobilenetv3-large-small">
   MobileNetV3 Large &amp; Small
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#efficientnet-v1">
   EfficientNet-V1
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#efficientnet-v2">
   EfficientNet-V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regnet">
   RegNet
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#small-models">
     Small models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#medium-models">
     Medium models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-models">
     Large models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vision-transformer">
   Vision Transformer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-b-16">
     vit_b_16
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-b-32">
     vit_b_32
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-l-16">
     vit_l_16
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#vit-l-32">
     vit_l_32
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convnext">
   ConvNeXt
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#swintransformer">
   SwinTransformer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#swintransformer-v2">
   SwinTransformer V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maxvit">
   MaxViT
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#shufflenet-v2">
   ShuffleNet V2
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mixed-precision-training">
   Mixed precision training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantized">
   Quantized
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#post-training-quantized-models">
     Post training quantized models
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#quantized-shufflenet-v2">
     Quantized ShuffleNet V2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#qat-mobilenetv2">
     QAT MobileNetV2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#qat-mobilenetv3">
     QAT MobileNetV3
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#command-to-evaluate-quantized-models-using-the-pre-trained-weights">
     Command to evaluate quantized models using the pre-trained weights:
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="image-classification-reference-training-scripts">
<h1>Image classification reference training scripts<a class="headerlink" href="#image-classification-reference-training-scripts" title="Permalink to this headline">¶</a></h1>
<p>This folder contains reference training scripts for image classification.
They serve as a log of how to train specific models, as provide baseline
training and evaluation scripts to quickly bootstrap research.</p>
<p>Except otherwise noted, all models have been trained on 8x V100 GPUs with
the following parameters:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Parameter</p></th>
<th class="head"><p>value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--batch_size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">32</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--epochs</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">90</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--lr</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0.1</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--momentum</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0.9</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--wd</span></code>, <code class="docutils literal notranslate"><span class="pre">--weight-decay</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1e-4</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">--lr-step-size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">30</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">--lr-gamma</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0.1</span></code></p></td>
</tr>
</tbody>
</table>
<div class="section" id="alexnet-and-vgg">
<h2>AlexNet and VGG<a class="headerlink" href="#alexnet-and-vgg" title="Permalink to this headline">¶</a></h2>
<p>Since <code class="docutils literal notranslate"><span class="pre">AlexNet</span></code> and the original <code class="docutils literal notranslate"><span class="pre">VGG</span></code> architectures do not include batch
normalization, the default initial learning rate <code class="docutils literal notranslate"><span class="pre">--lr</span> <span class="pre">0.1</span></code> is too high.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
    --model $MODEL --lr 1e-2
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">alexnet</span></code>, <code class="docutils literal notranslate"><span class="pre">vgg11</span></code>, <code class="docutils literal notranslate"><span class="pre">vgg13</span></code>, <code class="docutils literal notranslate"><span class="pre">vgg16</span></code> or <code class="docutils literal notranslate"><span class="pre">vgg19</span></code>. Note
that <code class="docutils literal notranslate"><span class="pre">vgg11_bn</span></code>, <code class="docutils literal notranslate"><span class="pre">vgg13_bn</span></code>, <code class="docutils literal notranslate"><span class="pre">vgg16_bn</span></code>, and <code class="docutils literal notranslate"><span class="pre">vgg19_bn</span></code> include batch
normalization and thus are trained with the default parameters.</p>
</div>
<div class="section" id="googlenet">
<h2>GoogLeNet<a class="headerlink" href="#googlenet" title="Permalink to this headline">¶</a></h2>
<p>The weights of the GoogLeNet model are ported from the original paper rather than trained from scratch.</p>
</div>
<div class="section" id="inception-v3">
<h2>Inception V3<a class="headerlink" href="#inception-v3" title="Permalink to this headline">¶</a></h2>
<p>The weights of the Inception V3 model are ported from the original paper rather than trained from scratch.</p>
<p>Since it expects tensors with a size of N x 3 x 299 x 299, to validate the model use the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">inception_v3</span>\
      <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">Inception_V3_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
</pre></div>
</div>
</div>
<div class="section" id="resnet">
<h2>ResNet<a class="headerlink" href="#resnet" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py --model $MODEL
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">resnet18</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet34</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet50</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet101</span></code> or <code class="docutils literal notranslate"><span class="pre">resnet152</span></code>.</p>
</div>
<div class="section" id="resnext">
<h2>ResNext<a class="headerlink" href="#resnext" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
    --model $MODEL --epochs 100
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">resnext50_32x4d</span></code> or <code class="docutils literal notranslate"><span class="pre">resnext101_32x8d</span></code>.
Note that the above command corresponds to a single node with 8 GPUs. If you use
a different number of GPUs and/or a different batch size, then the learning rate
should be scaled accordingly. For example, the pretrained model provided by
<code class="docutils literal notranslate"><span class="pre">torchvision</span></code> was trained on 8 nodes, each with 8 GPUs (for a total of 64 GPUs),
with <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">16</span></code> and <code class="docutils literal notranslate"><span class="pre">--lr</span> <span class="pre">0.4</span></code>, instead of the current defaults
which are respectively batch_size=32 and lr=0.1</p>
</div>
<div class="section" id="mobilenetv2">
<h2>MobileNetV2<a class="headerlink" href="#mobilenetv2" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
     <span class="o">--</span><span class="n">model</span> <span class="n">mobilenet_v2</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">300</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.045</span> <span class="o">--</span><span class="n">wd</span> <span class="mf">0.00004</span>\
     <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">step</span><span class="o">-</span><span class="n">size</span> <span class="mi">1</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">gamma</span> <span class="mf">0.98</span>
</pre></div>
</div>
</div>
<div class="section" id="mobilenetv3-large-small">
<h2>MobileNetV3 Large &amp; Small<a class="headerlink" href="#mobilenetv3-large-small" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
     --model $MODEL --epochs 600 --opt rmsprop --batch-size 128 --lr 0.064\ 
     --wd 0.00001 --lr-step-size 2 --lr-gamma 0.973 --auto-augment imagenet --random-erase 0.2
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">mobilenet_v3_large</span></code> or <code class="docutils literal notranslate"><span class="pre">mobilenet_v3_small</span></code>.</p>
<p>Then we averaged the parameters of the last 3 checkpoints that improved the Acc&#64;1. See <a class="reference external" href="https://github.com/pytorch/vision/pull/3182">#3182</a>
and <a class="reference external" href="https://github.com/pytorch/vision/pull/3354">#3354</a> for details.</p>
</div>
<div class="section" id="efficientnet-v1">
<h2>EfficientNet-V1<a class="headerlink" href="#efficientnet-v1" title="Permalink to this headline">¶</a></h2>
<p>The weights of the B0-B4 variants are ported from Ross Wightman’s <a class="reference external" href="https://github.com/rwightman/pytorch-image-models/blob/01cb46a9a50e3ba4be167965b5764e9702f09b30/timm/models/efficientnet.py#L95-L108">timm repo</a>.</p>
<p>The weights of the B5-B7 variants are ported from Luke Melas’ <a class="reference external" href="https://github.com/lukemelas/EfficientNet-PyTorch/blob/1039e009545d9329ea026c9f7541341439712b96/efficientnet_pytorch/utils.py#L562-L564">EfficientNet-PyTorch repo</a>.</p>
<p>All models were trained using Bicubic interpolation and each have custom crop and resize sizes. To validate the models use the following commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b0</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B0_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b1</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B1_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b2</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b3</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B3_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b4</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B4_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b5</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B5_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b6</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B6_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
<span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">efficientnet_b7</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">weights</span> <span class="n">EfficientNet_B7_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span>
</pre></div>
</div>
</div>
<div class="section" id="efficientnet-v2">
<h2>EfficientNet-V2<a class="headerlink" href="#efficientnet-v2" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py \
--model $MODEL --batch-size 128 --lr 0.5 --lr-scheduler cosineannealinglr \
--lr-warmup-epochs 5 --lr-warmup-method linear --auto-augment ta_wide --epochs 600 --random-erase 0.1 \
--label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 --weight-decay 0.00002 --norm-weight-decay 0.0 \
--train-crop-size $TRAIN_SIZE --model-ema --val-crop-size $EVAL_SIZE --val-resize-size $EVAL_SIZE \
--ra-sampler --ra-reps 4
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">efficientnet_v2_s</span></code> and <code class="docutils literal notranslate"><span class="pre">efficientnet_v2_m</span></code>.
Note that the Small variant had a <code class="docutils literal notranslate"><span class="pre">$TRAIN_SIZE</span></code> of <code class="docutils literal notranslate"><span class="pre">300</span></code> and a <code class="docutils literal notranslate"><span class="pre">$EVAL_SIZE</span></code> of <code class="docutils literal notranslate"><span class="pre">384</span></code>, while the Medium <code class="docutils literal notranslate"><span class="pre">384</span></code> and <code class="docutils literal notranslate"><span class="pre">480</span></code> respectively.</p>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 4 nodes, each with 8 GPUs (for a total of 32 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">32</span></code>.</p>
<p>The weights of the Large variant are ported from the original paper rather than trained from scratch. See the <code class="docutils literal notranslate"><span class="pre">EfficientNet_V2_L_Weights</span></code> entry for their exact preprocessing transforms.</p>
</div>
<div class="section" id="regnet">
<h2>RegNet<a class="headerlink" href="#regnet" title="Permalink to this headline">¶</a></h2>
<div class="section" id="small-models">
<h3>Small models<a class="headerlink" href="#small-models" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
     --model $MODEL --epochs 100 --batch-size 128 --wd 0.00005 --lr=0.8\
     --lr-scheduler=cosineannealinglr --lr-warmup-method=linear\
     --lr-warmup-epochs=5 --lr-warmup-decay=0.1
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">regnet_x_400mf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_x_800mf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_x_1_6gf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_y_400mf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_y_800mf</span></code> and <code class="docutils literal notranslate"><span class="pre">regnet_y_1_6gf</span></code>. Please note we used learning rate 0.4 for <code class="docutils literal notranslate"><span class="pre">regent_y_400mf</span></code> to get the same Acc&#64;1 as [the paper)(<a class="reference external" href="https://arxiv.org/abs/2003.13678">https://arxiv.org/abs/2003.13678</a>).</p>
</div>
<div class="section" id="medium-models">
<h3>Medium models<a class="headerlink" href="#medium-models" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
     --model $MODEL --epochs 100 --batch-size 64 --wd 0.00005 --lr=0.4\
     --lr-scheduler=cosineannealinglr --lr-warmup-method=linear\
     --lr-warmup-epochs=5 --lr-warmup-decay=0.1
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">regnet_x_3_2gf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_x_8gf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_x_16gf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_y_3_2gf</span></code> and <code class="docutils literal notranslate"><span class="pre">regnet_y_8gf</span></code>.</p>
</div>
<div class="section" id="large-models">
<h3>Large models<a class="headerlink" href="#large-models" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
     --model $MODEL --epochs 100 --batch-size 32 --wd 0.00005 --lr=0.2\
     --lr-scheduler=cosineannealinglr --lr-warmup-method=linear\
     --lr-warmup-epochs=5 --lr-warmup-decay=0.1
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">regnet_x_32gf</span></code>, <code class="docutils literal notranslate"><span class="pre">regnet_y_16gf</span></code> and <code class="docutils literal notranslate"><span class="pre">regnet_y_32gf</span></code>.</p>
</div>
</div>
<div class="section" id="vision-transformer">
<h2>Vision Transformer<a class="headerlink" href="#vision-transformer" title="Permalink to this headline">¶</a></h2>
<div class="section" id="vit-b-16">
<h3>vit_b_16<a class="headerlink" href="#vit-b-16" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
    <span class="o">--</span><span class="n">model</span> <span class="n">vit_b_16</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">300</span> <span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span> <span class="mi">512</span> <span class="o">--</span><span class="n">opt</span> <span class="n">adamw</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.003</span> <span class="o">--</span><span class="n">wd</span> <span class="mf">0.3</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">cosineannealinglr</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">method</span> <span class="n">linear</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">epochs</span> <span class="mi">30</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">decay</span> <span class="mf">0.033</span> <span class="o">--</span><span class="n">amp</span> <span class="o">--</span><span class="n">label</span><span class="o">-</span><span class="n">smoothing</span> <span class="mf">0.11</span> <span class="o">--</span><span class="n">mixup</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">0.2</span> <span class="o">--</span><span class="n">auto</span><span class="o">-</span><span class="n">augment</span> <span class="n">ra</span>\
    <span class="o">--</span><span class="n">clip</span><span class="o">-</span><span class="n">grad</span><span class="o">-</span><span class="n">norm</span> <span class="mi">1</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">sampler</span> <span class="o">--</span><span class="n">cutmix</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">1.0</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">ema</span>
</pre></div>
</div>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 8 nodes, each with 8 GPUs (for a total of 64 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">64</span></code>.</p>
</div>
<div class="section" id="vit-b-32">
<h3>vit_b_32<a class="headerlink" href="#vit-b-32" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
    <span class="o">--</span><span class="n">model</span> <span class="n">vit_b_32</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">300</span> <span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span> <span class="mi">512</span> <span class="o">--</span><span class="n">opt</span> <span class="n">adamw</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.003</span> <span class="o">--</span><span class="n">wd</span> <span class="mf">0.3</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">cosineannealinglr</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">method</span> <span class="n">linear</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">epochs</span> <span class="mi">30</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">decay</span> <span class="mf">0.033</span> <span class="o">--</span><span class="n">amp</span> <span class="o">--</span><span class="n">label</span><span class="o">-</span><span class="n">smoothing</span> <span class="mf">0.11</span> <span class="o">--</span><span class="n">mixup</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">0.2</span> <span class="o">--</span><span class="n">auto</span><span class="o">-</span><span class="n">augment</span> <span class="n">imagenet</span>\
    <span class="o">--</span><span class="n">clip</span><span class="o">-</span><span class="n">grad</span><span class="o">-</span><span class="n">norm</span> <span class="mi">1</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">sampler</span> <span class="o">--</span><span class="n">cutmix</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">1.0</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">ema</span>
</pre></div>
</div>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 2 nodes, each with 8 GPUs (for a total of 16 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">256</span></code>.</p>
</div>
<div class="section" id="vit-l-16">
<h3>vit_l_16<a class="headerlink" href="#vit-l-16" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
    <span class="o">--</span><span class="n">model</span> <span class="n">vit_l_16</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">600</span> <span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span> <span class="mi">128</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.5</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">cosineannealinglr</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">method</span> <span class="n">linear</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">epochs</span> <span class="mi">5</span> <span class="o">--</span><span class="n">label</span><span class="o">-</span><span class="n">smoothing</span> <span class="mf">0.1</span> <span class="o">--</span><span class="n">mixup</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">0.2</span>\
    <span class="o">--</span><span class="n">auto</span><span class="o">-</span><span class="n">augment</span> <span class="n">ta_wide</span> <span class="o">--</span><span class="n">random</span><span class="o">-</span><span class="n">erase</span> <span class="mf">0.1</span> <span class="o">--</span><span class="n">weight</span><span class="o">-</span><span class="n">decay</span> <span class="mf">0.00002</span> <span class="o">--</span><span class="n">norm</span><span class="o">-</span><span class="n">weight</span><span class="o">-</span><span class="n">decay</span> <span class="mf">0.0</span>\
    <span class="o">--</span><span class="n">clip</span><span class="o">-</span><span class="n">grad</span><span class="o">-</span><span class="n">norm</span> <span class="mi">1</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">sampler</span> <span class="o">--</span><span class="n">cutmix</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">1.0</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">ema</span> <span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">resize</span><span class="o">-</span><span class="n">size</span> <span class="mi">232</span>
</pre></div>
</div>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 2 nodes, each with 8 GPUs (for a total of 16 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">64</span></code>.</p>
</div>
<div class="section" id="vit-l-32">
<h3>vit_l_32<a class="headerlink" href="#vit-l-32" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
    <span class="o">--</span><span class="n">model</span> <span class="n">vit_l_32</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">300</span> <span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span> <span class="mi">512</span> <span class="o">--</span><span class="n">opt</span> <span class="n">adamw</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.003</span> <span class="o">--</span><span class="n">wd</span> <span class="mf">0.3</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">scheduler</span> <span class="n">cosineannealinglr</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">method</span> <span class="n">linear</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">epochs</span> <span class="mi">30</span>\
    <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">decay</span> <span class="mf">0.033</span> <span class="o">--</span><span class="n">amp</span> <span class="o">--</span><span class="n">label</span><span class="o">-</span><span class="n">smoothing</span> <span class="mf">0.11</span> <span class="o">--</span><span class="n">mixup</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">0.2</span> <span class="o">--</span><span class="n">auto</span><span class="o">-</span><span class="n">augment</span> <span class="n">ra</span>\
    <span class="o">--</span><span class="n">clip</span><span class="o">-</span><span class="n">grad</span><span class="o">-</span><span class="n">norm</span> <span class="mi">1</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">sampler</span> <span class="o">--</span><span class="n">cutmix</span><span class="o">-</span><span class="n">alpha</span> <span class="mf">1.0</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">ema</span>
</pre></div>
</div>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 8 nodes, each with 8 GPUs (for a total of 64 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">64</span></code>.</p>
</div>
</div>
<div class="section" id="convnext">
<h2>ConvNeXt<a class="headerlink" href="#convnext" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\ 
--model $MODEL --batch-size 128 --opt adamw --lr 1e-3 --lr-scheduler cosineannealinglr \ 
--lr-warmup-epochs 5 --lr-warmup-method linear --auto-augment ta_wide --epochs 600 --random-erase 0.1 \ 
--label-smoothing 0.1 --mixup-alpha 0.2 --cutmix-alpha 1.0 --weight-decay 0.05 --norm-weight-decay 0.0 \
--train-crop-size 176 --model-ema --val-resize-size 232 --ra-sampler --ra-reps 4
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">convnext_tiny</span></code>, <code class="docutils literal notranslate"><span class="pre">convnext_small</span></code>, <code class="docutils literal notranslate"><span class="pre">convnext_base</span></code> and <code class="docutils literal notranslate"><span class="pre">convnext_large</span></code>. Note that each variant had its <code class="docutils literal notranslate"><span class="pre">--val-resize-size</span></code> optimized in a post-training step, see their <code class="docutils literal notranslate"><span class="pre">Weights</span></code> entry for their exact value.</p>
<p>Note that the above command corresponds to training on a single node with 8 GPUs.
For generatring the pre-trained weights, we trained with 2 nodes, each with 8 GPUs (for a total of 16 GPUs),
and <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">64</span></code>.</p>
</div>
<div class="section" id="swintransformer">
<h2>SwinTransformer<a class="headerlink" href="#swintransformer" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\ 
--model $MODEL --epochs 300 --batch-size 128 --opt adamw --lr 0.001 --weight-decay 0.05 --norm-weight-decay 0.0  --bias-weight-decay 0.0 --transformer-embedding-decay 0.0 --lr-scheduler cosineannealinglr --lr-min 0.00001 --lr-warmup-method linear  --lr-warmup-epochs 20 --lr-warmup-decay 0.01 --amp --label-smoothing 0.1 --mixup-alpha 0.8 --clip-grad-norm 5.0 --cutmix-alpha 1.0 --random-erase 0.25 --interpolation bicubic --auto-augment ta_wide --model-ema --ra-sampler --ra-reps 4  --val-resize-size 224
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">swin_t</span></code>, <code class="docutils literal notranslate"><span class="pre">swin_s</span></code> or <code class="docutils literal notranslate"><span class="pre">swin_b</span></code>.
Note that <code class="docutils literal notranslate"><span class="pre">--val-resize-size</span></code> was optimized in a post-training step, see their <code class="docutils literal notranslate"><span class="pre">Weights</span></code> entry for the exact value.</p>
</div>
<div class="section" id="swintransformer-v2">
<h2>SwinTransformer V2<a class="headerlink" href="#swintransformer-v2" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 train.py\
--model $MODEL --epochs 300 --batch-size 128 --opt adamw --lr 0.001 --weight-decay 0.05 --norm-weight-decay 0.0  --bias-weight-decay 0.0 --transformer-embedding-decay 0.0 --lr-scheduler cosineannealinglr --lr-min 0.00001 --lr-warmup-method linear  --lr-warmup-epochs 20 --lr-warmup-decay 0.01 --amp --label-smoothing 0.1 --mixup-alpha 0.8 --clip-grad-norm 5.0 --cutmix-alpha 1.0 --random-erase 0.25 --interpolation bicubic --auto-augment ta_wide --model-ema --ra-sampler --ra-reps 4  --val-resize-size 256 --val-crop-size 256 --train-crop-size 256 
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">swin_v2_t</span></code>, <code class="docutils literal notranslate"><span class="pre">swin_v2_s</span></code> or <code class="docutils literal notranslate"><span class="pre">swin_v2_b</span></code>.
Note that <code class="docutils literal notranslate"><span class="pre">--val-resize-size</span></code> was optimized in a post-training step, see their <code class="docutils literal notranslate"><span class="pre">Weights</span></code> entry for the exact value.</p>
</div>
<div class="section" id="maxvit">
<h2>MaxViT<a class="headerlink" href="#maxvit" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>torchrun --nproc_per_node=8 --n_nodes=4 train.py\
--model $MODEL --epochs 400 --batch-size 128 --opt adamw --lr 3e-3 --weight-decay 0.05 --lr-scheduler cosineannealinglr --lr-min 1e-5 --lr-warmup-method linear  --lr-warmup-epochs 32  --label-smoothing 0.1 --mixup-alpha 0.8 --clip-grad-norm 1.0 --interpolation bicubic --auto-augment ta_wide --policy-magnitude 15 --model-ema --val-resize-size 224\
--val-crop-size 224 --train-crop-size 224 --amp  --model-ema-steps 32 --transformer-embedding-decay 0 --sync-bn
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is <code class="docutils literal notranslate"><span class="pre">maxvit_t</span></code>.
Note that <code class="docutils literal notranslate"><span class="pre">--val-resize-size</span></code> was not optimized in a post-training step.</p>
</div>
<div class="section" id="shufflenet-v2">
<h2>ShuffleNet V2<a class="headerlink" href="#shufflenet-v2" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> \
<span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span><span class="o">=</span><span class="mi">128</span> \
<span class="o">--</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">scheduler</span><span class="o">=</span><span class="n">cosineannealinglr</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">epochs</span><span class="o">=</span><span class="mi">5</span> <span class="o">--</span><span class="n">lr</span><span class="o">-</span><span class="n">warmup</span><span class="o">-</span><span class="n">method</span><span class="o">=</span><span class="n">linear</span> \
<span class="o">--</span><span class="n">auto</span><span class="o">-</span><span class="n">augment</span><span class="o">=</span><span class="n">ta_wide</span> <span class="o">--</span><span class="n">epochs</span><span class="o">=</span><span class="mi">600</span> <span class="o">--</span><span class="n">random</span><span class="o">-</span><span class="n">erase</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">--</span><span class="n">weight</span><span class="o">-</span><span class="n">decay</span><span class="o">=</span><span class="mf">0.00002</span> \
<span class="o">--</span><span class="n">norm</span><span class="o">-</span><span class="n">weight</span><span class="o">-</span><span class="n">decay</span><span class="o">=</span><span class="mf">0.0</span> <span class="o">--</span><span class="n">label</span><span class="o">-</span><span class="n">smoothing</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">--</span><span class="n">mixup</span><span class="o">-</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span> <span class="o">--</span><span class="n">cutmix</span><span class="o">-</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span> \
<span class="o">--</span><span class="n">train</span><span class="o">-</span><span class="n">crop</span><span class="o">-</span><span class="n">size</span><span class="o">=</span><span class="mi">176</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">ema</span> <span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">resize</span><span class="o">-</span><span class="n">size</span><span class="o">=</span><span class="mi">232</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">sampler</span> <span class="o">--</span><span class="n">ra</span><span class="o">-</span><span class="n">reps</span><span class="o">=</span><span class="mi">4</span>
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is either <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x1_5</span></code> or <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x2_0</span></code>.</p>
<p>The models <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x0_5</span></code> and <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x1_0</span></code> were contributed by the community. See <a class="reference external" href="https://github.com/pytorch/vision/pull/849#issuecomment-483391686">PR-849</a> for details.</p>
</div>
<div class="section" id="mixed-precision-training">
<h2>Mixed precision training<a class="headerlink" href="#mixed-precision-training" title="Permalink to this headline">¶</a></h2>
<p>Automatic Mixed Precision (AMP) training on GPU for Pytorch can be enabled with the <a class="reference external" href="https://pytorch.org/docs/stable/amp.html?highlight=amp#module-torch.cuda.amp">torch.cuda.amp</a>.</p>
<p>Mixed precision training makes use of both FP32 and FP16 precisions where appropriate. FP16 operations can leverage the Tensor cores on NVIDIA GPUs (Volta, Turing or newer architectures) for improved throughput, generally without loss in model accuracy. Mixed precision training also often allows larger batch sizes. GPU automatic mixed precision training for Pytorch Vision can be enabled via the flag value <code class="docutils literal notranslate"><span class="pre">--amp=True</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>\
    <span class="o">--</span><span class="n">model</span> <span class="n">resnext50_32x4d</span> <span class="o">--</span><span class="n">epochs</span> <span class="mi">100</span> <span class="o">--</span><span class="n">amp</span>
</pre></div>
</div>
</div>
<div class="section" id="quantized">
<h2>Quantized<a class="headerlink" href="#quantized" title="Permalink to this headline">¶</a></h2>
<div class="section" id="post-training-quantized-models">
<h3>Post training quantized models<a class="headerlink" href="#post-training-quantized-models" title="Permalink to this headline">¶</a></h3>
<p>For all post training quantized models, the settings are:</p>
<ol class="simple">
<li><p>num_calibration_batches: 32</p></li>
<li><p>num_workers: 16</p></li>
<li><p>batch_size: 32</p></li>
<li><p>eval_batch_size: 128</p></li>
<li><p>backend: ‘fbgemm’</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="o">--</span><span class="n">post</span><span class="o">-</span><span class="n">training</span><span class="o">-</span><span class="n">quantize</span> <span class="o">--</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;fbgemm&#39;</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;$MODEL&#39;</span>
</pre></div>
</div>
<p>Here <code class="docutils literal notranslate"><span class="pre">$MODEL</span></code> is one of <code class="docutils literal notranslate"><span class="pre">googlenet</span></code>, <code class="docutils literal notranslate"><span class="pre">inception_v3</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet18</span></code>, <code class="docutils literal notranslate"><span class="pre">resnet50</span></code>, <code class="docutils literal notranslate"><span class="pre">resnext101_32x8d</span></code>, <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x0_5</span></code> and <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x1_0</span></code>.</p>
</div>
<div class="section" id="quantized-shufflenet-v2">
<h3>Quantized ShuffleNet V2<a class="headerlink" href="#quantized-shufflenet-v2" title="Permalink to this headline">¶</a></h3>
<p>Here are commands that we use to quantized the <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x1_5</span></code> and <code class="docutils literal notranslate"><span class="pre">shufflenet_v2_x2_0</span></code> models.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># For shufflenet_v2_x1_5</span>
<span class="n">python</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="o">--</span><span class="n">post</span><span class="o">-</span><span class="n">training</span><span class="o">-</span><span class="n">quantize</span> <span class="o">--</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;fbgemm&#39;</span> \
    <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="n">shufflenet_v2_x1_5</span> <span class="o">--</span><span class="n">weights</span><span class="o">=</span><span class="s2">&quot;ShuffleNet_V2_X1_5_Weights.IMAGENET1K_V1&quot;</span> \
    <span class="o">--</span><span class="n">train</span><span class="o">-</span><span class="n">crop</span><span class="o">-</span><span class="n">size</span> <span class="mi">176</span> <span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">resize</span><span class="o">-</span><span class="n">size</span> <span class="mi">232</span> <span class="o">--</span><span class="n">data</span><span class="o">-</span><span class="n">path</span> <span class="o">/</span><span class="n">datasets01_ontap</span><span class="o">/</span><span class="n">imagenet_full_size</span><span class="o">/</span><span class="mi">061417</span><span class="o">/</span>

<span class="c1"># For shufflenet_v2_x2_0</span>
<span class="n">python</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="o">--</span><span class="n">post</span><span class="o">-</span><span class="n">training</span><span class="o">-</span><span class="n">quantize</span> <span class="o">--</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;fbgemm&#39;</span> \
    <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="n">shufflenet_v2_x2_0</span> <span class="o">--</span><span class="n">weights</span><span class="o">=</span><span class="s2">&quot;ShuffleNet_V2_X2_0_Weights.IMAGENET1K_V1&quot;</span> \
    <span class="o">--</span><span class="n">train</span><span class="o">-</span><span class="n">crop</span><span class="o">-</span><span class="n">size</span> <span class="mi">176</span> <span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">resize</span><span class="o">-</span><span class="n">size</span> <span class="mi">232</span> <span class="o">--</span><span class="n">data</span><span class="o">-</span><span class="n">path</span> <span class="o">/</span><span class="n">datasets01_ontap</span><span class="o">/</span><span class="n">imagenet_full_size</span><span class="o">/</span><span class="mi">061417</span><span class="o">/</span>
</pre></div>
</div>
</div>
<div class="section" id="qat-mobilenetv2">
<h3>QAT MobileNetV2<a class="headerlink" href="#qat-mobilenetv2" title="Permalink to this headline">¶</a></h3>
<p>For Mobilenet-v2, the model was trained with quantization aware training, the settings used are:</p>
<ol class="simple">
<li><p>num_workers: 16</p></li>
<li><p>batch_size: 32</p></li>
<li><p>eval_batch_size: 128</p></li>
<li><p>backend: ‘qnnpack’</p></li>
<li><p>learning-rate: 0.0001</p></li>
<li><p>num_epochs: 90</p></li>
<li><p>num_observer_update_epochs:4</p></li>
<li><p>num_batch_norm_update_epochs:3</p></li>
<li><p>momentum: 0.9</p></li>
<li><p>lr_step_size:30</p></li>
<li><p>lr_gamma: 0.1</p></li>
<li><p>weight-decay: 0.0001</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;mobilenet_v2&#39;</span>
</pre></div>
</div>
<p>Training converges at about 10 epochs.</p>
</div>
<div class="section" id="qat-mobilenetv3">
<h3>QAT MobileNetV3<a class="headerlink" href="#qat-mobilenetv3" title="Permalink to this headline">¶</a></h3>
<p>For Mobilenet-v3 Large, the model was trained with quantization aware training, the settings used are:</p>
<ol class="simple">
<li><p>num_workers: 16</p></li>
<li><p>batch_size: 32</p></li>
<li><p>eval_batch_size: 128</p></li>
<li><p>backend: ‘qnnpack’</p></li>
<li><p>learning-rate: 0.001</p></li>
<li><p>num_epochs: 90</p></li>
<li><p>num_observer_update_epochs:4</p></li>
<li><p>num_batch_norm_update_epochs:3</p></li>
<li><p>momentum: 0.9</p></li>
<li><p>lr_step_size:30</p></li>
<li><p>lr_gamma: 0.1</p></li>
<li><p>weight-decay: 0.00001</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span><span class="o">=</span><span class="mi">8</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;mobilenet_v3_large&#39;</span> \
    <span class="o">--</span><span class="n">wd</span> <span class="mf">0.00001</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.001</span>
</pre></div>
</div>
<p>For post training quant, device is set to CPU. For training, the device is set to CUDA.</p>
</div>
<div class="section" id="command-to-evaluate-quantized-models-using-the-pre-trained-weights">
<h3>Command to evaluate quantized models using the pre-trained weights:<a class="headerlink" href="#command-to-evaluate-quantized-models-using-the-pre-trained-weights" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train_quantization</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span> <span class="o">--</span><span class="n">test</span><span class="o">-</span><span class="n">only</span> <span class="o">--</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;&lt;backend&gt;&#39;</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="s1">&#39;&lt;model_name&gt;&#39;</span>
</pre></div>
</div>
<p>For inception_v3 you need to pass the following extra parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">resize</span><span class="o">-</span><span class="n">size</span> <span class="mi">342</span> <span class="o">--</span><span class="n">val</span><span class="o">-</span><span class="n">crop</span><span class="o">-</span><span class="n">size</span> <span class="mi">299</span> <span class="o">--</span><span class="n">train</span><span class="o">-</span><span class="n">crop</span><span class="o">-</span><span class="n">size</span> <span class="mi">299</span>
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./others/vision/references/classification"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book Community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>